<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>彩音のBlog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="/"/>
  <updated>2021-12-04T03:12:48.370Z</updated>
  <id>/</id>
  
  <author>
    <name>彩音</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pytorch环境配置</title>
    <link href="/2021/12/03/Pytorch%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <id>/2021/12/03/Pytorch环境配置/</id>
    <published>2021-12-03T07:41:00.000Z</published>
    <updated>2021-12-04T03:12:48.370Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Pytorch环境配置"><a href="#Pytorch环境配置" class="headerlink" title="Pytorch环境配置"></a>Pytorch环境配置</h1><p>硬件环境：AMD5900X+NVIDIA3070</p><p>软件环境配置：windows11+python3.7+pytorch1.8+cuda11.1+cudnn8.2</p><h2 id="Python3-7安装"><a href="#Python3-7安装" class="headerlink" title="Python3.7安装"></a>Python3.7安装</h2><p>python3.7.9 官方下载链接：<a href="https://www.python.org/ftp/python/3.7.9/python-3.7.9-amd64.exe" target="_blank" rel="noopener">https://www.python.org/ftp/python/3.7.9/python-3.7.9-amd64.exe</a></p><p>安装时记得勾选 <code>add python3.7 to path</code></p><p>命令行中输入 <code>python</code> 得到如下回显即为成功：</p><pre><code class="markdown">PS C:\Users\circle&gt; pythonPython 3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)] on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt;</code></pre><h2 id="cuda11-1-cudnn8-2安装"><a href="#cuda11-1-cudnn8-2安装" class="headerlink" title="cuda11.1+cudnn8.2安装"></a>cuda11.1+cudnn8.2安装</h2><p>cuda版本可以查阅：NVIDIA控制面板-系统信息-组件</p><p>理论上安装的cuda版本要低于NVIDIA控制面板显示值并根据pytorch支持的情况进行选择。</p><a href="\img\post\Pytorch环境配置\控制面板信息.png" data-fancybox="images" data-caption="控制面板信息"><img src="\img\post\Pytorch环境配置\控制面板信息.png"></a><p>cuda 安装列表：<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit-archive</a></p><p>cuda11.1 官方下载链接：<a href="https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda_11.1.0_456.43_win10.exe" target="_blank" rel="noopener">https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda_11.1.0_456.43_win10.exe</a></p><p>cudnn版本可以根据cudnn安装列表按照cuda版本进行安装，cudnn下载可能需要注册并登录NVIDIA官网。</p><p>cudnn 安装列表：<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-archive</a></p><p>cudnn8.2 for cuda11.x 官方下载链接：<a href="https://developer.nvidia.com/compute/machine-learning/cudnn/secure/8.2.0.53/11.3_04222021/cudnn-11.3-windows-x64-v8.2.0.53.zip" target="_blank" rel="noopener">https://developer.nvidia.com/compute/machine-learning/cudnn/secure/8.2.0.53/11.3_04222021/cudnn-11.3-windows-x64-v8.2.0.53.zip</a></p><p>将cudnn解压后得到的文件复制到cuda根目录下即可。</p><a href="\img\post\Pytorch环境配置\文件目录.png" data-fancybox="images" data-caption="文件目录"><img src="\img\post\Pytorch环境配置\文件目录.png"></a><p>命令行中输入 <code>nvidia-smi</code> 得到如下回显即为成功：</p><pre><code class="markdown">PS C:\Users\circle&gt; nvidia-smiFri Dec  3 18:38:11 2021+-----------------------------------------------------------------------------+| NVIDIA-SMI 496.13       Driver Version: 496.13       CUDA Version: 11.5     ||-------------------------------+----------------------+----------------------+| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||                               |                      |               MIG M. ||===============================+======================+======================||   0  NVIDIA GeForce ... WDDM  | 00000000:0A:00.0  On |                  N/A ||  0%   40C    P8     9W / 220W |   1327MiB /  8192MiB |      3%      Default ||                               |                      |                  N/A |+-------------------------------+----------------------+----------------------+</code></pre><p>cuda版本建议安装11.1，其他版本有可能和pytorch兼容性差导致无法正常调用pytorch函数库。</p><h2 id="Pytorch1-8安装"><a href="#Pytorch1-8安装" class="headerlink" title="Pytorch1.8安装"></a>Pytorch1.8安装</h2><p>命令行输入 <code>pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html</code></p><p>安装成功后，命令行执行如下指令：</p><pre><code class="markdown">PS C:\Users\circle&gt; pythonPython 3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)] on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import torch&gt;&gt;&gt; torch.cuda.get_device_name(0)&#39;NVIDIA GeForce RTX 3070&#39;&gt;&gt;&gt;</code></pre><p>显卡名称正常回显即为成功安装pytorch。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Pytorch环境配置&quot;&gt;&lt;a href=&quot;#Pytorch环境配置&quot; class=&quot;headerlink&quot; title=&quot;Pytorch环境配置&quot;&gt;&lt;/a&gt;Pytorch环境配置&lt;/h1&gt;&lt;p&gt;硬件环境：AMD5900X+NVIDIA3070&lt;/p&gt;
&lt;p&gt;软件
      
    
    </summary>
    
      <category term="生活" scheme="/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="python" scheme="/tags/python/"/>
    
      <category term="pytorch" scheme="/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Python的语句</title>
    <link href="/2021/12/01/Python%E7%9A%84%E8%AF%AD%E5%8F%A5/"/>
    <id>/2021/12/01/Python的语句/</id>
    <published>2021-12-01T05:35:00.000Z</published>
    <updated>2021-12-01T10:21:30.955Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Python的语句"><a href="#Python的语句" class="headerlink" title="Python的语句"></a>Python的语句</h1><h2 id="条件控制语句"><a href="#条件控制语句" class="headerlink" title="条件控制语句"></a>条件控制语句</h2><h3 id="if语句"><a href="#if语句" class="headerlink" title="if语句"></a>if语句</h3><pre><code class="python">if condition_1:    statement_1elif condition_2:    statement_2else:    statement_3</code></pre><h3 id="match语句"><a href="#match语句" class="headerlink" title="match语句"></a>match语句</h3><h2 id="循环语句"><a href="#循环语句" class="headerlink" title="循环语句"></a>循环语句</h2><h3 id="for-循环"><a href="#for-循环" class="headerlink" title="for 循环"></a>for 循环</h3><pre><code class="python">for i in range(n):    statement_1else:    statement_2</code></pre><h3 id="while-循环"><a href="#while-循环" class="headerlink" title="while 循环"></a>while 循环</h3><pre><code class="python">while condition:    statement_1else:    statement_2</code></pre><h3 id="break语句和continue语句"><a href="#break语句和continue语句" class="headerlink" title="break语句和continue语句"></a>break语句和continue语句</h3><pre><code class="python">for i in range(n):    if condition:        statement_1        continue    else:        statement_2        break</code></pre><h3 id="pass语句"><a href="#pass语句" class="headerlink" title="pass语句"></a>pass语句</h3><pre><code class="python">while condition:    statement_1    pass</code></pre><h2 id="异常语句"><a href="#异常语句" class="headerlink" title="异常语句"></a>异常语句</h2><h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><pre><code class="python">try:    statement_1except XxxError:    statement_2else:    statement_3finally:    statement_4</code></pre><h3 id="触发异常"><a href="#触发异常" class="headerlink" title="触发异常"></a>触发异常</h3><pre><code class="python">assert condition</code></pre><pre><code class="python">if not condition:    raise XxxError</code></pre><p>当 XxxError 为 AssertionError 时，上述两者等价。 </p><h2 id="命名空间和作用域"><a href="#命名空间和作用域" class="headerlink" title="命名空间和作用域"></a>命名空间和作用域</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Python的语句&quot;&gt;&lt;a href=&quot;#Python的语句&quot; class=&quot;headerlink&quot; title=&quot;Python的语句&quot;&gt;&lt;/a&gt;Python的语句&lt;/h1&gt;&lt;h2 id=&quot;条件控制语句&quot;&gt;&lt;a href=&quot;#条件控制语句&quot; class=&quot;head
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="python" scheme="/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>我的装机单</title>
    <link href="/2021/12/01/%E6%88%91%E7%9A%84%E8%A3%85%E6%9C%BA%E5%8D%95/"/>
    <id>/2021/12/01/我的装机单/</id>
    <published>2021-12-01T04:28:00.000Z</published>
    <updated>2021-12-03T10:11:02.207Z</updated>
    
    <content type="html"><![CDATA[<h1 id="我的装机单"><a href="#我的装机单" class="headerlink" title="我的装机单"></a>我的装机单</h1><table><thead><tr><th style="text-align:center">配件</th><th style="text-align:center">型号</th><th style="text-align:center">价格</th></tr></thead><tbody><tr><td style="text-align:center">CPU</td><td style="text-align:center">AMD 5900X</td><td style="text-align:center">3000</td></tr><tr><td style="text-align:center">GPU</td><td style="text-align:center">影驰 金属大师 RTX3070</td><td style="text-align:center">3900</td></tr><tr><td style="text-align:center">主板</td><td style="text-align:center">技嘉 X570 AORUS PRO WIFI</td><td style="text-align:center">1500</td></tr><tr><td style="text-align:center">内存</td><td style="text-align:center">金士顿 FURY 16GB DDR4 3200 * 2</td><td style="text-align:center">400 * 2</td></tr><tr><td style="text-align:center">SSD</td><td style="text-align:center">三星 980 1T * 2</td><td style="text-align:center">750 * 2</td></tr><tr><td style="text-align:center">CPU散热</td><td style="text-align:center">九州风神 大霜塔 PRO</td><td style="text-align:center">150</td></tr><tr><td style="text-align:center">电源</td><td style="text-align:center">酷冷至尊 GX750 金牌全模组</td><td style="text-align:center">500</td></tr><tr><td style="text-align:center">机箱</td><td style="text-align:center">酷冷至尊 S600 清风侠</td><td style="text-align:center">320</td></tr><tr><td style="text-align:center">晒单返E卡</td><td style="text-align:center"></td><td style="text-align:center">-300</td></tr><tr><td style="text-align:center">合计</td><td style="text-align:center"></td><td style="text-align:center">11370</td></tr></tbody></table><p><del>给孩子买来上网课的，孩子用了很喜欢。</del></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;我的装机单&quot;&gt;&lt;a href=&quot;#我的装机单&quot; class=&quot;headerlink&quot; title=&quot;我的装机单&quot;&gt;&lt;/a&gt;我的装机单&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;配件&lt;/th&gt;
&lt;t
      
    
    </summary>
    
      <category term="生活" scheme="/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="彩音之选" scheme="/tags/%E5%BD%A9%E9%9F%B3%E4%B9%8B%E9%80%89/"/>
    
  </entry>
  
  <entry>
    <title>CS224N - 语言模型</title>
    <link href="/2021/11/26/CS224N%20-%20%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    <id>/2021/11/26/CS224N - 语言模型/</id>
    <published>2021-11-26T11:50:00.000Z</published>
    <updated>2021-12-03T16:43:36.940Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CS224N-语言模型"><a href="#CS224N-语言模型" class="headerlink" title="CS224N - 语言模型"></a>CS224N - 语言模型</h1><p>## </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CS224N-语言模型&quot;&gt;&lt;a href=&quot;#CS224N-语言模型&quot; class=&quot;headerlink&quot; title=&quot;CS224N - 语言模型&quot;&gt;&lt;/a&gt;CS224N - 语言模型&lt;/h1&gt;&lt;p&gt;## &lt;/p&gt;

      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="NLP" scheme="/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>CS224N - 单词的含义表示</title>
    <link href="/2021/11/23/CS224N%20-%20%E5%8D%95%E8%AF%8D%E7%9A%84%E5%90%AB%E4%B9%89%E8%A1%A8%E7%A4%BA/"/>
    <id>/2021/11/23/CS224N - 单词的含义表示/</id>
    <published>2021-11-23T11:00:00.000Z</published>
    <updated>2021-11-26T07:21:55.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Lecture-1"><a href="#Lecture-1" class="headerlink" title="Lecture 1"></a>Lecture 1</h1><h2 id="1-单词的含义表示"><a href="#1-单词的含义表示" class="headerlink" title="1 单词的含义表示"></a>1 单词的含义表示</h2><h3 id="1-1-单词的数据库-WordNet"><a href="#1-1-单词的数据库-WordNet" class="headerlink" title="1.1 单词的数据库 - WordNet"></a>1.1 单词的数据库 - WordNet</h3><p>待解决问题：如何表示单词的含义</p><p>描述：WordNet® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. </p><p>优点：</p><ol><li>词性标注</li><li>同义归类</li><li>词间关系</li></ol><p>缺点：</p><ol><li>缺少语境</li><li>缺少新的词汇和已有词汇的新含义</li><li>依赖人工标注</li><li>无法计算单词相似度（无法向量化）</li></ol><h3 id="1-2-单词的稀疏向量表示-One-hot-Vector"><a href="#1-2-单词的稀疏向量表示-One-hot-Vector" class="headerlink" title="1.2 单词的稀疏向量表示 - One-hot Vector"></a>1.2 单词的稀疏向量表示 - One-hot Vector</h3><p>待解决问题：如何表示单词的含义</p><p>描述：在传统NLP中，我们将不同的单词视为独立的个体。我们可以用 one-hot 编码的形式去表示他们，如下所示。向量的维度将会是词汇量的大小。</p><p>motel = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]<br>hotel = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</p><p>缺点：</p><ol><li>one-hot 编码的向量都是正交的，无法计算相似度。</li></ol><h3 id="1-3-单词的稠密向量表示-Word-Vector"><a href="#1-3-单词的稠密向量表示-Word-Vector" class="headerlink" title="1.3 单词的稠密向量表示 - Word Vector"></a>1.3 单词的稠密向量表示 - Word Vector</h3><p>待解决问题：如何表示单词的含义-如何计算单词相似度</p><p>分布式语义：假设一个单词的含义取决于其高频出现的上下文。</p><p>描述：通过多个含有单词 w 的上下文建立起单词 w 的表示。这个表示是一个稠密向量，可被称为词表示或者词嵌入，这是一种分布式表示。</p><p>优点：</p><ol><li>在这种分布式语义中，所得到的稠密向量可以用于计算单词相似度，即在向量空间上同义词距离近，反义词距离远。</li></ol><h3 id="1-4-Word-Vector-的具体实现-word2vec"><a href="#1-4-Word-Vector-的具体实现-word2vec" class="headerlink" title="1.4 Word Vector 的具体实现 - word2vec"></a>1.4 Word Vector 的具体实现 - word2vec</h3><p>待解决问题：如何表示单词的含义-如何计算单词相似度</p><p>描述：</p><ol><li>根据 word vector 的思想，我们将基于上下文用稠密向量表示一个单词，这样可以在表示单词含义的同时保留单词之间的相关性信息。</li><li>对于我们的语料库中任意位置的单词 c（center），有上下文单词集合 o（outside）。</li><li>用单词 c 以及上下文单词集合 o 中的单词的 word vector 的相似度去计算 p(c | o) 以及 p(o | c)。同一单词，对于出现在上下文中的该单词以及出现在 center 位的该单词，我们用两个向量 <strong>*1</strong> 分别表示。</li><li>调整各单词的词向量使概率最大。</li></ol><p><strong>*1</strong> 可以使用单个向量表示，但对于同一单词同时出现在 center 和上下文，会出现 $ x^{T}x $ 的情况，会增加梯度下降难度。</p><p>损失函数：<br>$$<br>\begin{equation}<br>J(\theta)=-\frac{1}{T} \sum_{t=1}^{T} \sum_{-m \leq j \leq m \atop j \neq 0} \log P\left(w_{t+j} \mid w_{t} ; \theta\right)<br>\end{equation}<br>$$<br>损失函数会计算每一个位置 t 周围的 2m 个单词出现的概率。损失函数越小，概率越大。</p><p>条件概率：<br>$$<br>\begin{equation}<br>P(o \mid c)=\frac{\exp \left(u_{o}^{T} v_{c}\right)}{\sum_{w \in V} \exp \left(u_{w}^{T} v_{c}\right)}<br>\end{equation}<br>$$</p><p>条件概率的计算中，对上下文单词和中心单词词向量的点乘做了softmax正则化，即对于同一个中心单词，上下文单词词向量与中心单词词向量的点乘结果越大，其条件概率占整个上下文单词概率空间的比重越多。</p><p>优点：</p><ol><li>模型可以继承 <strong>1.3 单词的稠密向量表示 - Word Vector</strong> 的思路进行自我迭代。</li><li>迭代后得到的词向量能够计算单词相似度，且单词之间一定程度上具有自然语言的逻辑叠加性质，即经典示例 $ V_{king} - V_{man} + V_{woman} = V_{queen} $</li></ol><h1 id="Lecture-2"><a href="#Lecture-2" class="headerlink" title="Lecture 2"></a>Lecture 2</h1><h2 id="1-单词的含义表示-1"><a href="#1-单词的含义表示-1" class="headerlink" title="1 单词的含义表示"></a>1 单词的含义表示</h2><h3 id="1-5-word2vec-的两种形式-Skip-grams-和-Continuous-Bag-of-Words"><a href="#1-5-word2vec-的两种形式-Skip-grams-和-Continuous-Bag-of-Words" class="headerlink" title="1.5 word2vec 的两种形式 - Skip-grams 和 Continuous Bag of  Words"></a>1.5 word2vec 的两种形式 - Skip-grams 和 Continuous Bag of  Words</h3><p>待解决问题：如何表示单词的含义-如何计算单词相似度</p><p>word2vec 的两种形式：</p><ol><li>Skip-grams：给出中心单词预测上下文单词。（常见）</li><li>CBoW：给出上下文预测中心单词。</li></ol><h3 id="1-6-word2vec-的高效实现-Negative-Sampling"><a href="#1-6-word2vec-的高效实现-Negative-Sampling" class="headerlink" title="1.6 word2vec 的高效实现 - Negative Sampling"></a>1.6 word2vec 的高效实现 - Negative Sampling</h3><p>待解决问题：如何表示单词的含义-如何计算单词相似度-如何提高 word2vec 损失函数计算效率</p><p>描述：</p><p>在 <strong>1.4 Word Vector 的具体实现 - word2vec</strong> 中给出的条件概率计算方式在单词维度很大的时候，计算开销极大。在实际操作中使用随机负采样单词和中心单词配对，提升上下文单词词向量与中心单词词向量的点乘大小，降低随机采样单词与中心单词的点乘大小。</p><p>损失函数：<br>$$<br>J(\theta)=\frac{1}{T} \sum_{t=1}^{T} J_{t}(\theta)<br>$$<br>其中，<br>$$<br>J_{t}(\theta)=-\log \sigma(u_{o}^{T} v_{c})-\sum_{i=1}^{k} E_{j \sim P(w)}[\log \sigma(-u_{j}^{T} v_{c})]<br>$$</p><p>$$<br>\sigma(x)=\frac{1}{1+e^{-x}}<br>$$</p><p>损失函数的第一部分，上下文单词词向量与中心单词词向量点乘越大，损失函数越小。损失函数第二部分，随机负采样的k个单词的词向量与中心单词词向量点乘越小损失函数越小。</p><p>优点：</p><ol><li>相比原先的softmax需要在每次条件概率中计算整个单词表，负采样后的损失函数只需要计算上下文单词和经过随机负采样选出的单词，计算开销大幅下降。</li></ol><h3 id="1-7-Word-Vector-的简单实现-共现矩阵"><a href="#1-7-Word-Vector-的简单实现-共现矩阵" class="headerlink" title="1.7 Word Vector 的简单实现 - 共现矩阵"></a>1.7 Word Vector 的简单实现 - 共现矩阵</h3><p>待解决问题：如何表示单词的含义-如何计算单词相似度</p><p>描述：</p><p>通过单词间相邻次数（出现在对方相邻 n 个单词中的次数）构建整个词汇表中单词间的共现矩阵，并用矩阵的 行向量/列向量 表示该单词。</p><p>示例（语料库）：</p><ol><li>I like deep learning. </li><li>I like NLP.</li><li>I enjoy flying.</li></ol><table><thead><tr><th style="text-align:center">出现次数</th><th style="text-align:center">I</th><th style="text-align:center">like</th><th style="text-align:center">enjoy</th><th style="text-align:center">deep</th><th style="text-align:center">learning</th><th style="text-align:center">NLP</th><th style="text-align:center">flying</th><th style="text-align:center">.</th></tr></thead><tbody><tr><td style="text-align:center">I</td><td style="text-align:center">0</td><td style="text-align:center">2</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">like</td><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">enjoy</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">deep</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">learning</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">NLP</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">flying</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">.</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr></tbody></table><p>各单词对应词向量：</p><table><thead><tr><th style="text-align:center">单词</th><th style="text-align:center">向量</th></tr></thead><tbody><tr><td style="text-align:center">I</td><td style="text-align:center">[0, 2, 1, 0, 0, 0, 0, 0]</td></tr><tr><td style="text-align:center">like</td><td style="text-align:center">[2, 0, 0, 1, 0, 1, 0, 0]</td></tr><tr><td style="text-align:center">enjoy</td><td style="text-align:center">[1, 0, 0, 0, 0, 0, 1, 0]</td></tr><tr><td style="text-align:center">deep</td><td style="text-align:center">[0, 1, 0, 0, 1, 0, 0, 0]</td></tr><tr><td style="text-align:center">learning</td><td style="text-align:center">[0, 0, 0, 1, 0, 0, 0, 1]</td></tr><tr><td style="text-align:center">NLP</td><td style="text-align:center">[0, 1, 0, 0, 0, 0, 0, 1]</td></tr><tr><td style="text-align:center">flying</td><td style="text-align:center">[0, 0, 1, 0, 0, 0, 0, 1]</td></tr><tr><td style="text-align:center">.</td><td style="text-align:center">[0, 0, 0, 0, 1, 1, 1, 0]</td></tr></tbody></table><p>最终，根据上下文单词出现的频率，相似的单词（词法/含义 相似）会具有高相似度的词向量。</p><p>优点：</p><ol><li>实现逻辑简单，不需要训练。</li></ol><p>缺点：</p><ol><li>空间占用高，随着词汇量增大而增大。（解决方法：数学降维方法 / 预处理词库）</li></ol><h3 id="1-8-GloVe-共现矩阵和word2vec的结合"><a href="#1-8-GloVe-共现矩阵和word2vec的结合" class="headerlink" title="1.8 GloVe - 共现矩阵和word2vec的结合"></a>1.8 GloVe - 共现矩阵和word2vec的结合</h3><p>待解决问题：如何表示单词的含义-如何计算单词相似度-如何建立一个时空高效且效果好的模型</p><p>现有模型优缺点：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">共现矩阵</th><th style="text-align:center">word2vec</th></tr></thead><tbody><tr><td style="text-align:center">特点</td><td style="text-align:center">基于单词出现次数</td><td style="text-align:center">基于概率预测</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">优点</td><td style="text-align:center">基于统计学，无需训练，时间高效</td><td style="text-align:center">能够捕捉单词相似度之外的复杂特征</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">能在 downstream 任务中获得更好的效果</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">缺点</td><td style="text-align:center">仅可用于捕捉单词相似度</td><td style="text-align:center">随着语料库的增加，训练过程耗时加长，效率降低</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">对高频词汇分配了过多的权重</td></tr></tbody></table><p>GloVe核心思想：</p><ol><li>通过共现概率之比编码一些有用信息</li><li>用词向量点乘拟合共现概率</li></ol><table><thead><tr><th style="text-align:center">$ x =  $</th><th style="text-align:center">$ solid $</th><th style="text-align:center">$ gas $</th><th style="text-align:center">$ water $</th><th style="text-align:center">$ random $</th></tr></thead><tbody><tr><td style="text-align:center">$ \begin{equation}P(x&#124;ice)\end{equation} $</td><td style="text-align:center">高</td><td style="text-align:center">低</td><td style="text-align:center">高</td><td style="text-align:center">低</td></tr><tr><td style="text-align:center">$ P(x&#124;steam) $</td><td style="text-align:center">低</td><td style="text-align:center">高</td><td style="text-align:center">高</td><td style="text-align:center">低</td></tr><tr><td style="text-align:center">$ \frac{P(x&#124;ice)}{P(x&#124;steam)} $</td><td style="text-align:center">高</td><td style="text-align:center">低</td><td style="text-align:center">~1</td><td style="text-align:center">~1</td></tr></tbody></table><ul><li><code>&amp;#124;</code> 可用于转义 <code>|</code> 。</li></ul><p>共现概率之比可以编码一些成分信息（类比），如 $ V_{king} - V_{man} + V_{woman} = V_{queen} $</p><p>为了在训练中使得向量具有这种可叠加的特点，我们让词向量点乘拟合共现概率。<br>$$<br>w_{i} \cdot w_{j}=\log P(i \mid j) \tag{1}<br>$$</p><p>$$<br>w_{x} \cdot\left(w_{a}-w_{b}\right)=\log \frac{P(x \mid a)}{P(x \mid b)}\tag{2}<br>$$</p><p>通过 <strong>公式1</strong> 对于共现概率的拟合，词向量将拥有 <strong>公式2</strong> 的可叠加性，并将共现概率之比的信息保留在词向量中。</p><p>损失函数：<br>$$<br>J=\sum_{i, j=1}^{V} f(X_{i j})(w_{i}^{T} w_{j}+b_{i}+b_{j}-\log X_{i j})^{2}<br>$$</p><p>$ f(x) $ 是一个权重函数：<br>$$<br>\begin{equation}<br>f(x) =<br>\begin{cases}<br>(x / x_{\max })^{\alpha} &amp; \text { if } x&lt;x_{\max }<br>\newline 1 &amp; \text { otherwise }<br>\end{cases}<br>\end{equation}<br>$$<br>其中，$ x_{\max } $ 是共现次数的最大值，$ \alpha $ 的典型值为 $ \frac{3}{4} $ 。我们希望给予高频共现单词对更高的权重，但不像 <strong>1.7 Word Vector 的简单实现 - 共现矩阵</strong> 中高频共现词汇对那样过高的权重。</p><h3 id="1-9-如何评价-Word-Vector-的好坏？"><a href="#1-9-如何评价-Word-Vector-的好坏？" class="headerlink" title="1.9 如何评价 Word Vector 的好坏？"></a>1.9 如何评价 Word Vector 的好坏？</h3><ol><li><p>Intrinsic Evaluation：基于直接的词汇对，如 <strong>比较级 / 过去式</strong>。</p></li><li><p>Extrinsic Evaluation：基于真实的任务场景，如 <strong>命名实体识别</strong>。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Lecture-1&quot;&gt;&lt;a href=&quot;#Lecture-1&quot; class=&quot;headerlink&quot; title=&quot;Lecture 1&quot;&gt;&lt;/a&gt;Lecture 1&lt;/h1&gt;&lt;h2 id=&quot;1-单词的含义表示&quot;&gt;&lt;a href=&quot;#1-单词的含义表示&quot; class
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="NLP" scheme="/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Python的内置类型</title>
    <link href="/2021/11/17/Python%E7%9A%84%E5%86%85%E7%BD%AE%E7%B1%BB%E5%9E%8B/"/>
    <id>/2021/11/17/Python的内置类型/</id>
    <published>2021-11-17T03:46:00.000Z</published>
    <updated>2021-11-26T07:32:12.378Z</updated>
    
    <content type="html"><![CDATA[<ul><li>本文参考<br>[1] <a href="https://docs.python.org/zh-cn/3/" target="_blank" rel="noopener">官方 Python3 教程</a><br>[2] <a href="https://www.runoob.com/python3/python3-tutorial.html" target="_blank" rel="noopener">RUNOOB Python3 教程</a></li></ul><h1 id="Python的内置类型"><a href="#Python的内置类型" class="headerlink" title="Python的内置类型"></a>Python的内置类型</h1><h2 id="逻辑值"><a href="#逻辑值" class="headerlink" title="逻辑值"></a>逻辑值</h2><ol><li>被定义为假值的常量: <code>None</code> 和 <code>False</code>。</li><li>任何数值类型的零: <code>0</code>, <code>0.0</code>, <code>0j</code>, <code>Decimal(0)</code>, <code>Fraction(0, 1)</code></li><li>空的序列和多项集: <code>&#39;&#39;</code>, <code>()</code>, <code>[]</code>, <code>{}</code>, <code>set()</code>, <code>range(0)</code></li></ol><h2 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h2><table><thead><tr><th style="text-align:center">逻辑运算</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">x or y</td><td style="text-align:center">或</td></tr><tr><td style="text-align:center">x and y</td><td style="text-align:center">与</td></tr><tr><td style="text-align:center">not x</td><td style="text-align:center">非</td></tr></tbody></table><h2 id="比较运算"><a href="#比较运算" class="headerlink" title="比较运算"></a>比较运算</h2><table><thead><tr><th style="text-align:center">比较运算</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">&lt;</td><td style="text-align:center">严格小于</td></tr><tr><td style="text-align:center">&lt;=</td><td style="text-align:center">小于等于</td></tr><tr><td style="text-align:center">&gt;</td><td style="text-align:center">严格大于</td></tr><tr><td style="text-align:center">&gt;=</td><td style="text-align:center">大于等于</td></tr><tr><td style="text-align:center">==</td><td style="text-align:center">等于</td></tr><tr><td style="text-align:center">!=</td><td style="text-align:center">不等于</td></tr></tbody></table><h2 id="成员运算及身份运算"><a href="#成员运算及身份运算" class="headerlink" title="成员运算及身份运算"></a>成员运算及身份运算</h2><table><thead><tr><th style="text-align:center">运算</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">in</td><td style="text-align:center">包含于</td></tr><tr><td style="text-align:center">not in</td><td style="text-align:center">不包含于</td></tr><tr><td style="text-align:center">is</td><td style="text-align:center">相同对象</td></tr><tr><td style="text-align:center">is not</td><td style="text-align:center">不相同对象</td></tr></tbody></table><pre><code class="python">&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = a&gt;&gt;&gt; b == aTrue&gt;&gt;&gt; b is aTrue&gt;&gt;&gt; b = a[:]&gt;&gt;&gt; b == aTrue&gt;&gt;&gt; b is aFalse</code></pre><ol><li><code>b = a</code> 中，列表的赋值采用的是引用赋值，两者不光数值相同，指针指向也相同。其中之一的列表元素发生改变，另一个也会跟着改变。此时，a 和 b 为相同对象。</li><li><code>b = a[:]</code> 中，<code>[:]</code> 表示只取值，此时列表的赋值只是单纯的复制了数值，两者的数值虽然相同，但指针指向不同。其中之一的列表元素发生改变，另一个不会跟着改变。此时，a 和 b 为不同对象。</li></ol><h2 id="数字类型及运算符"><a href="#数字类型及运算符" class="headerlink" title="数字类型及运算符"></a>数字类型及运算符</h2><h3 id="数字类型"><a href="#数字类型" class="headerlink" title="数字类型"></a>数字类型</h3><ol><li>int<br><code>x = 5</code></li><li>float<br><code>x = 5.0</code></li><li>complex<br><code>x = 5 + 5.0j</code></li></ol><pre><code class="python">&gt;&gt;&gt; x = []&gt;&gt;&gt; x.append(5);x.append(5.1);x.append(5+5.1j)&gt;&gt;&gt; x[5, 5.1, (5+5.1j)]</code></pre><h3 id="数字运算"><a href="#数字运算" class="headerlink" title="数字运算"></a>数字运算</h3><table><thead><tr><th style="text-align:center">数字运算</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">x + y</td><td style="text-align:center">加</td></tr><tr><td style="text-align:center">x - y</td><td style="text-align:center">减</td></tr><tr><td style="text-align:center">x * y</td><td style="text-align:center">乘</td></tr><tr><td style="text-align:center">x / y</td><td style="text-align:center">除</td></tr><tr><td style="text-align:center">x // y</td><td style="text-align:center">整除（向下取整）</td></tr><tr><td style="text-align:center">x % y</td><td style="text-align:center">取余</td></tr><tr><td style="text-align:center">x ** y</td><td style="text-align:center">x 的 y 次幂</td></tr><tr><td style="text-align:center">pow(x, y)</td><td style="text-align:center">x 的 y 次幂</td></tr><tr><td style="text-align:center">abs(x)</td><td style="text-align:center">取绝对值</td></tr><tr><td style="text-align:center">int()</td><td style="text-align:center">整数强制类型转换</td></tr><tr><td style="text-align:center">float()</td><td style="text-align:center">浮点数强制类型转换</td></tr><tr><td style="text-align:center">complex(real, imag)</td><td style="text-align:center">复数</td></tr><tr><td style="text-align:center">divmod(x, y)</td><td style="text-align:center">(x // y, x % y)</td></tr><tr><td style="text-align:center">round(x[, n])</td><td style="text-align:center">将x保留n位小数（四舍五入）</td></tr><tr><td style="text-align:center">math.floor(x)</td><td style="text-align:center">&lt;=x的最大整数</td></tr><tr><td style="text-align:center">math.ceil(x)</td><td style="text-align:center">&gt;=x的最小整数</td></tr></tbody></table><h3 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h3><table><thead><tr><th style="text-align:center">位运算</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">x</td><td style="text-align:center">y</td></tr><tr><td style="text-align:center">x ^ y</td><td style="text-align:center">按位异或</td></tr><tr><td style="text-align:center">x &amp; y</td><td style="text-align:center">按位与</td></tr><tr><td style="text-align:center">x &lt;&lt; n</td><td style="text-align:center">左移n位</td></tr><tr><td style="text-align:center">x &gt;&gt; n</td><td style="text-align:center">右移n位</td></tr><tr><td style="text-align:center">~x</td><td style="text-align:center">按位取反</td></tr></tbody></table><h2 id="序列类型"><a href="#序列类型" class="headerlink" title="序列类型"></a>序列类型</h2><h3 id="通用序列操作"><a href="#通用序列操作" class="headerlink" title="通用序列操作"></a>通用序列操作</h3><table><thead><tr><th style="text-align:center">通用序列操作</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">x in s</td><td style="text-align:center">如果 s 中的某项等于 x 则结果为 True，否则为 False</td></tr><tr><td style="text-align:center">x not in s</td><td style="text-align:center">如果 s 中的某项等于 x 则结果为 False，否则为 True</td></tr><tr><td style="text-align:center">s + t</td><td style="text-align:center">s 与 t 相拼接</td></tr><tr><td style="text-align:center">s * n</td><td style="text-align:center">相当于 s 与自身进行 n 次拼接</td></tr><tr><td style="text-align:center">s[i]</td><td style="text-align:center">s 的第 i 项，起始为 0</td></tr><tr><td style="text-align:center">s[i:j]</td><td style="text-align:center">s 从 i 到 j 的切片</td></tr><tr><td style="text-align:center">s[i:j:step]</td><td style="text-align:center">s 从 i 到 j 步长为 k 的切片</td></tr><tr><td style="text-align:center">len(s)</td><td style="text-align:center">s 的长度</td></tr><tr><td style="text-align:center">min(s)</td><td style="text-align:center">s 的最小项</td></tr><tr><td style="text-align:center">max(s)</td><td style="text-align:center">s 的最大项</td></tr><tr><td style="text-align:center">s.index(x[, i[, j]])</td><td style="text-align:center">x 在 s 中首次出现项的索引号（索引号在 i 或其后且在 j 之前）</td></tr><tr><td style="text-align:center">s.count(x)</td><td style="text-align:center">x 在 s 中出现的总次数</td></tr></tbody></table><h3 id="可变序列操作"><a href="#可变序列操作" class="headerlink" title="可变序列操作"></a>可变序列操作</h3><table><thead><tr><th style="text-align:center">可变序列操作</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">s[i] = x</td><td style="text-align:center">将 s 的第 i 项替换为 x</td></tr><tr><td style="text-align:center">s[i:j] = t</td><td style="text-align:center">将 s 从 i 到 j 的切片替换为可迭代对象 t 的内容</td></tr><tr><td style="text-align:center">del s[i:j]</td><td style="text-align:center">等同于 s[i:j] = []</td></tr><tr><td style="text-align:center">s.append(x)</td><td style="text-align:center">将 x 添加到序列的末尾 (等同于 s[len(s):len(s)] = [x])</td></tr><tr><td style="text-align:center">s.clear()</td><td style="text-align:center">从 s 中移除所有项 (等同于 del s[:])</td></tr><tr><td style="text-align:center">s.copy()</td><td style="text-align:center">创建 s 的浅拷贝 (等同于 s[:])</td></tr><tr><td style="text-align:center">s.extend(t)</td><td style="text-align:center">用 t 的内容扩展 s (基本上等同于 s[len(s):len(s)] = t)</td></tr><tr><td style="text-align:center">s.insert(i, x)</td><td style="text-align:center">在由 i 给出的索引位置将 x 插入 s (等同于 s[i:i] = [x])</td></tr><tr><td style="text-align:center">s.pop(*[, i])</td><td style="text-align:center">提取在 i 位置上的项，并将其从 s 中移除</td></tr><tr><td style="text-align:center">s.remove(x)</td><td style="text-align:center">删除 s 中第一个 s[i] 等于 x 的项目。</td></tr><tr><td style="text-align:center">s.reverse()</td><td style="text-align:center">就地将列表中的元素逆序。</td></tr></tbody></table><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><p>列表是可变序列，通常用于存放同类项目的集合（其中精确的相似程度将根据应用而变化）。</p><p><code>class list([iterable])</code><br>可以用多种方式构建列表：</p><ol><li>使用一对方括号来表示空列表: <code>[]</code></li><li>使用方括号，其中的项以逗号分隔: <code>[a]</code> / <code>[a, b, c]</code></li><li>使用列表推导式: <code>[x for _ in iterable]</code></li><li>使用类型的构造器: <code>list()</code> / <code>list(iterable)</code></li></ol><p><code>list.sort(\*, key=None, reverse=False)</code><br>此方法会对列表进行原地排序，保证稳定。</p><pre><code class="python">&gt;&gt;&gt; list = [1, 5, 3, 4, 6, 2]&gt;&gt;&gt; list.sort()&gt;&gt;&gt; list[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; list = [[1, 5, 3], [4, 6, 2]]&gt;&gt;&gt; list.sort(key=lambda x:x[2])&gt;&gt;&gt; list[[4, 6, 2], [1, 5, 3]]</code></pre><h3 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h3><p>元组是不可变序列，通常用于储存异构数据的多项集（例如由 <code>enumerate()</code> 内置函数所产生的二元组）。 元组也被用于需要同构数据的不可变序列的情况（例如允许存储到 set 或 dict 的实例）。</p><p><code>class tuple([iterable])</code><br>可以用多种方式构建元组：</p><ol><li>使用一对圆括号来表示空元组: <code>()</code></li><li>使用一个后缀的逗号来表示单元组: <code>a,</code> / <code>(a,)</code></li><li>使用以逗号分隔的多个项: <code>a, b, c</code> / <code>(a, b, c)</code></li><li>使用内置的tuple(): <code>tuple()</code> / <code>tuple(iterable)</code></li></ol><h3 id="range-对象"><a href="#range-对象" class="headerlink" title="range 对象"></a>range 对象</h3><p>range 类型表示不可变的数字序列，通常用于在 for 循环中循环指定的次数。</p><p><code>class range(stop)</code><br><code>class range(start, stop[, step])</code><br>range 构造器的参数必须为整数。 </p><ol><li>如果省略 step 参数，其默认值为 1。 </li><li>如果省略 start 参数，其默认值为 0。</li><li>如果 step 为零则会引发 ValueError。</li></ol><pre><code class="python">&gt;&gt;&gt; list(range(10))[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; list(range(1, 11))[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&gt;&gt;&gt; list(range(0, 30, 5))[0, 5, 10, 15, 20, 25]&gt;&gt;&gt; list(range(0, 10, 3))[0, 3, 6, 9]&gt;&gt;&gt; list(range(0, -10, -1))[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]&gt;&gt;&gt; list(range(0))[]&gt;&gt;&gt; list(range(1, 0))[]</code></pre><h3 id="文本序列类型"><a href="#文本序列类型" class="headerlink" title="文本序列类型"></a>文本序列类型</h3><p>在 Python 中处理文本数据是使用 str 对象，也称为 字符串。<br>字符串是由 Unicode 码位构成的不可变序列。</p><p><code>class str(object=&#39;&#39;)</code><br><code>class str(object=b&#39;&#39;, encoding=&#39;utf-8&#39;, errors=&#39;strict&#39;)</code><br>可以用多种方式构建：</p><ol><li>使用引号：<code>&#39;&#39;</code> /<code>&quot;&quot;</code> /<code>&#39;&#39;&#39; &#39;&#39;&#39;</code> / <code>&quot;&quot;&quot; &quot;&quot;&quot;</code></li><li>使用内置的str()：<code>str()</code> / <code>str(object)</code></li><li>使用raw禁止转义：<code>r&#39;\n&#39;</code></li></ol><table><thead><tr><th style="text-align:center">str的方法</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">str.capitalize()</td><td style="text-align:center">将str首字母大写</td></tr><tr><td style="text-align:center">str.find(s)</td><td style="text-align:center">检测字符串s是否在str中，真返回True，假返回False</td></tr><tr><td style="text-align:center">str.is?()</td><td style="text-align:center">检查str是否为?，真返回True，假返回False</td></tr><tr><td style="text-align:center">str.join(s)</td><td style="text-align:center">以str为分割，将s中的元素合并为一个新的字符串</td></tr><tr><td style="text-align:center">str.lower() / str.upper()</td><td style="text-align:center">将str全部字符转为小写/大写</td></tr><tr><td style="text-align:center">str.lstrip(s) / str.rstrip(s) / str.strip(s)</td><td style="text-align:center">将str 左侧/右侧/两侧 的字符串s去掉</td></tr><tr><td style="text-align:center">str.replace(old, new[, max])</td><td style="text-align:center">将str中的字符串old替换为new，最大次数为max</td></tr><tr><td style="text-align:center">str.split(sep, maxsplit=-1)</td><td style="text-align:center">将str以sep中的元素为基准进行分割，最多分割maxsplit次，得到maxsplit段</td></tr><tr><td style="text-align:center">str.startwith(startstr, beg=0, end=len(string))</td><td style="text-align:center">检查str是否在(beg, end)区间以startstr作为开头</td></tr><tr><td style="text-align:center">str.swapcase()</td><td style="text-align:center">将str的 大/小 写字母转换为 小/大 写字母</td></tr><tr><td style="text-align:center">str.title()</td><td style="text-align:center">将str中所有单词首字母大写</td></tr></tbody></table><p><code>str.is?()</code>：</p><table><thead><tr><th style="text-align:center">str.is?() 中的 ?</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">alnum</td><td style="text-align:center">是否只包含字母或数字</td></tr><tr><td style="text-align:center">alpha</td><td style="text-align:center">是否只包含字母</td></tr><tr><td style="text-align:center">digit</td><td style="text-align:center">是否只包含数字</td></tr><tr><td style="text-align:center">lower</td><td style="text-align:center">是否只包含小写字母（只考虑区分大小写的）</td></tr><tr><td style="text-align:center">numeric</td><td style="text-align:center">是否只包含数字字符</td></tr><tr><td style="text-align:center">space</td><td style="text-align:center">是否只包含空格</td></tr><tr><td style="text-align:center">upper</td><td style="text-align:center">是否只包含大写字母（只考虑区分大小写的）</td></tr></tbody></table><h3 id="字符串格式化"><a href="#字符串格式化" class="headerlink" title="字符串格式化"></a>字符串格式化</h3><p><a href="https://docs.python.org/zh-cn/3/library/string.html#formatstrings" target="_blank" rel="noopener">str.format()</a></p><h2 id="二进制序列类型（待补充）"><a href="#二进制序列类型（待补充）" class="headerlink" title="二进制序列类型（待补充）"></a>二进制序列类型（待补充）</h2><h2 id="集合类型-set-frozen"><a href="#集合类型-set-frozen" class="headerlink" title="集合类型 - set, frozen"></a>集合类型 - set, frozen</h2><p>set 对象是由具有唯一性的 hashable 对象所组成的无序多项集。常见的用途包括成员检测、从序列中去除重复项以及数学中的集合类计算，例如交集、并集、差集与对称差集等等。<br>目前有两种内置集合类型：set 和 frozenset。</p><ol><li>set 类型是可变的。其内容可以使用 <code>add()</code> 和 <code>remove()</code> 这样的方法来改变。由于是可变类型，它没有哈希值，且不能被用作字典的键或其他集合的元素。</li><li>frozenset 类型是不可变并且为 hashable 。其内容在被创建后不能再改变；因此它可以被用作字典的键或其他集合的元素。</li></ol><p><code>class set([iterable])</code><br><code>class frozenset([iterable])</code><br>返回一个新的 set 或 frozenset 对象，其元素来自于 iterable。集合的元素必须为 hashable 要表示由集合对象构成的集合，所有的内层集合必须为 frozenset 对象。如果未指定 iterable，则将返回一个新的空集合。<br>集合可用多种方式来创建：</p><ol><li>使用花括号内以逗号分隔元素的方式:<br><code>{&#39;jack&#39;, &#39;sjoerd&#39;}</code></li><li>使用集合推导式:<br><code>{c for c in &#39;abracadabra&#39; if c not in &#39;abc&#39;}</code></li><li>使用类型构造器:<br><code>set()</code> / <code>set(&#39;foobar&#39;)</code> / <code>set([&#39;a&#39;, &#39;b&#39;, &#39;foo&#39;])</code></li></ol><table><thead><tr><th style="text-align:center">set的操作</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">len(set)</td><td style="text-align:center">返回set中的元素数量</td></tr><tr><td style="text-align:center">element in set / element not in set</td><td style="text-align:center">判断element是否出现在set中</td></tr><tr><td style="text-align:center">set.add(element)</td><td style="text-align:center">将element加入set</td></tr><tr><td style="text-align:center">set.clear()</td><td style="text-align:center">清空set</td></tr><tr><td style="text-align:center">set.copy()</td><td style="text-align:center">返回set的浅拷贝</td></tr><tr><td style="text-align:center">setx.difference(sety)</td><td style="text-align:center">返回包含在setx但不包含在sety的元素</td></tr><tr><td style="text-align:center">set.discard(element)</td><td style="text-align:center">移除set中的指定element（element不存在不报错）</td></tr><tr><td style="text-align:center">set.intersection(set)</td><td style="text-align:center">返回两个集合的交集</td></tr><tr><td style="text-align:center">set.isjoint(set)</td><td style="text-align:center">判断两个集合是否有交集</td></tr><tr><td style="text-align:center">setx.issubset(sety)</td><td style="text-align:center">判断setx是否为sety的子集</td></tr><tr><td style="text-align:center">setx.issuperset(sety)</td><td style="text-align:center">判断setx是否为sety的父集</td></tr><tr><td style="text-align:center">set.pop()</td><td style="text-align:center">随机移除set中的元素，返回该元素</td></tr><tr><td style="text-align:center">set.remove(element)</td><td style="text-align:center">移除set中的指定element（element不存在报错）</td></tr><tr><td style="text-align:center">setx.symmetric_difference(sety)</td><td style="text-align:center">返回setx和sety中不重复的元素</td></tr><tr><td style="text-align:center">set.union(set)</td><td style="text-align:center">返回两个集合的并集</td></tr><tr><td style="text-align:center">setx.update(sety)</td><td style="text-align:center">将setx置为两个集合的并集</td></tr></tbody></table><h2 id="映射类型"><a href="#映射类型" class="headerlink" title="映射类型"></a>映射类型</h2><p>mapping 对象会将 hashable 值映射到任意对象。 映射属于可变对象。目前仅有一种标准映射类型 字典。<br>字典的键几乎可以是任何值。非 hashable 的值，即包含列表、字典或其他可变类型的值（此类对象基于值而非对象标识进行比较）不可用作键。数字类型用作键时遵循数字比较的一般规则：如果两个数值相等 (例如 1 和 1.0) 则两者可以被用来索引同一字典条目。</p><p><code>class dict(\*\*kwarg)</code><br><code>class dict(mapping, \*\*kwarg)</code><br><code>class dict(iterable, \*\*kwarg)</code><br>返回一个新的字典，基于可选的位置参数和可能为空的关键字参数集来初始化。<br>字典可用多种方式来创建：</p><ol><li>使用花括号内以逗号分隔 键: 值 对的方式: <code>{&#39;jack&#39;: 4098, &#39;sjoerd&#39;: 4127}</code> or <code>{4098: &#39;jack&#39;, 4127: &#39;sjoerd&#39;}</code></li><li>使用字典推导式: <code>{}</code>, <code>{x: x ** 2 for x in range(10)}</code></li><li>使用类型构造器: <code>dict()</code> / <code>dict([(&#39;foo&#39;, 100), (&#39;bar&#39;, 200)])</code> / <code>dict(foo=100, bar=200)</code></li></ol><table><thead><tr><th style="text-align:center">dict的操作</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">list(dict)</td><td style="text-align:center">返回dict所有key的列表</td></tr><tr><td style="text-align:center">len(dict)</td><td style="text-align:center">返回dict的长度</td></tr><tr><td style="text-align:center">dict[key]</td><td style="text-align:center">返回dict中key的value，若key不存在则报错</td></tr><tr><td style="text-align:center">dict[key] = value</td><td style="text-align:center">将key增加至dict中并赋值value</td></tr><tr><td style="text-align:center">del dict[key]</td><td style="text-align:center">移除dict中的key，若key不存在则报错</td></tr><tr><td style="text-align:center">key in dict / key not in dict</td><td style="text-align:center">判断key是否在dict中</td></tr><tr><td style="text-align:center">dict.clear()</td><td style="text-align:center">清空dict</td></tr><tr><td style="text-align:center">dict.copy()</td><td style="text-align:center">返回dict的浅拷贝</td></tr><tr><td style="text-align:center">dict.fromkeys(iterable[, value])</td><td style="text-align:center">通过iterable类型的元素建立列表</td></tr><tr><td style="text-align:center">dict.get(key[, default])</td><td style="text-align:center">如果key存在则返回key对应的value，如果key不存在则返回default的值，default默认为None</td></tr><tr><td style="text-align:center">dict.items()</td><td style="text-align:center">以((key, value), ( , ), …)的形式返回dict的键值对</td></tr><tr><td style="text-align:center">dict.keys()</td><td style="text-align:center">以视图对象dict_keys([key1, key2, …])的形式返回dict的keys</td></tr><tr><td style="text-align:center">dict.pop(key)</td><td style="text-align:center">返回dict中key的value，并将该key移除（key不存在则报错）</td></tr><tr><td style="text-align:center">dict.popitem()</td><td style="text-align:center">以LIFO（Last In First Out）顺序返回dict中key的value，并将其移除</td></tr><tr><td style="text-align:center">dict.values()</td><td style="text-align:center">以视图对象dict_values([value1, value2, …])的形式返回dict的values</td></tr></tbody></table><h3 id="字典视图对象"><a href="#字典视图对象" class="headerlink" title="字典视图对象"></a>字典视图对象</h3><p>由 <code>dict.keys()</code>, <code>dict.values()</code> 和 <code>dict.items()</code> 所返回的对象是 视图对象。该对象提供字典条目的一个动态视图，这意味着当字典改变时，视图也会相应改变。<br>可以使用 <code>list(dict.keys())</code> 将字典视图对象转换为list。</p><h2 id="上下文管理器类型（待补充）"><a href="#上下文管理器类型（待补充）" class="headerlink" title="上下文管理器类型（待补充）"></a>上下文管理器类型（待补充）</h2><p>Python 的 with 语句支持通过上下文管理器所定义的运行时上下文这一概念。此对象的实现使用了一对专门方法，允许用户自定义类来定义运行时上下文，在语句体被执行前进入该上下文，并在语句执行完毕时退出该上下文。<br>详情请参考 <a href="\">with 语句</a>。</p><h2 id="union类型（待补充）"><a href="#union类型（待补充）" class="headerlink" title="union类型（待补充）"></a>union类型（待补充）</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;本文参考&lt;br&gt;[1] &lt;a href=&quot;https://docs.python.org/zh-cn/3/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方 Python3 教程&lt;/a&gt;&lt;br&gt;[2] &lt;a href=&quot;https://www
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="python" scheme="/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>「突撃！南島原情報局」南岛原市宣传片字幕翻译</title>
    <link href="/2021/07/11/%E3%80%8C%E7%AA%81%E6%92%83%EF%BC%81%E5%8D%97%E5%B3%B6%E5%8E%9F%E6%83%85%E5%A0%B1%E5%B1%80%E3%80%8D%E5%8D%97%E5%B2%9B%E5%8E%9F%E5%B8%82%E5%AE%A3%E4%BC%A0%E7%89%87%E5%AD%97%E5%B9%95%E7%BF%BB%E8%AF%91/"/>
    <id>/2021/07/11/「突撃！南島原情報局」南岛原市宣传片字幕翻译/</id>
    <published>2021-07-11T08:30:38.000Z</published>
    <updated>2021-07-11T08:30:38.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="「突撃！南島原情報局」"><a href="#「突撃！南島原情報局」" class="headerlink" title="「突撃！南島原情報局」"></a>「突撃！南島原情報局」</h1><h2 id="作品简介"><a href="#作品简介" class="headerlink" title="作品简介"></a>作品简介</h2><p>日语宣传片的个人翻译练习。看到朋友搬运了这个视频感觉很有趣，就当作训练素材了（神经翻译系统训练ing）。这个宣传视频主要介绍了日本长崎县南岛原市的风光以及特产。</p><h2 id="突撃！南島原情報局【神回】"><a href="#突撃！南島原情報局【神回】" class="headerlink" title="突撃！南島原情報局【神回】"></a>突撃！南島原情報局【神回】</h2><div style="position: relative; width: 95%; height: 0; left: 2.5%; padding-bottom: 65%;"><br>    <iframe src="https://www.bilibili.com/blackboard/html5mobileplayer.html?aid=714134464&bvid=BV13X4y157GW&cid=362713060&page=1&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> </iframe><br></div><h2 id="勘误"><a href="#勘误" class="headerlink" title="勘误"></a>勘误</h2><p>有些地方把 <strong>一揆（いっき）</strong> 听成了 <strong>域（いき）</strong>。因为之前并不知道 <strong>一揆（いっき）</strong> 这个词，导致字幕里面有的地方翻译成了 <strong>地区</strong> 忘了改成 <strong>起义</strong>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;「突撃！南島原情報局」&quot;&gt;&lt;a href=&quot;#「突撃！南島原情報局」&quot; class=&quot;headerlink&quot; title=&quot;「突撃！南島原情報局」&quot;&gt;&lt;/a&gt;「突撃！南島原情報局」&lt;/h1&gt;&lt;h2 id=&quot;作品简介&quot;&gt;&lt;a href=&quot;#作品简介&quot; class=&quot;
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="日语" scheme="/tags/%E6%97%A5%E8%AF%AD/"/>
    
      <category term="翻译" scheme="/tags/%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>「先輩とみなみちゃん」JA共済CM合集字幕翻译</title>
    <link href="/2021/07/11/%E3%80%8C%E5%85%88%E8%BC%A9%E3%81%A8%E3%81%BF%E3%81%AA%E3%81%BF%E3%81%A1%E3%82%83%E3%82%93%E3%80%8DJA%E5%85%B1%E6%B8%88CM%E5%90%88%E9%9B%86%E5%AD%97%E5%B9%95%E7%BF%BB%E8%AF%91/"/>
    <id>/2021/07/11/「先輩とみなみちゃん」JA共済CM合集字幕翻译/</id>
    <published>2021-07-11T07:31:46.000Z</published>
    <updated>2021-07-11T07:31:46.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="「先輩とみなみちゃん」（前辈和美波酱）"><a href="#「先輩とみなみちゃん」（前辈和美波酱）" class="headerlink" title="「先輩とみなみちゃん」（前辈和美波酱）"></a>「先輩とみなみちゃん」（前辈和美波酱）</h1><h2 id="作品简介"><a href="#作品简介" class="headerlink" title="作品简介"></a>作品简介</h2><p>日语广告片的个人翻译练习。合集主要介绍了JA共済的相关保障服务，类似于保险业务。</p><h2 id="1-JA共済とは（JA共济是什么）"><a href="#1-JA共済とは（JA共济是什么）" class="headerlink" title="# 1 ＪＡ共済とは（JA共济是什么）"></a># 1 ＪＡ共済とは（JA共济是什么）</h2><div style="position: relative; width: 95%; height: 0; left: 2.5%; padding-bottom: 65%;"><br>    <iframe src="https://www.bilibili.com/blackboard/html5mobileplayer.html?aid=418566655&bvid=BV1xV41147yw&page=1&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> </iframe><br></div><h2 id="2-JA共済の保障とは（JA共济的保障是什么）"><a href="#2-JA共済の保障とは（JA共济的保障是什么）" class="headerlink" title="# 2 ＪＡ共済の保障とは（JA共济的保障是什么）"></a># 2 ＪＡ共済の保障とは（JA共济的保障是什么）</h2><div style="position: relative; width: 95%; height: 0; left: 2.5%; padding-bottom: 65%;"><br>    <iframe src="https://www.bilibili.com/blackboard/html5mobileplayer.html?aid=418566655&bvid=BV1xV41147yw&page=2&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> </iframe><br></div><h2 id="3-ライフアドバイザーとは（生活顾问是什么）"><a href="#3-ライフアドバイザーとは（生活顾问是什么）" class="headerlink" title="# 3 ライフアドバイザーとは（生活顾问是什么）"></a># 3 ライフアドバイザーとは（生活顾问是什么）</h2><div style="position: relative; width: 95%; height: 0; left: 2.5%; padding-bottom: 65%;"><br>    <iframe src="https://www.bilibili.com/blackboard/html5mobileplayer.html?aid=418566655&bvid=BV1xV41147yw&page=3&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> </iframe><br></div><h2 id="4-医療共済（医疗共济）"><a href="#4-医療共済（医疗共济）" class="headerlink" title="# 4 医療共済（医疗共济）"></a># 4 医療共済（医疗共济）</h2><div style="position: relative; width: 95%; height: 0; left: 2.5%; padding-bottom: 65%;"><br>    <iframe src="https://www.bilibili.com/blackboard/html5mobileplayer.html?aid=418566655&bvid=BV1xV41147yw&page=4&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> </iframe><br></div><h2 id="5-そなエール（防范准备）"><a href="#5-そなエール（防范准备）" class="headerlink" title="# 5 そなエール（防范准备）"></a># 5 そなエール（防范准备）</h2><div style="position: relative; width: 95%; height: 0; left: 2.5%; padding-bottom: 65%;"><br>    <iframe src="https://www.bilibili.com/blackboard/html5mobileplayer.html?aid=418566655&bvid=BV1xV41147yw&page=5&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> </iframe><br></div><h2 id="6-終身共済（终身共济）"><a href="#6-終身共済（终身共济）" class="headerlink" title="# 6 終身共済（终身共济）"></a># 6 終身共済（终身共济）</h2><div style="position: relative; width: 95%; height: 0; left: 2.5%; padding-bottom: 65%;"><br>    <iframe src="https://www.bilibili.com/blackboard/html5mobileplayer.html?aid=418566655&bvid=BV1xV41147yw&page=6&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> </iframe><br></div><h2 id="7-メディフル（一時金）（Mediful-一次性补贴）"><a href="#7-メディフル（一時金）（Mediful-一次性补贴）" class="headerlink" title="# 7 メディフル（一時金）（Mediful 一次性补贴）"></a># 7 メディフル（一時金）（Mediful 一次性补贴）</h2><div style="position: relative; width: 95%; height: 0; left: 2.5%; padding-bottom: 65%;"><br>    <iframe src="https://www.bilibili.com/blackboard/html5mobileplayer.html?aid=418566655&bvid=BV1xV41147yw&page=7&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> </iframe><br></div><h2 id="8-メディフル（祝金）（Mediful-健康红包）"><a href="#8-メディフル（祝金）（Mediful-健康红包）" class="headerlink" title="# 8 メディフル（祝金）（Mediful 健康红包）"></a># 8 メディフル（祝金）（Mediful 健康红包）</h2><div style="position: relative; width: 95%; height: 0; left: 2.5%; padding-bottom: 65%;"><br>    <iframe src="https://www.bilibili.com/blackboard/html5mobileplayer.html?aid=418566655&bvid=BV1xV41147yw&page=8&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> </iframe><br></div><h2 id="9-My家財プラス（我的家产plus）"><a href="#9-My家財プラス（我的家产plus）" class="headerlink" title="# 9 My家財プラス（我的家产plus）"></a># 9 My家財プラス（我的家产plus）</h2><div style="position: relative; width: 95%; height: 0; left: 2.5%; padding-bottom: 65%;"><br>    <iframe src="https://www.bilibili.com/blackboard/html5mobileplayer.html?aid=418566655&bvid=BV1xV41147yw&page=9&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> </iframe><br></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;「先輩とみなみちゃん」（前辈和美波酱）&quot;&gt;&lt;a href=&quot;#「先輩とみなみちゃん」（前辈和美波酱）&quot; class=&quot;headerlink&quot; title=&quot;「先輩とみなみちゃん」（前辈和美波酱）&quot;&gt;&lt;/a&gt;「先輩とみなみちゃん」（前辈和美波酱）&lt;/h1&gt;&lt;h2 i
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="日语" scheme="/tags/%E6%97%A5%E8%AF%AD/"/>
    
      <category term="翻译" scheme="/tags/%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>日语课总结（1）</title>
    <link href="/2021/05/26/%E6%97%A5%E8%AF%AD%E8%AF%BE%E6%80%BB%E7%BB%93%EF%BC%881%EF%BC%89/"/>
    <id>/2021/05/26/日语课总结（1）/</id>
    <published>2021-05-26T15:31:42.000Z</published>
    <updated>2021-05-26T15:31:42.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="日语课总结（1）"><a href="#日语课总结（1）" class="headerlink" title="日语课总结（1）"></a>日语课总结（1）</h1><h2 id="表記（ひょうき）"><a href="#表記（ひょうき）" class="headerlink" title="表記（ひょうき）"></a>表記（ひょうき）</h2><ol><li>どんなことも、まずやってみようという精神（せいしん）が大事だ。</li><li>ごみの処理（しょり）にはお金がかかる。</li><li>みんな同じコップを使いますから、自分のコップに印（しるし）を付けてください。</li><li>胸に記（しる）して忘れない。</li><li>日記（にっき）</li><li>今日の夜、テレビでサッカーの試合を放送します。</li><li>私の趣味はお菓子を作ることです。</li><li>彼は三十七歳のとき、始めて小説を著（あらわ）した。</li><li>悲しみの感情を表（あらわ）した音楽。</li><li>危険（きけん）な症状を現す。</li><li>父の財産を兄と私で半分ずつ相続（そうぞく）した。</li><li>この腕時計（うでどけ）は一日に一分ずつ進む。</li><li>大雨でサッカーの決勝戦（けっしょうせん）は延期されることになった。</li><li>現場から犯人のものと思われる足跡（あしあと）が発見された。</li><li>このゲームは非常（ひじょう）に集中力が要（い）る。</li></ol><h2 id="言い換え類義"><a href="#言い換え類義" class="headerlink" title="言い換え類義"></a>言い換え類義</h2><ol><li>母親は息子の部屋のドアを　<strong>そっと／静かに</strong>　閉めた</li><li><strong>こっそり／こそこそ</strong></li><li>きちんと 整洁、恰当</li><li>ちゃんと 认真、规矩、整齐</li><li>確り（しっかり） 可靠、牢固</li><li>地震（じしん）の時は　<strong>冷静／落ち着いて</strong>　に行動しなければならない。</li><li><strong>急いで／慌（あわ）てて</strong></li><li>今年の梅雨（ばいう）が　<strong>長引（ながび）ている／なかなか終わらない</strong>　。</li><li>土地の問題をめぐる住民（じゅうみん）の対立の　<strong>根（ね）／原因</strong>　は深い。</li><li>専門用語（せんもんようご）の多い英語（えいご）を翻訳（ほんやく）するのは　<strong>厄介（やっかい）／面倒（めんどう）</strong>　なので、専門家に頼むんだ。</li><li>この争（あらそ）いの　<strong>根（ね）／原因</strong>　は一つだけではない。</li><li>からかうのは　<strong>よして／やめて</strong>　ください。</li><li>車を止める。</li><li>道路（どうろ）の石を退（ど）ける。</li><li>結婚式（けっこんしき）の招待状（しょうたいじょう）を送ったら、　<strong>続々（ぞくぞく）と／次々（つぎつぎ）に</strong>　返事が届いた。</li><li>順々（じゅんじゅん）に仕事をかたづける。</li><li>転々（てんてん）と各地（かくち）を巡業（じゅんぎょう）する。</li><li>度々注意したが聞き入れない。</li><li>選手（せんしゅ）たちはゴールに向かって　<strong>徐々（じょじょ）に／少しずつ</strong>　走るスピードを上げていった。</li><li>工事は　<strong>着々（ちゃくちゃく）と／順調に</strong>　進んでいる。</li><li>さんまがどっと市場（いちば）へ出回（でまわ）る。</li><li>彼女は　<strong>穏（おだ）やかな／静かな</strong>　表情（ひょうじょう）で話している。</li></ol><h2 id="語形成（ごけいせい）"><a href="#語形成（ごけいせい）" class="headerlink" title="語形成（ごけいせい）"></a>語形成（ごけいせい）</h2><ol><li>おいしいと評判（ひょうばん）のケーキを買いに行ったが、売り　<u><strong>切れて</strong></u>　いて買えなかった。</li><li>日本で　<u><strong>少子化（しょうしか）</strong></u>　が進んでいる原因の一つとして、結婚の時期が遅くなっていることがあげられる。</li><li>今回のエベントは、この会社に入って初めての　<u><strong>大</strong></u>　仕事だから、みんな張り切っている。</li><li>自転車で走っていたら、横道から子供が飛び　<u><strong>出して</strong></u>　きて、びっくりした。</li><li>母はいつも、肉、魚、野菜をバランスよく取り　<u><strong>入れて</strong></u>　料理を作ってくれる。</li><li>もう少しで頂上（ちょうじょう）というところまで行ったが、急に天気が悪くなったので仕方なく引き　<u><strong>返した</strong></u>。</li><li>子どもを引き　<u><strong>寄せる</strong></u>。</li><li>以前は英語なんて話せないと思い　<u><strong>込んで</strong></u>　いたが、海外からの客が増えて、どうしても話さないわけにはいかなくなった。</li><li>地球（ちきゅう）　<u><strong>温暖化（おんだんか）</strong></u>　の影響（えいきょう）だろうか、異常（いじょう）気象（きしょう）が続いている。</li><li>この仏像（ぶつぞう）は国宝（こくほう）だが、一般的（いっぱんてき）には　<u><strong>非</strong></u>　公開になっている。</li><li>タバコはやめたはずなのに、無　<u><strong>意識</strong></u>　に灰皿（はいざら）のある場所を探してしまう。</li><li>この会社では、新製品を発売するための準備が　<u><strong>着々と</strong></u>　進んでいる。</li></ol><h2 id="文脈規定（ぶんみゃくきてい）"><a href="#文脈規定（ぶんみゃくきてい）" class="headerlink" title="文脈規定（ぶんみゃくきてい）"></a>文脈規定（ぶんみゃくきてい）</h2><ol><li>呉呉（くれぐれ）もお大事に。</li><li>栄養（えいよう）の　<u><strong>バランス</strong></u>　を取るには、野菜をたくさん食べることです。</li><li>朝飯の　<u><strong>献立（こんだて）／メニュー</strong></u>　はみそ汁・たまご焼き・のり・香の物だ。</li><li>世界の何処（どこ）かで戦争（せんそう）が起こっている。平和（へいわ）を　<u><strong>維持</strong></u>　するのは難（むずか）しいことだ。</li><li>結論（けつろん）を出すために、話し合いの　<u><strong>焦点（しょうてん）</strong></u>　を絞（しぼ）りましょう。</li><li>首相（しゅしょう）はインタビューで政府の重要（じゅうよう）課題（かだい）に対する　<u><strong>見解</strong></u>　を明（あき）らかにする。</li><li>会費は5万円くらいと　<u><strong>見当をつける／を推測（すいそく）する</strong></u>。</li><li>事故（じこ）は　<u><strong>思いがけない</strong></u>　ところで起こることが多いから、一瞬の注意も怠（おこた）ることができない。</li><li>手入れを怠（おこた）ると故障（こしょう）する。</li><li>この国の女性の　<u><strong>平均寿命（へいきんじゅみょう）</strong></u>　は八十歳である。</li><li>この料理は野菜が　<u><strong>たっぷり</strong></u>　入っているので、体にいいですよ。</li><li>青空に山が　<u><strong>くっきり／はっきり</strong></u>　見える。</li><li>こっそり跡をつける。</li><li>ぐっすりと眠っている。</li><li>彼女は、この仕事では二十年のキャリアがある　<u><strong>ベテラン（veteran）</strong></u>　だ。</li><li>テレビのアンテナ（antenna）を取り付ける。</li><li>この道は狭いから、車が　<u><strong>擦（す）れ違う</strong></u>　のは難（むずか）しい。</li><li>レポートを書くために、世界の人口の　<u><strong>分布（ぶんぷ）</strong></u>　を調べてみた。</li><li>社会人は自分の　<u><strong>行動（こうどう）</strong></u>　に責任を持たなげればならない。</li><li>この荷物（にもつ）は上下（じょうげ）が　<strong>逆（さか）さま</strong>　にならないように注意して運（はこ）んでください。</li><li>入選作は　<u><strong>各々（おのおの）／銘々（めいめい）／それぞれ</strong></u>　優（すぐ）れている。</li><li>試験の前日はしっかり睡眠（すいみん）をとったほうがいい。</li></ol><h2 id="文法（ぶんぽう）"><a href="#文法（ぶんぽう）" class="headerlink" title="文法（ぶんぽう）"></a>文法（ぶんぽう）</h2><ol><li><strong>Vる + ほかない</strong><br>含义：除此 <strong>该动作</strong> 之外没别的办法。「Vる + しかない」的official版本。<br>例句：だれにも頼めないから、自分で <u><strong>やる</strong></u> ほかない。</li><li><strong>Vる + ものだ／ものではない</strong><br>含义：认为 <strong>该动作</strong> 为一般常识，这样的动作更好。语气较为强烈。<br>例句1： 学生は <u><strong>勉強する</strong></u> ものです。遊んでばかりいてはいけません。<br>例句2：日本では、女性に年齢を <u><strong>聞く</strong></u> ものではない。</li><li><strong>V／いAい／なAな + わけではない</strong><br>含义：认为 <strong>该动作/形容</strong> 不完全正确。<br>例句：日本人が全員、敬語が上手に <u><strong>話せる</strong></u> わけではない。</li><li><strong>Vる + ことはない</strong><br>含义：认为 <strong>该动作</strong> 没有必要。用于主观性的建议。<br>例句：彼のほうが悪いのだから、君が <u><strong>謝る</strong></u> ことはない。</li><li><strong>Vる／N + どころではない</strong><br>含义：表示现在不是 <strong>该动作/名词</strong> 发生的时候。语气较为强烈，带有责难或质疑。<br>例句：<br>A：こんばん、映画に行かない？<br>B：え？明日、テストなんだから、 <u><strong>行く／映画</strong></u> どころではないよ！</li><li><strong>Vる、Vない + ことだ</strong><br>含义：认为 <strong>该动作</strong> 比较好、重要。用于主观性建议。<br>例句：日本語が上手になりたかったら、毎日、日本人と <u><strong>練習する／会話する</strong></u> ことだ。</li><li><strong>V／いAい／なAな／Nの + わけがない</strong><br>含义：表示对于 <u><strong>该动作/形容/名词</strong></u> 的强烈否定。语气带有强烈怀疑、质疑。<br>例句：<br>A：旅行に行かない？<br>B：えっ？今、コロナなんだから、旅行に <u><strong>行く</strong></u> わけがないでしょう。</li><li><strong>Vる、Vない + ことになっている</strong><br>含义：表示 <strong>该动作</strong> 是被规则、计划等决定好的。<br>例句1：日本では、二十歳（はたち）未満でお酒を飲んでは <u><strong>いけない</strong></u> ことになっている。<br>例句2：能力試験は、7月は中止になったら、12月は <u><strong>行（おこな）う</strong></u> ことになっている。</li><li><strong>N + からして</strong><br>含义：表示仅仅看 <strong>该名词</strong> ，不看其他方面，就可以得出一些结论。用于表达 <strong>该名词</strong> 的重要性亦或是做事的最低限度。<br>例句：あのコンビニのバイト、新人だね。 <u><strong>あいさつ</strong></u> からして、きちんとしていないよ。</li><li><strong>V／いAい／なAな／Nの + あまり</strong><br>含义：表示 该动作/形容/名词 过分到超过了一般情况。常用于表示 <strong>该动作</strong> 做的过了， <strong>该名词（情感）</strong> 过剩。<br>*余（あま）り。<br>例句：田中さんは、彼にふられて、 <u><strong>悲しみ</strong></u> のあまり、ご飯を食べなくなった。</li><li><strong>V／いAい／なAである／Nである + ことから</strong><br>含义：表示 <strong>该动作/形容/名词</strong> 是后文的原因。<br>例句：ここから、よく星が <u><strong>見える</strong></u> ことから、ここは星見町という名前になった。</li><li><strong>V／いAい／なAである／Nである + からには</strong><br>含义：表示 <strong>该动作/形容/名词</strong> 是后文的原因（当然でしょう）。语气中包含着强烈的 決意（けつい），可理解为「既然 … 就一定要 … 」。<br>例句：<u><strong>約束した</strong></u> からには、守らなければならない／守るべきだ。</li><li><strong>Nの + かわりに</strong><br>含义：表示后文动作本应由 <strong>该名词</strong> 完成，作为  <strong>该名词</strong> 的替代，主语完成了该动作。<br>例句：学会（がっかい）には、忙しい先輩のかわりに私が出席（しゅっせき）した。</li><li><strong>Nの + ことだから</strong><br>含义：在较为了解 <strong>该名词</strong> 的情况下，推测 <strong>该名词</strong> 很有可能导致后文的动作发生。<br>例句：よく遅（おく）れる <u><strong>田中さん</strong></u> のことだから、今日も、遅（おく）れるだろう。</li><li><strong>Vます／N + がちだ</strong><br>含义：表示 <strong>该动作/名词</strong> 发生的次数很多或者很容易发生。<br>例句：彼女は小さいときからよく病気する。→彼女は <u><strong>病気</strong></u> がちだ。</li><li><strong>N + だらけ</strong><br>含义：表示 <strong>该名词</strong> 大量出现。使用场景仅限于眼见的实体。<br>例句：この作文は間違いがたくさんある。→この作文は <u><strong>まちがい</strong></u> だらけだ。</li><li><strong>Vて／N + ばかり</strong><br>含义：表示只会一直进行 <strong>该动作/名词</strong> 不做别的。常用于责难的时候，带有不满的语气。<br>例句：彼はいつもゲームを <u><strong>して</strong></u> ばかりいる。＝彼はいつも <u><strong>ゲーム</strong></u> ばかりしている。</li><li><strong>Vる + べきだ</strong><br>含义：表示 <strong>该动作</strong> 是当然应该做的。常用于提出强烈的主张和忠告。<br>例句1：子供でも、悪いことをしたら、 <u><strong>謝る</strong></u> べきだ。<br>例句2：結婚式に白い服を <u><strong>着る</strong></u> べきではない。</li><li><strong>V／いAい／なAな + わけだ</strong><br>含义：表示 <strong>该动作</strong> 是有理由的。常用于表示前后文关系的合理性。<br>例句：<br>A：ジョンさんはアメリカ人だけど、お母さんが日本人なんだって。<br>B：それで、日本語が <u><strong>わかる／話せる</strong></u> わけだ。</li><li><strong>N1をN2として</strong><br>含义：把 <strong>名词1</strong> 当作是 <strong>名词2</strong>。<br>例句：今日は、 <u><strong>ベトさん</strong></u> を <u><strong>先生</strong></u> として、ベトナム語を勉強しましょう。</li><li><strong>Vる、Vている、Vない／いAい／なAな／Nの + うちに</strong><br>含义：趁着 <strong>该动作/形容/名词</strong> 的时间，去做后文的动作。<br>* の間に<br>例句1：子供が <u><strong>ねている</strong></u> うちに、そうじしよう／買い物に行こう。<br>例句2：<u><strong>覚えている／忘れない</strong></u> うちに、メモしよう。</li><li><strong>Vる、Vた／Nの + ついでに</strong><br>含义：<strong>该动作/名词</strong> 的顺便做了后文的动作。<br>例句：スーパーへ <u><strong>行く</strong></u> ついでに、銀行／郵便局に寄った。</li><li><strong>V／いAい／なAなである／Nである + わりに</strong><br>含义：表示在 该动作/形容/名词 的前提下，后文的事件与预想不符。通常用于前后文的正负相关性与预想不符。<br>例句：あのレストランは、値段が <u><strong>安い</strong></u> わりに、量が多い。</li><li><strong>Vます形 + 得る</strong><br>含义：表示 该动作是可能发生的。official版本。不能用于表示能力。<br>例句1：コロナは、だれでも、 <u><strong>なり／かかり</strong></u> うる病気だ。<br>例句2：私は1キロ（<strong>泳げる</strong>・<del>泳ぎうる</del>）。</li><li><strong>Vます形 + っこない</strong><br>含义：表示 该动作 绝对不可能发生。口语。<br>例句：こんなにたくさんの言葉、一日じゃ、 <u><strong>覚えられ</strong></u> っこないよ。</li><li><strong>Vる／Nの + おそれがある</strong><br>含义：表示 <strong>该动作</strong> 恐怕有可能发生。通常 <strong>该动作</strong> 为负面结果。<br>例句：地震の後は、津波（つなみ）が <u><strong>くる</strong></u> おそれがあります。</li><li><strong>Vます形 + つつある</strong><br>含义：表示正在逐渐向 <strong>该动作</strong> 的方向变化。<strong>该动作</strong> 通常是具有改变、成为等含义的动词。<br>例句：台風で、風が強くなりつつあります。</li><li><strong>Vた + すえに</strong><br>含义：表示后文是 <strong>该动作</strong> 的结果。这个结果的发生通常需要 <strong>该动作</strong> 经过较长时间。<br>例句：<u><strong>考えた</strong></u> すえに、国に帰ることに決めました。</li><li><strong>Vる、Vている、Vた + ところ</strong><br>含义：表示 <strong>即将要、正在、刚刚</strong> 做了 <strong>该动作</strong> 的时候，就发生了后文的动作。</li></ol><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>这一节课不会的东西也太多了，全记成电子笔记的话工程量有点遭不住啊。。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;日语课总结（1）&quot;&gt;&lt;a href=&quot;#日语课总结（1）&quot; class=&quot;headerlink&quot; title=&quot;日语课总结（1）&quot;&gt;&lt;/a&gt;日语课总结（1）&lt;/h1&gt;&lt;h2 id=&quot;表記（ひょうき）&quot;&gt;&lt;a href=&quot;#表記（ひょうき）&quot; class=&quot;head
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="日语" scheme="/tags/%E6%97%A5%E8%AF%AD/"/>
    
  </entry>
  
  <entry>
    <title>「天気の子」翻译（人物介绍、序章）</title>
    <link href="/2021/05/08/%E3%80%8C%E5%A4%A9%E6%B0%97%E3%81%AE%E5%AD%90%E3%80%8D%E7%BF%BB%E8%AF%91%EF%BC%88%E4%BA%BA%E7%89%A9%E4%BB%8B%E7%BB%8D%E3%80%81%E5%BA%8F%E7%AB%A0%EF%BC%89/"/>
    <id>/2021/05/08/「天気の子」翻译（人物介绍、序章）/</id>
    <published>2021-05-08T15:58:00.000Z</published>
    <updated>2021-05-08T15:58:00.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>原文为自购的「天気の子」@角川つばさ文庫<br>新海誠（しんかいまこと）　作<br>ちーこ　挿絵</li><li>本文仅用于日语学习用途，请勿用于商业用途！</li></ul><h1 id="「天気の子」翻译"><a href="#「天気の子」翻译" class="headerlink" title="「天気の子」翻译"></a>「天気の子」翻译</h1><h2 id="人物紹介（じんぶつしょうかい）"><a href="#人物紹介（じんぶつしょうかい）" class="headerlink" title="人物紹介（じんぶつしょうかい）"></a>人物紹介（じんぶつしょうかい）</h2><ol><li>天野陽菜（あまのひな）：帆高（ほだか）が出会った女の子。”祈る”と空を晴れにできる。</li><li>森嶋帆高（もりしまほだか）：家出して、東京にやってきた高校生（こうこうせい）。</li><li>夏美（なつみ）：須賀（すが）の事務所（じむしょ）で働く女子（じょし）大生（だいせい）。</li><li>須賀圭介（すがけいすけ）：帆高を雇（やと）う小さな編集（へんしゅう）プロダクション（production）のライター（writer）。</li><li>天野渚（あまのなぎ）：陽菜の弟（おとうと）。女子に人気の小学生（しょうがくせい）。</li></ol><h2 id="序章（じょしょう）-君に聞いた物語"><a href="#序章（じょしょう）-君に聞いた物語" class="headerlink" title="序章（じょしょう）　君に聞いた物語"></a>序章（じょしょう）　君に聞いた物語</h2><p>三月（さんがつ）の雨空（あまぞら）に、フェリーの出港（しゅっこ）を知らせる汽笛（きてき）が長く響く。</p><p><em>在一个三月的雨天，预示着轮渡出港的汽笛声长鸣。</em></p><p>巨大（きょだい）な船体（せんたい）が海水（かいすい）を押しのけていく重い振動（しんどう）が、尻から全身（ぜんしん）に伝わってくる。</p><p><em>巨大的船体推开海水产生的剧烈震动，从屁股传向全身。</em></p><p>僕のチケットは船底（せんてい）に最（もっと）も近い二等船室（にとうせんしつ）。東京までは十時間以上（いじょう）の船旅（ふなたび）で、到着（とうちゃく）は夜になる。このフェリーで東京に向かうのは、人生で二度目だ。僕は立ち上げり、デッキテラスへの階段（かいだん）に向かう。</p><p><em>我的船票是离船底最近的二等房间。到东京是要十小时以上船旅的，到了的时候已经是晚上了。坐这班轮渡去往东京，已经是人生中的第二次了。我站起来，面向甲板的台阶。</em></p><p>「あいつには前科（ぜんか）があるらしい」とか、「今でも警察（けいさつ）に追（お）われているらしい」とか、僕が学校（がっこう）でそんな噂（うわさ）をされるようになたのは、二年半前の東京での出来事がきっかけだった。噂（うわさ）をされること自体（じたい）はどうということもなかったけれど（実際（じっさい）、噂（うわさ）になるのは当然（とうぜん）だったと思う）、僕はあの夏の東京での出来事を、島の誰にも話さなかった。断片的に語（かた）ったことはあるけれど、本当に大事なことは親にも友人（ゆうじん）にも警察（けいさつ）にも話さなかった。あの夏の出来事をまるごと抱えたまま、僕はもう一度東京に行くのだ。</p><p><em>「那个人好像有前科」、「好像现在还在被警察追查」什么的，我在学校被那样的传闻缠身，正是因为两年前在东京的变故。被传闲话这样的事，自己倒是觉得没什么大不了的（实际上，我认为会变成传闻也是当然的）。那个夏天在东京的事故，我对这个岛上的任何人都没提起过。虽然有过只言片语，但真正重要的事情我就算对父母、朋友还是警察都没提起过。因为背负着那个夏天的变故，我再一次前往东京了。</em></p><p>十八歳になった今、今度こそあの街に住むために。</p><p><em>已经18岁的现在，这次一定要为了住在那个街区。</em></p><p>もう一度あの人に会うために。</p><p><em>为了再一次和那个人相遇。</em></p><p>そのことを考えると、いつでも肋骨（ろっこつ）の内側（うちがわ）が熱を持つ。頬（ほお）がじわりと火照（ほて）る。早く海風（うみかぜ）に当たりたくて、僕は階段を登る足を速める。</p><p><em>考虑那个事情的话，不论何时肋骨的内侧都会（感觉）温热。脸颊一点点发烫。想要赶快感受海风，我加快脚步登上台阶。</em></p><p>デッキテラスに出ると、冷たい風が雨と共にどっと顔を打った。その全部を飲み込むようにして、僕は大きく息を吸い込む。風はまだ冷たいけれど、そこには春の気配（けはい）がたっぷりと含（ふく）まれている。ようやく高校を卒業（そつぎょう）したんだーーその実感（じっかん）が、遅（おく）れた通知（つうち）のように今さらに胸に届（とど）く。僕はデッキの手すりに肘（ひじ）を乗せ、遠ざかっていく島を眺（なが）め、風巻（しま）く空に目を移（うつ）す。視界の遥か彼方（かなた）まで、数（かぞ）え切れない雨粒（あまつぶ）が舞（ま）っている。</p><p><em>一从甲板阳台中出来，刺骨的寒风混合着雨点一下子打到我的脸上。像是要把他们全部吞下去一样，我大口吸气。虽然寒风依旧，那里面却包含着春的气息。终于高中毕业了啊——那个实感像是迟来的通知一样，现在才传达到我的心中。我靠在甲板的扶手上，眺望着远去的海岛，将视线移向刮着狂风的空中。直到视线的远方，数不清的雨点在（空中）飞舞。</em></p><p>その途端（とたん）ーーぞわりと、全身の肌（はだ）が粟立（あわだ）った。</p><p><em>正当这时——一阵寒颤，全身的汗毛都竖了起来。</em></p><p>まただ。思わずきつく目を閉じる。じっとしている僕の顔を雨が叩（たた）き、耳朶（じだ）には雨音（あまおと）が響き続ける。この二年半、雨は常（つね）にそこにあった。どんなに息を殺しても決（けっ）して消せない鼓動（こどう）のように。どんなに強く瞑（つむ）っても完全な闇（やみ）には出来ない瞼（まぶた）のように。どんなに静（しず）めても片時も沈黙（ちんもく）出来ない心のように。</p><p><em>还没到。禁不住紧紧闭上眼睛。雨点拍打着我一动不动的脸，耳中一直回响着雨点的声音。这两年半中，经常下雨。像是不论怎么屏住呼吸也绝对抹不掉的脉搏一样。像是不论如何紧闭双眼也不能做到完全黑暗的眼睑一样。像是不论如何镇静也练片刻沉默都做不到的心脏一样。</em></p><p>ゆっくりと息を吐（は）きながら、僕は目を開ける。</p><p><em>一边慢慢的吐气，我睁开了眼睛。</em></p><p>雨。</p><p><em>雨。</em></p><p>呼吸（こきゅう）をするようにうねる黒い海面に、雨が際限（さいげん）なく吸い込むまれていく。まるで空と海が共謀（きょうぼう）して、いたずらに海面を押し上げようとしているかのようだ。僕は怖くなる。身体（からだ）の奥底（おくそこ）から震（ふる）えが湧（わ）き上がってくる。引き裂かれそうになる。ばらばらになりそうになる。僕は手すりをぎゅっと掴（つか）む。鼻から深（ふか）く息を吸う。そしていつものように、あの人のことを思い出す。彼女の大きな瞳（ひとみ）や、よく動（うご）く表情（ひょうじょう）や、ころころ変わる声のトーンや、二つに結んだ長い髪を。そして、大丈夫だ、と思う。彼女がいる。東京で彼女が生きている。彼女がいる限（かぎ）り、僕はこの世界にしっかりと繋ぎ止められている。</p><p><em>雨被像是呼吸一样起伏的黑色的海面无限制地吸进去。完全是天空和大海的同谋，像是要没有意义的将海平面抬高一样。我开始感到害怕。恐惧从身体的深处涌了上来。像是要变得被撕裂一样。像是要变得破碎一样。我紧紧握住扶手。用鼻子深深地吸气。就这样像往常一样，回想起那个人。想起她的大眼睛、多变的表情、轻快转变的声调、扎成两束的长发。之后就会觉得没关系的。她还活着。她还在东京好好的生活着。只要她还活着，我就能和这个世界紧紧相连。</em></p><p>「ーーだから、泣かないで、帆高」</p><p><em>「——所以，别哭啊，帆高」</em></p><p>と、あの夜、彼女は言った。逃げ込んだ池袋（いけぶくろ）のホテル。天井（てんじょう）を叩（たた）く雨の音が、遠い太鼓（たいこ）のようだった。同じシャンプーの香りと、何もかもを許したような彼女の優し声と、闇に青白（あおじろ）く光る彼女の肌（はだ）。それらは余（あま）り鮮明（せんめい）で、僕は不図（ふと）、今（いま）も自分があの場所（ばしょ）にいるような気持ちに襲（おそ）われる。本当（ほんとう）の僕たちは今（いま）もあのホテルにいて、僕はたまたまのデジャヴ（dejavu）のように、未来の自分がフェリーに乗っている姿（すがた）を想像しただけなのではないか。昨日の卒業式もこのフェリーも全部錯覚（さっかく）で、本当の僕の隣にいて、世界はいつもと同じ姿のまま、変わらぬ日常が再開するのではないか。</p><p><em>那个晚上，她这么说道。逃进池袋的旅馆。拍打着天花板的雨声像是远处的太鼓（声）。同样的洗发水的香气、像是什么都原谅的她温柔的声音、在黑暗中显出苍白血色的她的肌肤。因为这些（场景）都太深刻了，突然之间，像是自己也在那个地方的感觉向我袭来。像是我们真的在那个旅馆一样，像是我偶然（脑中）出现了似曾相识感一样，这不只是我在想象未来的自己乘上轮渡的样子吗？昨天的毕业典礼和这个轮渡全都是错觉，实际上我的周围，实际还是和往常相同的的样子，改变不了的日常再次上演，难道不是吗？</em></p><p>汽笛（きてき）が鋭（するど）く鳴（な）った。</p><p><em>汽笛声尖锐的响起。</em></p><p>違う、そうじゃない。僕は手すりの鉄の感触（かんしょく）を確かめ、潮（しお）の匂いを確かめ、水平線（すいへいせん）に消えかかっている島影（しまかげ）を確かめる。そうじゃない、今はあの夜ではない。あれはもうずっと前のことだ。フェリーに揺られているこの自分が、今の本当の僕だ。きちんと考えよう。最初（さいしょ）から思い出そう。雨をにらみながら僕はそう思う。彼女に再会する前に、僕たちに起きたことを理解しておかなければ。いや、たとえ理解は出来なくても、せめて考え尽（つ）くさなければ。</p><p><em>不是的，不是这样的。我确认了扶手金属的触感，确认了海潮的味道，确认了眼看就要消失在水平线的海岛的样子。不是这样的，现在不是那个晚上了。那已经是很久以前的事情了。随着轮渡摇摆的自己，才是真正的我。好好的思考啊。从最初开始回忆。一边盯着雨点，我这么想着。和她再遇之前，必须要预先理解因为我们而起的事情。不不，比如说就算不能理解，也必须尽力考虑。</em></p><p>僕たちになにが起きたのか。僕たちはなにを選んだのか。そして僕は、これから彼女にどういう言葉（ことば）を届けるべきなのか。</p><p><em>因为我们而发生了什么是吗？我们选择了什么是吗？还有就是，我从这开始应该向她传递怎样的话语呢？</em></p><p>すべてのきっかけはーーそう、たぶんあの日だ。</p><p><em>所有的原因就是——对，大概就是那天了。</em></p><p>彼女が最初（さいしょ）にそれを目撃（もくげき）した日。彼女が語（かた）ってくれたあの日の出来事が、すべての始まりだったんだ。</p><p><em>她最开始目击到那个的日子。她对我讲述的那天偶然发生的事，是一切的开始（强烈解释性语气）。</em></p><hr><p>彼女の母親は、もう何カ月も目を覚まさないままだったそうだ。</p><p><em>她的母亲好像已经好几个月一直没有醒过来了。</em></p><p>小さな病室（びょうしつ）を満（み）たしていたのは、バイタルモニター（vital monitor）の規則的（きそくてき）な電子音（でんしおん）と呼吸器（こきゅうき）のシューという動作音（どうさおん）と、執拗（しつよう）に窓をたたく雨音（あまおと）。それと、長く人の留（とど）まった病室に特有（とくゆう）の、世間（せけん）と切り離されたしんとした空気（くうき）。</p><p><em>生命检测器规律的电子声音、呼吸器“咻”的工作声音以及执拗的敲在窗户上的雨声充满了小小的病房。以及（病）人住了很久的病房特有的，与世隔绝的寂静气氛。</em></p><p>彼女はベッドサイドの丸椅子に座ったまま、すっかり骨張（ほねば）ってしまった母親の手をきゅっと握（にぎ）る。母親の酸素（さんそ）マスクが規則的（きそくてき）に白く濁（にご）るさまを眺（なが）め、ずっと伏（ふ）せられたままの睫毛（まつげ）を見つめる。不安に押しつぶされそうになりながら、彼女はただただ祈っている。お母（かあ）さんが目を覚ましますように。ピンチの時のヒーローみたいな風が力強（ちからづよ）く吹（ふ）きつけて、憂鬱（ゆううつ）とか心配とか雨雲（あまぐも）とか暗くて重い物をすっきりと吹き飛ばし、家族三人で、もう一度青空（あおぞら）の下を笑いながら歩けますように。</p><p><em>她一直坐在床边的圆凳上，紧紧的握着母亲已经（瘦弱到）完全皮包骨头的手。注视着母亲规律性被白色雾气笼罩的氧气面罩，紧盯着一直被垂下的睫毛。被不安（的情绪）压倒，她也唯有祈祷。母亲好像睁开了眼睛。紧急关头伴随着像是英雄一样的强风，将忧郁、担心、阴雨和黑暗沉重的心情一下子吹飞，为了一家三人能再一次在蓝天下笑着散步。</em></p><p>ふわり、と彼女の髪が揺られた。ぴちょん、と耳元で微（かす）かな水音が聞こえた。</p><p><em>她的头发轻柔地摇摆着。咚的一声，耳边听到了微弱的水声。</em></p><p>彼女は顔を上げる。閉（し）め切ったはずの窓（まど）のカーテンがかすかに揺れている。窓ガラス越しの空に、彼女の目は引き寄せられる。いつの間にか陽が射（さ）している。雨は相変わらず本降（ほんぶ）りだけど、雲に小さな隙間（すきま）が出来ていて、そこから伸（の）びた細（ほそ）い光が地上（ちじょう）お一点を照らしている。彼女は目を凝（こ）らす。視界の果てまで敷（し）き詰（つ）められた建物。そのうちの一つのビルの屋上（おくじょう）だけが、スポットライトを浴（あ）びた役者（やくしゃ）みたいにぽつんと光っている。</p><p><em>她仰着头。本应紧闭着的窗户的窗帘正微微地摇摆着。她的眼神被吸引到穿过窗户玻璃的天空上。不知何时，阳光照射了出来。虽然雨还是老样子下得很大，阳光却从云间的缝隙中钻出，并顺着这个缝隙延伸开来照在了地面上的一点。她聚精会神。视野的尽头被建筑物覆盖。只有那里面一座高楼的屋顶在孤零零的发光，就像沐浴在聚光灯下的演员。</em></p><p>誰かに呼ばれたかのように、気づけば彼女は病室から駆け出していた。</p><p><em>像是被谁呼唤着一样，不经意间，她已经从病房中跑了出去。</em></p><p>そこは廃ビルだった。周囲の建物はぴかぴかに真新しいのに、その雑居（ざっきょ）ビルだけは時間に取り残されたかのように茶色く朽（く）ちていた。「ビリヤード（billiard）」とか「金物店（かなものてん）」とか「鰻（うなぎ）」とか「麻雀（マージャン）」とか、錆（さ）び付いて色褪（いろあ）せた看板がビルの周囲にいくつも貼（は）り付いていた。ビニール傘越（がさご）しに見上げると、陽射しは確かにここの屋上（おくじょう）を照らしている。ビルの脇（わき）を覗（のぞ）くと小さな駐車場（ちゅうしゃじょう）になっていて、ぼろぼろに錆（さ）び付いた非常階段（ひじょうかいだん）が屋上まで伸びていた。</p><p><em>那是废弃的高楼。明明周围的建筑物都崭新到闪闪发光，只有那个杂堆中的高楼像是落后于时代一样在茶色中腐朽。有很多「台球馆」、「五金店」、「鳗鱼」、「麻将」这样的生锈褪色的看板贴在高楼的周围。透过塑料伞向上看，阳光确实正在照射着这里的屋顶。稍微看向高楼的周围，能看到一个面积不大的停车场，破损不堪的生锈的（百度翻译：锈蚀不堪的）紧急楼梯延伸到屋顶。</em></p><p>ーーまるで光の水たまりみたい。</p><p><em>简直就像是光的水塘。</em></p><p>階段を昇りきった彼女は、一時（いっとき）、眼前（がんぜん）の景色（けしき）に見とれた。</p><p><em>登上楼梯的她一时间被眼前的景色吸引住了。</em></p><p>手すりに囲（かこ）まれたその屋上（おくじょう）は二十五メートルプールのちょうど半分くらいの広さで、床（ゆか）のタイルはぼろぼろにひび割（わ）れ、一面緑の雑草（ざっそう）に覆（おお）われていた。その一番奥に茂（しげ）みに抱（だ）き抱（かか）えるようにして小さな鳥居（とりい）を真っ直ぐに照らしている。鳥居の朱色（あかいろ）が、陽射しのスポットライトの中で雨粒（あまつぶ）と一緒（いっしょ）にきらきらと輝いていた。雨に濁（にご）った世界の中で、そこだけが鮮（あざ）やかだった。</p><p><em>被扶手包围的屋顶差不多正好有25米游泳池的一半大，地板的瓷砖已经破损不堪出现裂纹，被一片绿色的杂草所覆盖。（阳光）直直的照射着那最深处像是被繁茂草木簇拥着的⛩（神社牌坊）。⛩（神社牌坊）的朱红色在阳光聚光灯束中和雨点一起闪闪发光。被雨点遮住的世界中，只有这里是鲜艳亮丽的。</em></p><p>ゆっくりと、彼女は鳥居に向かって屋上を歩いた。さくさくという柔（やわ）らかい音（おと）と心地（ここち）好い弾力（だんりょく）がある。雨のカーテンの向こうには、幾（いく）つもの高層（こうそう）ビルが白く霞（かす）んで立っている。何処（どこ）かに巣（す）があるのか、小鳥の囀（さえず）りがあたりに満ちている。そこに微かに、まるで別の世界から聞こえてくるような山手線（やまのてせん）の遠い音が混じっている。</p><p><em>慢慢的，她面向神社走在屋顶上。有沙沙的柔软的声音和令人舒服的弹性。雨帘的另一边，有几座高楼在白雾中矗立着。像是哪里有鸟巢一样，到处都是小鸟的啼叫。在那里，完全像是从别的世界传来山手线遥远的声音微弱的混杂（在小鸟的叫声中）。</em></p><p>傘を地面に置（お）いた。雨の冷たさが彼女の滑（なめ）らかな頬（ほお）を撫（な）でる。鳥居の奥には小さな石の祠（ほこら）があり、その周囲には紫色（むらさきいろ）の小さな花が茂（しげ）っていた。そこに埋もれるように、誰が置いたのか盆飾（ぽんかざ）りの精霊馬（しょうりょううま）が二体（にたい）あった。竹（たけ）籤（ひご）を刺したキュウリとように。ゆっくりと目を閉じ、願いながら鳥居を潜（くぐ）る。お母さんが目を覚まして、青空の下を一緒に歩けますように。</p><p><em>把伞放在地面上。雨的寒冷抚摸着她光滑的脸颊。神社的里面有一个石头（搭的）小祠堂，那（祠堂）周围紫色的小花繁茂（生长着）。在哪里埋没着一样，像是被谁放置（在那里）的装饰盂兰盆节的精灵马（一种祭祀用品）有两个。像是竹签刺入的黄瓜一样。慢慢闭上眼睛，一边许愿一边走过神社牌坊。为了能在母亲醒来之后一起走在蓝天之下。</em></p><p>鳥居を抜けると、不意（ふい）に空気が変わった。</p><p><em>穿过神社牌坊，不经意间气场改变了。</em></p><p>雨の音が、ぷつりと途切（とぎ）れた。</p><p><em>雨声，（像绳子一样）啪的一下中断了。</em></p><p>目を開くとーーそこは青空の真ん中だった。</p><p><em>张开双眼——这里是蓝天的正中央。</em></p><p>彼女は強い風に吹かれながら、空のずっと高い場所に浮（う）かんでいた。いや、風を切り裂（さ）いて落ちていた。聞いたこともないような低（ひく）くて深（ふか）い風の音が周囲に渦巻（うずま）いていた。息は吐くたびに白く凍（こお）り、濃紺（のうこん）の中でキラキラと瞬（またた）いた。それなのに、恐怖（きょうふ）はなかった。目覚（めざ）めたまま夢を見ているような奇妙な感覚（かんかく）だった。</p><p><em>她一边被强风吹拂，一边漂浮在空中相当高的地方。不对，是把风劈开向下落。从没听过的低沉深邃的风声在周围卷起漩涡。吐气冻成白雾，在深蓝（的天空）中闪闪发亮。就算如此，也并没有（感到）害怕。（而是）一直睁着眼睛做梦一样的奇妙感觉。</em></p><p>足元を見下（みお）ろすと、巨大（きょだい）なカリフラワーのような積乱雲（せきらんうん）が幾つも浮（う）かんでいた。一つ一つがきっと何（なん）キロメートルもの大きさの、それは壮麗（そうれい）な空の森のようだった。</p><p><em>看向脚下，几块巨大的菜花一样的积雨云漂浮着。每一个都一定有几公里那么大，那就像是壮丽的空中森林。</em></p><p>ふと、雲の色が変化していることに彼女は気付（きづ）いた。雲の頂上（ちょうじょう）、大気（たいき）の境目（さかいめ）で平らになっている平野（へいや）のような場所（ばしょ）に、ぽつりぽつりと緑が生まれ始めている。彼女は目を見張（みは）る。</p><p><em>突然，她注意到云的颜色正在变化。云的顶端，在大气的分界线处变得平坦的像平原一样的地方，绿色开始一点一点（墨水滴到纸上一样）生长。她惊讶的睁大了眼睛。</em></p><p>それは、まるで草原だった。地上からは決（けっ）して見えない雲の頭頂（とうちょう）に、さざめく緑が生まれては消えているのだ。そしてその周囲（しゅうい）に気付けば生き物のような微細（びさい）な何かが群（むら）がっている。</p><p><em>那简直就是草原。在从地面上绝对看不到的云的顶端，沙沙作响生长出来的绿色消失了。之后，稍微注意就会发现，在那周围有像是活物一样微小的什么东西在聚集。</em></p><p>「……魚？」</p><p><em>「……鱼？」</em></p><p>幾何学的（きかがくてき）な渦（うず）を描いてゆったりとうねるその群体（ぐんたい）は、まるで魚の群（む）れのように見えた。彼女は落下（らっか）しながら、じっとそれを見つめる。雲の上の平原（へいげん）を、無数（むすう）の魚たちが泳いでいるーー。</p><p><em>画着几何学漩涡顺畅蜿蜒的那个群体，不如说像是看到鱼群一样。她一边下落，一边聚精会神的盯着那个（鱼群）。无数的鱼正在云上的平原游泳。</em></p><p>突然、指先（ゆびさき）に何かが触れた。驚（おどろ）いて手を見る。やはり魚だ。透明な体（からだ）を持つ小さな魚たちが、重さのある風のように指や髪をすり抜けている。長いひれをなびかせているものや、くらげのように丸いものや、メダカのように細（こま）かなもの。様々な姿形（すがたかたち）の魚たちは、太陽の光を透（す）かしてプリズマみたいに輝いている。気付けば彼女は空の魚に囲（かこ）まれている。</p><p><em>突然，指尖碰到了什么。吓得（赶紧）看向手。果然是鱼。有着透明身体的小鱼们像是劲风一样穿过手指和头发。浮动着长鳍的东西，像是水母一样的圆的东西，像是青鳉鱼一样纤细的东西。各种各样形态的鱼透过阳光像棱镜一样发光。回过神来，她已经被空中的鱼包围起来。</em></p><p>空の青と、雲の白と、さざめく緑と、七色に輝く魚たち。彼女がいるのは、聞いたことも想像したこともない不思議で美しい更（さら）の世界だった。やがて彼女の足元を覆（おお）っていた雨雲（あまぐも）が解（ほど）けるように消えていき、眼下（がんか）にはどこまでも広がる東京の街並みが姿を現（あらわ）した。ビルの一つひとつ、車の一台（いちだい）いちだい、窓ガラスの一枚いちまいが、太陽を浴びて誇（ほこ）らしげに光っている。雨に洗（あら）われて生まれ変わったようなその街に、彼女は風に乗ってゆっくりと落ちていく。次第（しだい）に、不思議な一体感（いったいかん）が全身に満ちてくる。自分がこの世界の一部であることが、言葉以前（ことばいぜん）の感覚（かんかく）として彼女にはただ分かる。自分が風であり水であり、青であり白であり、心であり願いである。奇妙な幸せと切なさが全身に広がっていく。そしてゆっくりと、深く布団（ふとん）に沈み込むように意識が消えていくーー。</p><p><em>天空的蓝，云彩的白，喧嚣的绿，以及发出彩色光芒的鱼群。她所在的是闻所未闻、想所未想过的不可思议的美丽新世界。将将盖住她脚底的雨云像是解散一样消失了，眼下显现出的是向着各处伸展的东京的街道。一座座高楼，一台台汽车，一块块窗户玻璃在阳光的沐浴下自豪的发光。在这个被大雨洗刷后再生一般的街道上，她乘着风慢慢的落下来。（看到这个场景后）立刻，不可思议的一致感充满了全身。自己是这个世界的一部分，（这种）难以言表的感觉只有她能明白。风与水，青与白，心与愿都是我。奇妙的幸福感与苦闷传向全身。之后慢慢的，像是深深坠入被窝一样，意识消失了。</em></p><hr><p>「あの景色。あの時私が見たものは全部夢だったのかもしれないけどーー」と、嘗（かつ）て彼女は僕に語（かた）った。</p><p><em>「那个风景。虽然当时我看到的东西说不定全部都是梦境。」，她曾经这样对我说。</em></p><p>でも、夢ではなかったのだ。僕たちは今ではそれを知っているし、僕たちはその後、ともに同じ景色を目の当たりにすることになる。誰も知らない空の世界を。</p><p><em>但是，那不是在梦中啊。我们现在是知道了这（件事），我们在那之后一起看到的一样的眼前的景色。（知道了）谁也不知道的空中世界。</em></p><p>彼女と共に過ごした、あの年の夏。</p><p><em>和她一起度过的，那年的夏天。</em></p><p>東京の空の上で僕たちは、世界の形を決定的（けっていてき）に変えてしまったのだ。</p><p><em>在东京的上空，我们不经意间让世界的形态发生了决定性的改变啊。</em></p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>仨礼拜我翻完了14页哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈。我快吐了。</p><p>本书一共296页，预计共需要 $ \frac{296页}{14页/3周} = 63.43周 &gt; 1年 $ 的时间。希望之后我能提速！</p><p>也可能放弃提速转向填充附录的单词注释？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;原文为自购的「天気の子」@角川つばさ文庫&lt;br&gt;新海誠（しんかいまこと）　作&lt;br&gt;ちーこ　挿絵&lt;/li&gt;
&lt;li&gt;本文仅用于日语学习用途，请勿用于商业用途！&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;「天気の子」翻译&quot;&gt;&lt;a href=&quot;#「天気の子」翻译&quot; cl
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="日语" scheme="/tags/%E6%97%A5%E8%AF%AD/"/>
    
  </entry>
  
  <entry>
    <title>NLP with GTX1060（完形填空）</title>
    <link href="/2021/04/17/NLP%20with%20GTX1060%EF%BC%88%E5%AE%8C%E5%BD%A2%E5%A1%AB%E7%A9%BA%EF%BC%89/"/>
    <id>/2021/04/17/NLP with GTX1060（完形填空）/</id>
    <published>2021-04-17T07:06:14.000Z</published>
    <updated>2021-04-17T07:06:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="NLP-with-GTX1060（完形填空）"><a href="#NLP-with-GTX1060（完形填空）" class="headerlink" title="NLP with GTX1060（完形填空）"></a>NLP with GTX1060（完形填空）</h1><h1 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1 环境准备"></a>1 环境准备</h1><p>我的软件环境：</p><ol><li>Windows10 </li><li>python3.7</li><li>cuda11.0 + pytorch1.8.0 + cudnn（对应版本）</li></ol><ul><li>cuda和cudnn需要和驱动版本搭配，cudnn安装需要注册英伟达账号。</li></ul><p>我的硬件环境：</p><ol><li>Intel I7-8750H</li><li>Nvidia GTX1060(6G)</li></ol><p>python依赖的几个库：</p><ol><li>pytorch（<a href="https://pytorch.org/" target="_blank" rel="noopener">官网命令行安装</a>）</li><li>transformers（<a href="https://huggingface.co/transformers/installation.html" target="_blank" rel="noopener">官网安装引导</a>）</li><li>可能还要按需安装numpy（已经被pytorch依赖）、sklearn、matplotlib等。（直接pip）</li></ol><h1 id="2-完型填空-with-GTX1060"><a href="#2-完型填空-with-GTX1060" class="headerlink" title="2 完型填空 with GTX1060"></a>2 完型填空 with GTX1060</h1><h2 id="2-1-介绍"><a href="#2-1-介绍" class="headerlink" title="2.1 介绍"></a>2.1 介绍</h2><h3 id="2-1-1-任务介绍"><a href="#2-1-1-任务介绍" class="headerlink" title="2.1.1 任务介绍"></a>2.1.1 任务介绍</h3><p>完型填空概要：</p><ol><li>已知条件：在一段文本中，几个单词被替换为了[MASK]符号。</li><li>先验知识：一个未被替换任何单词的文本集合。</li><li>目标：对给定一段被替换了n个单词的任意文本进行还原，使整段文本语义通顺，符合逻辑。</li></ol><p>上下文填空其实是模型在预训练时使用的我认为最主要的获取单词含义、上下文意思的一种方式。<br>实际上这种任务就是Bert中的Masked Language Model，详情可以参考 <a href="/2020/07/10/如何理解%20BERT/#1-3-1-Masked-LM">Masked LM</a> 。<br>这种任务的本质也是一种分类，只不过在该任务中，类别有vocab_size种，因为字典中的每个token都有填入这里的可能性，我们只是挑选概率高的作为候选。</p><h3 id="2-1-2-模型介绍"><a href="#2-1-2-模型介绍" class="headerlink" title="2.1.2 模型介绍"></a>2.1.2 模型介绍</h3><p>使用模型：<a href="https://arxiv.org/abs/1910.01108" target="_blank" rel="noopener">DistilBERT</a><br>特点：详见 <a href="/2021/04/16/NLP%20with%20GTX1060（文本分类）/#2-1-2-模型介绍">2.1.2 模型介绍</a> 。</p><h2 id="2-2-代码"><a href="#2-2-代码" class="headerlink" title="2.2 代码"></a>2.2 代码</h2><h3 id="2-2-1-DistilBERT模型预测"><a href="#2-2-1-DistilBERT模型预测" class="headerlink" title="2.2.1 DistilBERT模型预测"></a>2.2.1 DistilBERT模型预测</h3><pre><code class="python"># 库import torchimport torch.nn as nnfrom decimal import Decimalfrom transformers import DistilBertTokenizer, DistilBertForMaskedLM# 定义 mask位置寻找函数# input_ids列表 - [index1, index2, ... , index]# 返回的列表包含所有mask在输入文本中的index位置def find_mask_index(input_tensor):    output_list = []    count = 0    for ids in input_tensor[0]:        if ids == 103:  # mask的id为103            output_list.append(count)        count = count + 1    return output_list# 定义 bert完型预测函数def bert_maskedlm_prediction(input_text):    # 设备选择    device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)    # 选择已经预训练好的模型和tokenizer    tokenizer = DistilBertTokenizer.from_pretrained(&#39;./distilbert-base-uncased&#39;)    model = DistilBertForMaskedLM.from_pretrained(&#39;./distilbert-base-uncased&#39;)    model = model.to(device)    # 将输出logits转化为对应vocab的归一化概率    inputs = tokenizer(input_text, return_tensors=&quot;pt&quot;)    mask_list = find_mask_index(inputs[&#39;input_ids&#39;])    inputs = inputs.to(device)    outputs = model(**inputs)    logits = outputs.logits    softmax = nn.Softmax()                  # 选择归一化函数    output_prob_list = []    for mask_index in range(len(mask_list)):        output_prob_list.append(softmax(logits[0][mask_list[mask_index]][:]))      # 得到归一化概率    # 将概率排序后输出    out_prob_dict_sorted_list = []    # 降序排列    for mask_index in range(len(mask_list)):        output_prob_dict = {}        for ids in range(output_prob_list[mask_index].shape[-1]):            output_prob_dict[tokenizer.convert_ids_to_tokens(ids=ids)] = output_prob_list[mask_index][ids]        out_prob_dict_sorted = sorted(output_prob_dict.items(), key=lambda x:x[1], reverse=True)        out_prob_dict_sorted_list.append(out_prob_dict_sorted)    # 打印    for mask_index in range(len(mask_list)):        count = 1        print(&#39;######   MASK {}   ######&#39;.format(mask_index))        for (key, val) in out_prob_dict_sorted_list[mask_index]:            if count &gt; 5:   # 打印概率前5的结果                break            else:                val = float(val) * 100                val = Decimal(val).quantize(Decimal(&#39;0.00&#39;))                print(&#39;|{:&lt;15s}|{:&gt;5s}%|&#39;.format(key, str(val)))                count = count + 1# 定义 主函数def main():    input_text = &quot;Beijing is my [MASK], I have lived in [MASK] for many [MASK]. &quot;    bert_maskedlm_prediction(input_text)</code></pre><h3 id="2-2-2-DistilBERT模型预训练"><a href="#2-2-2-DistilBERT模型预训练" class="headerlink" title="2.2.2 DistilBERT模型预训练"></a>2.2.2 DistilBERT模型预训练</h3><ul><li><strong>2.2.1</strong> 中使用的是DistilBERT原作者release的预训练好的模型。若想要重新或者进一步预训练，可能需要极强的GPU资源。</li><li>预训练代码之后有时间的话会补上。</li></ul><p>待续。。。</p><h2 id="2-3-实验"><a href="#2-3-实验" class="headerlink" title="2.3 实验"></a>2.3 实验</h2><h3 id="2-3-1-输入文本范例"><a href="#2-3-1-输入文本范例" class="headerlink" title="2.3.1 输入文本范例"></a>2.3.1 输入文本范例</h3><p><code>Beijing is my [MASK], I have lived in [MASK] for many [MASK].</code></p><p>其中，[MASK]为被盖住的token，实际中没有绝对的标准答案，通常将原文视为标准答案。</p><h3 id="2-3-2-预测结果"><a href="#2-3-2-预测结果" class="headerlink" title="2.3.2 预测结果"></a>2.3.2 预测结果</h3><center><strong>######   MASK 0   ######</strong></center><table><thead><tr><th style="text-align:center">Prediction</th><th style="text-align:center">Probability</th></tr></thead><tbody><tr><td style="text-align:center">hometown</td><td style="text-align:center">49.86%</td></tr><tr><td style="text-align:center">birthplace</td><td style="text-align:center">16.05%</td></tr><tr><td style="text-align:center">home</td><td style="text-align:center">5.62%</td></tr><tr><td style="text-align:center">homeland</td><td style="text-align:center">4.64%</td></tr><tr><td style="text-align:center">capital</td><td style="text-align:center">2.64%</td></tr></tbody></table><center><strong>######   MASK 1   ######</strong></center><table><thead><tr><th style="text-align:center">Prediction</th><th style="text-align:center">Probability</th></tr></thead><tbody><tr><td style="text-align:center">beijing</td><td style="text-align:center">68.04%</td></tr><tr><td style="text-align:center">china</td><td style="text-align:center">11.14%</td></tr><tr><td style="text-align:center">peking</td><td style="text-align:center">2.20%</td></tr><tr><td style="text-align:center">shanghai</td><td style="text-align:center">1.52%</td></tr><tr><td style="text-align:center">tianjin</td><td style="text-align:center">1.49%</td></tr></tbody></table><center><strong>######   MASK 2   ######</strong></center><table><thead><tr><th style="text-align:center">Prediction</th><th style="text-align:center">Probability</th></tr></thead><tbody><tr><td style="text-align:center">years</td><td style="text-align:center">74.87%</td></tr><tr><td style="text-align:center">generations</td><td style="text-align:center">9.23%</td></tr><tr><td style="text-align:center">decades</td><td style="text-align:center">7.81%</td></tr><tr><td style="text-align:center">centuries</td><td style="text-align:center">5.62%</td></tr><tr><td style="text-align:center">months</td><td style="text-align:center">0.64%</td></tr></tbody></table><ul><li>预测结果：Beijing is my <strong><em>hometown / birthplace / home</em></strong>, I have lived in <strong><em>Beijing / China / Peking</em></strong> for many <strong><em>years / generations / decades</em></strong>.</li></ul><h3 id="2-3-3-总结"><a href="#2-3-3-总结" class="headerlink" title="2.3.3 总结"></a>2.3.3 总结</h3><p>说实话，模型的三个预测都是我原本想的词。从结果上说，学习了大量语料的BERT还是很擅长完形填空的。不知道在需要先验知识、情感分析、长距离上下文联系的时候，模型还能不能表现出这样的效果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;NLP-with-GTX1060（完形填空）&quot;&gt;&lt;a href=&quot;#NLP-with-GTX1060（完形填空）&quot; class=&quot;headerlink&quot; title=&quot;NLP with GTX1060（完形填空）&quot;&gt;&lt;/a&gt;NLP with GTX1060（完形填
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="NLP" scheme="/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>NLP with GTX1060（文本分类）</title>
    <link href="/2021/04/17/NLP%20with%20GTX1060%EF%BC%88%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%EF%BC%89/"/>
    <id>/2021/04/17/NLP with GTX1060（文本分类）/</id>
    <published>2021-04-17T07:05:58.000Z</published>
    <updated>2021-04-17T07:05:58.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="NLP-with-GTX1060（文本分类）"><a href="#NLP-with-GTX1060（文本分类）" class="headerlink" title="NLP with GTX1060（文本分类）"></a>NLP with GTX1060（文本分类）</h1><h1 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1 环境准备"></a>1 环境准备</h1><p>我的软件环境：</p><ol><li>Windows10 </li><li>python3.7</li><li>cuda11.0 + pytorch1.8.0 + cudnn（对应版本）</li></ol><ul><li>cuda和cudnn需要和驱动版本搭配，cudnn安装需要注册英伟达账号。</li></ul><p>我的硬件环境：</p><ol><li>Intel I7-8750H</li><li>Nvidia GTX1060(6G)</li></ol><p>python依赖的几个库：</p><ol><li>pytorch（<a href="https://pytorch.org/" target="_blank" rel="noopener">官网命令行安装</a>）</li><li>transformers（<a href="https://huggingface.co/transformers/installation.html" target="_blank" rel="noopener">官网安装引导</a>）</li><li>可能还要按需安装numpy（已经被pytorch依赖）、sklearn、matplotlib等。（直接pip）</li></ol><h1 id="2-文本分类-with-GTX1060"><a href="#2-文本分类-with-GTX1060" class="headerlink" title="2 文本分类 with GTX1060"></a>2 文本分类 with GTX1060</h1><h2 id="2-1-介绍"><a href="#2-1-介绍" class="headerlink" title="2.1 介绍"></a>2.1 介绍</h2><h3 id="2-1-1-任务介绍"><a href="#2-1-1-任务介绍" class="headerlink" title="2.1.1 任务介绍"></a>2.1.1 任务介绍</h3><p>文本分类概要：</p><ol><li>已知条件：每段文本都有且只有一个标签与之对应，标签集合已知。</li><li>先验知识：一个标注好标签的文本集合。</li><li>目标：对给定一段任意文本进行正确的分类。</li></ol><p>文本分类的实际应用：</p><ol><li>文章分类</li><li>文本情感分析（消极/积极）</li></ol><h3 id="2-1-2-模型介绍"><a href="#2-1-2-模型介绍" class="headerlink" title="2.1.2 模型介绍"></a>2.1.2 模型介绍</h3><p>使用模型：<a href="https://arxiv.org/abs/1910.01108" target="_blank" rel="noopener">DistilBERT</a><br>特点：<a href="https://huggingface.co/transformers/model_doc/distilbert.html" target="_blank" rel="noopener">DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark. </a><br>一句话概括：又快又好</p><h2 id="2-2-代码"><a href="#2-2-代码" class="headerlink" title="2.2 代码"></a>2.2 代码</h2><h3 id="2-2-1-DistilBERT模型训练"><a href="#2-2-1-DistilBERT模型训练" class="headerlink" title="2.2.1 DistilBERT模型训练"></a>2.2.1 DistilBERT模型训练</h3><pre><code class="python"># 库import torchfrom transformers import DistilBertTokenizerFast, DistilBertForSequenceClassificationfrom transformers import Trainer, TrainingArgumentsfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support# 定义 读取tsv文件函数# tsv文件 - [text1, text2, ... , text], [label1, label2, ... , label]# 其中返回的label会转换为Lookup Table中的序号def read_tsv_file(file_dir):    # Create Lookup Table    str2label = [&quot;cs.AI&quot;, &quot;cs.CE&quot;, &quot;cs.cv&quot;, &quot;cs.DS&quot;, &quot;cs.IT&quot;, &quot;cs.NE&quot;, &quot;cs.PL&quot;, &quot;cs.SY&quot;, &quot;math.AC&quot;, &quot;math.GR&quot;, &quot;math.ST&quot;]    texts = []    labels = []    with open(file_dir, &#39;r&#39;, encoding=&#39;utf-8&#39;, newline=&#39;&#39;) as tsv_file:        for line in tsv_file.readlines():            if line == &#39;&#39; or line == &#39;\n&#39;:                continue            line_list = line.split(&#39;\t&#39;)            texts.append(line_list[-1])                         # 文本在tsv中的最后一栏               labels.append(str2label.index(line_list[-2]))       # 标签在tsv中的倒数第二栏        tsv_file.close()    return texts, labels# 定义 bert训练函数def bert_classification_training(train_file_name, eval_file_name, epochs):    # 设备选择    device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)    # 文件输入    train_texts, train_labels = read_tsv_file(train_file_name + &#39;.tsv&#39;)    train_num = len(train_labels)    eval_texts, eval_labels = read_tsv_file(eval_file_name + &#39;.tsv&#39;)    eval_num = len(eval_labels)    # 模型、tokenizer选择    tokenizer = DistilBertTokenizerFast.from_pretrained(&#39;./distilbert-base-uncased&#39;)  # DistilBertTokenizer和BertTokenizerFast一样。Fast版本比非Fast版本多了CPU多线程支持，所以快。    model = DistilBertForSequenceClassification.from_pretrained(&#39;./distilbert-base-uncased&#39;)    # Tokenization    ###  注1    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512, return_tensors=&quot;pt&quot;)    eval_encodings = tokenizer(eval_texts, truncation=True, padding=True, max_length=512, return_tensors=&quot;pt&quot;)    # 定义 MyDataset类    class MyDataset(torch.utils.data.Dataset):        def __init__(self, encodings, labels):            self.encodings = encodings            self.labels = labels        ### 注2        def __getitem__(self, idx):            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}            item[&#39;labels&#39;] = torch.tensor(self.labels[idx])            return item        def __len__(self):            return len(self.labels)    # 创建数据集    train_dataset = MyDataset(train_encodings, train_labels)    eval_dataset = MyDataset(eval_encodings, eval_labels)    # MyTrainer参数设定    ### 注3    training_args = TrainingArguments(        output_dir=&#39;./results&#39;,                 # 输出目录        num_train_epochs=epochs,                # 训练轮数        per_device_train_batch_size=8,          # 训练batch        per_device_eval_batch_size=8,           # 评估batch        learning_rate=5e-5,                     # AdamW学习率        warmup_ratio=0.01,                      # 热身比率        weight_decay=0.01,                      # 衰减率        logging_steps=10,                       # log频率        metric_for_best_model=&#39;eval_accuracy&#39;,  # 决定最好模型的metric        eval_steps=500,                         # 评估频率        load_best_model_at_end=True,            # 是否在训练结束后加载最好的模型    )    # 定义 计算评估指标函数    def compute_metrics(pred):        labels = pred.label_ids        preds = pred.predictions.argmax(-1)        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=&#39;macro&#39;)        acc = accuracy_score(labels, preds)        return {            &#39;accuracy&#39;: acc,            &#39;f1&#39;: f1,            &#39;precision&#39;: precision,            &#39;recall&#39;: recall        }    # 初始化MyTrainer    MyTrainer = Trainer(        model=model,        args=training_args,        train_dataset=train_dataset,        eval_dataset=eval_dataset,        compute_metrics=compute_metrics    )    # 开始训练    MyTrainer.train()    # 保存最后的模型    bert_model_save_dir = &#39;./bert_model.pkl&#39;    torch.save(model, bert_model_save_dir)    # 开始评估    output_dict = MyTrainer.evaluate()    # 提取评估结果    eval_loss = output_dict[&#39;traineval_loss&#39;]    eval_accuracy = output_dict[&#39;eval_accuracy&#39;]    eval_macrof1 = output_dict[&#39;eval_f1&#39;]    eval_precision = output_dict[&#39;eval_precision&#39;]    eval_recall = output_dict[&#39;eval_recall&#39;]    # 将评估结果写入tsv文件    with open(&#39;distilbert_train&#39; + str(train_num) + &#39;_eval&#39; + str(eval_num) + &#39;_result.csv&#39;, &#39;a&#39;, encoding=&#39;utf-8&#39;) as result:        result.write(&#39;eval_loss,&#39; + str(eval_loss) + &#39;\n&#39;)        result.write(&#39;eval_accuracy,&#39; + str(eval_accuracy) + &#39;\n&#39;)        result.write(&#39;eval_macrof1,&#39; + str(eval_macrof1) + &#39;\n&#39;)        result.write(&#39;eval_precision,&#39; + str(eval_precision) + &#39;\n&#39;)        result.write(&#39;eval_recall,&#39; + str(eval_recall) + &#39;\n&#39;)        result.close()# 定义 主函数def main():    train_file_name, eval_file_name, epochs = input(&#39;Please input your train, evaluation file directory and expected number of training epoch.\nInput format: train eval 8\n&#39;).split(&#39; &#39;)    bert_classification_training(train_file_name, eval_file_name, float(epochs))</code></pre><h3 id="2-2-2-DistilBERT模型预测"><a href="#2-2-2-DistilBERT模型预测" class="headerlink" title="2.2.2 DistilBERT模型预测"></a>2.2.2 DistilBERT模型预测</h3><pre><code class="python"># 库import torchimport torch.nn as nnfrom transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification# 定义 bert预测函数def bert_classification_prediction(input_text):    # 设备选择    device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)    # 选择已经训练好的模型和tokenizer    tokenizer = DistilBertTokenizerFast.from_pretrained(&#39;./distilbert-base-uncased&#39;)    model = torch.load(&#39;./bert_model.pkl&#39;)    model = model.to(device)    # 将输入文本转化为对应label的归一化概率    input_encoding = tokenizer(input_text, truncation=True, padding=True, max_length=512, return_tensors=&quot;pt&quot;)  # tokenization    input_encoding = input_encoding.to(device)    output = model(**input_encoding)            # 模型输出    output_logit = output.logits                # 对应label的logits    softmax = nn.Softmax()               # 选择归一化函数    output_prob = softmax(output_logit)     # 得到归一化概率    # 将概率排序后输出    output_prob_dict = {}    str2label = [&quot;cs.AI&quot;, &quot;cs.CE&quot;, &quot;cs.cv&quot;, &quot;cs.DS&quot;, &quot;cs.IT&quot;, &quot;cs.NE&quot;, &quot;cs.PL&quot;, &quot;cs.SY&quot;, &quot;math.AC&quot;, &quot;math.GR&quot;, &quot;math.ST&quot;]    # 降序排列    for i in range(output_logit.shape[-1]):        output_prob_dict[str2label[i]] = output_prob[0][i]    out_prob_dict_sorted = sorted(output_prob_dict.items(), key=lambda x:x[1], reverse=True)    # 打印    count = 1    for (key, val) in out_prob_dict_sorted:        if count &gt; 5:   # 打印概率前5的结果            break        else:            print([key, float(val)])            count = count + 1# 定义 主函数def main():    input_text = input(&quot;Please input your text: &quot;)    bert_classification_prediction(input_text)</code></pre><h2 id="2-3-实验"><a href="#2-3-实验" class="headerlink" title="2.3 实验"></a>2.3 实验</h2><h3 id="2-3-1-tsv文件范例"><a href="#2-3-1-tsv文件范例" class="headerlink" title="2.3.1 tsv文件范例"></a>2.3.1 tsv文件范例</h3><table><thead><tr><th>id</th><th>label</th><th>text</th></tr></thead><tbody><tr><td>1</td><td>Label 1</td><td>Text 1</td></tr><tr><td>2</td><td>Label 2</td><td>Text 2</td></tr><tr><td>3</td><td>Label 3</td><td>Text 3</td></tr></tbody></table><p>实际使用详情参见 <code>read_tsv_file(file_dir):</code> 函数的文件读取逻辑。</p><h3 id="2-3-2-训练参数及结果"><a href="#2-3-2-训练参数及结果" class="headerlink" title="2.3.2 训练参数及结果"></a>2.3.2 训练参数及结果</h3><table><thead><tr><th style="text-align:center">Key</th><th style="text-align:center">Value</th></tr></thead><tbody><tr><td style="text-align:center">Task</td><td style="text-align:center">Document Classification</td></tr><tr><td style="text-align:center">Dataset</td><td style="text-align:center">arXiv</td></tr><tr><td style="text-align:center">Category</td><td style="text-align:center">11</td></tr><tr><td style="text-align:center">Train</td><td style="text-align:center">2000</td></tr><tr><td style="text-align:center">Eval</td><td style="text-align:center">300</td></tr><tr><td style="text-align:center">Batch Size</td><td style="text-align:center">8(Max)</td></tr><tr><td style="text-align:center">Input Length</td><td style="text-align:center">512 Tokens</td></tr><tr><td style="text-align:center">Epoch</td><td style="text-align:center">8</td></tr><tr><td style="text-align:center">Training Time</td><td style="text-align:center">20min</td></tr><tr><td style="text-align:center">Accuracy</td><td style="text-align:center">76.7%</td></tr></tbody></table><h2 id="2-4-注解"><a href="#2-4-注解" class="headerlink" title="2.4 注解"></a>2.4 注解</h2><h3 id="2-4-1-tokenizer"><a href="#2-4-1-tokenizer" class="headerlink" title="2.4.1 tokenizer"></a>2.4.1 tokenizer</h3><p><code>train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512, return_tensors=&quot;pt&quot;)</code></p><ol><li>truncation：多出裁剪</li><li>padding：不足填充</li><li>return_tensor=”pt”：<br>‘tf’: Return TensorFlow tf.constant objects.<br>‘pt’: Return PyTorch torch.Tensor objects.<br>‘np’: Return Numpy np.ndarray objects.</li></ol><p>文档链接：<br><a href="https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizerFast" target="_blank" rel="noopener">tokenizer方法</a></p><h3 id="2-4-2-MyDataset"><a href="#2-4-2-MyDataset" class="headerlink" title="2.4.2 MyDataset"></a>2.4.2 MyDataset</h3><pre><code class="python">def __getitem__(self, idx):            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}            item[&#39;labels&#39;] = torch.tensor(self.labels[idx])            return item</code></pre><ol><li><code>item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}</code> 将被tokenizer编码后的encoding字典中的各项提取出来，包括input_ids、attention_mask。</li><li><code>item[&#39;labels&#39;] = torch.tensor(self.labels[idx])</code> 将labels也加入到item字典中，和input_ids、attention_mask并列。</li></ol><h3 id="2-4-3-MyTrainer"><a href="#2-4-3-MyTrainer" class="headerlink" title="2.4.3 MyTrainer"></a>2.4.3 MyTrainer</h3><p>见附录。</p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="Trainer的Parameters"><a href="#Trainer的Parameters" class="headerlink" title="Trainer的Parameters"></a>Trainer的Parameters</h3><pre><code class="python">    &#39;&#39;&#39;    Parameters:        output_dir (:obj:`str`):            The output directory where the model predictions and checkpoints will be written.        overwrite_output_dir (:obj:`bool`, `optional`, defaults to :obj:`False`):            If :obj:`True`, overwrite the content of the output directory. Use this to continue training if            :obj:`output_dir` points to a checkpoint directory.        do_train (:obj:`bool`, `optional`, defaults to :obj:`False`):            Whether to run training or not. This argument is not directly used by :class:`~transformers.Trainer`, it&#39;s            intended to be used by your training/evaluation scripts instead. See the `example scripts            &lt;https://github.com/huggingface/transformers/tree/master/examples&gt;`__ for more details.        do_eval (:obj:`bool`, `optional`):            Whether to run evaluation on the validation set or not. Will be set to :obj:`True` if            :obj:`evaluation_strategy` is different from :obj:`&quot;no&quot;`. This argument is not directly used by            :class:`~transformers.Trainer`, it&#39;s intended to be used by your training/evaluation scripts instead. See            the `example scripts &lt;https://github.com/huggingface/transformers/tree/master/examples&gt;`__ for more            details.        do_predict (:obj:`bool`, `optional`, defaults to :obj:`False`):            Whether to run predictions on the test set or not. This argument is not directly used by            :class:`~transformers.Trainer`, it&#39;s intended to be used by your training/evaluation scripts instead. See            the `example scripts &lt;https://github.com/huggingface/transformers/tree/master/examples&gt;`__ for more            details.        evaluation_strategy (:obj:`str` or :class:`~transformers.trainer_utils.IntervalStrategy`, `optional`, defaults to :obj:`&quot;no&quot;`):            The evaluation strategy to adopt during training. Possible values are:                * :obj:`&quot;no&quot;`: No evaluation is done during training.                * :obj:`&quot;steps&quot;`: Evaluation is done (and logged) every :obj:`eval_steps`.                * :obj:`&quot;epoch&quot;`: Evaluation is done at the end of each epoch.        prediction_loss_only (:obj:`bool`, `optional`, defaults to `False`):            When performing evaluation and generating predictions, only returns the loss.        per_device_train_batch_size (:obj:`int`, `optional`, defaults to 8):            The batch size per GPU/TPU core/CPU for training.        per_device_eval_batch_size (:obj:`int`, `optional`, defaults to 8):            The batch size per GPU/TPU core/CPU for evaluation.        gradient_accumulation_steps (:obj:`int`, `optional`, defaults to 1):            Number of updates steps to accumulate the gradients for, before performing a backward/update pass.            .. warning::                When using gradient accumulation, one step is counted as one step with backward pass. Therefore,                logging, evaluation, save will be conducted every ``gradient_accumulation_steps * xxx_step`` training                examples.        eval_accumulation_steps (:obj:`int`, `optional`):            Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU. If            left unset, the whole predictions are accumulated on GPU/TPU before being moved to the CPU (faster but            requires more memory).        learning_rate (:obj:`float`, `optional`, defaults to 5e-5):            The initial learning rate for :class:`~transformers.AdamW` optimizer.        weight_decay (:obj:`float`, `optional`, defaults to 0):            The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in            :class:`~transformers.AdamW` optimizer.        adam_beta1 (:obj:`float`, `optional`, defaults to 0.9):            The beta1 hyperparameter for the :class:`~transformers.AdamW` optimizer.        adam_beta2 (:obj:`float`, `optional`, defaults to 0.999):            The beta2 hyperparameter for the :class:`~transformers.AdamW` optimizer.        adam_epsilon (:obj:`float`, `optional`, defaults to 1e-8):            The epsilon hyperparameter for the :class:`~transformers.AdamW` optimizer.        max_grad_norm (:obj:`float`, `optional`, defaults to 1.0):            Maximum gradient norm (for gradient clipping).        num_train_epochs(:obj:`float`, `optional`, defaults to 3.0):            Total number of training epochs to perform (if not an integer, will perform the decimal part percents of            the last epoch before stopping training).        max_steps (:obj:`int`, `optional`, defaults to -1):            If set to a positive number, the total number of training steps to perform. Overrides            :obj:`num_train_epochs`.        lr_scheduler_type (:obj:`str` or :class:`~transformers.SchedulerType`, `optional`, defaults to :obj:`&quot;linear&quot;`):            The scheduler type to use. See the documentation of :class:`~transformers.SchedulerType` for all possible            values.        warmup_ratio (:obj:`float`, `optional`, defaults to 0.0):            Ratio of total training steps used for a linear warmup from 0 to :obj:`learning_rate`.        warmup_steps (:obj:`int`, `optional`, defaults to 0):            Number of steps used for a linear warmup from 0 to :obj:`learning_rate`. Overrides any effect of            :obj:`warmup_ratio`.        logging_dir (:obj:`str`, `optional`):            `TensorBoard &lt;https://www.tensorflow.org/tensorboard&gt;`__ log directory. Will default to            `runs/**CURRENT_DATETIME_HOSTNAME**`.        logging_strategy (:obj:`str` or :class:`~transformers.trainer_utils.IntervalStrategy`, `optional`, defaults to :obj:`&quot;steps&quot;`):            The logging strategy to adopt during training. Possible values are:                * :obj:`&quot;no&quot;`: No logging is done during training.                * :obj:`&quot;epoch&quot;`: Logging is done at the end of each epoch.                * :obj:`&quot;steps&quot;`: Logging is done every :obj:`logging_steps`.        logging_first_step (:obj:`bool`, `optional`, defaults to :obj:`False`):            Whether to log and evaluate the first :obj:`global_step` or not.        logging_steps (:obj:`int`, `optional`, defaults to 500):            Number of update steps between two logs if :obj:`logging_strategy=&quot;steps&quot;`.        save_strategy (:obj:`str` or :class:`~transformers.trainer_utils.IntervalStrategy`, `optional`, defaults to :obj:`&quot;steps&quot;`):            The checkpoint save strategy to adopt during training. Possible values are:                * :obj:`&quot;no&quot;`: No save is done during training.                * :obj:`&quot;epoch&quot;`: Save is done at the end of each epoch.                * :obj:`&quot;steps&quot;`: Save is done every :obj:`save_steps`.        save_steps (:obj:`int`, `optional`, defaults to 500):            Number of updates steps before two checkpoint saves if :obj:`save_strategy=&quot;steps&quot;`.        save_total_limit (:obj:`int`, `optional`):            If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in            :obj:`output_dir`.        no_cuda (:obj:`bool`, `optional`, defaults to :obj:`False`):            Whether to not use CUDA even when it is available or not.        seed (:obj:`int`, `optional`, defaults to 42):            Random seed that will be set at the beginning of training. To ensure reproducibility across runs, use the            :func:`~transformers.Trainer.model_init` function to instantiate the model if it has some randomly            initialized parameters.        fp16 (:obj:`bool`, `optional`, defaults to :obj:`False`):            Whether to use 16-bit (mixed) precision training instead of 32-bit training.        fp16_opt_level (:obj:`str`, `optional`, defaults to &#39;O1&#39;):            For :obj:`fp16` training, Apex AMP optimization level selected in [&#39;O0&#39;, &#39;O1&#39;, &#39;O2&#39;, and &#39;O3&#39;]. See details            on the `Apex documentation &lt;https://nvidia.github.io/apex/amp.html&gt;`__.        fp16_backend (:obj:`str`, `optional`, defaults to :obj:`&quot;auto&quot;`):            The backend to use for mixed precision training. Must be one of :obj:`&quot;auto&quot;`, :obj:`&quot;amp&quot;` or            :obj:`&quot;apex&quot;`. :obj:`&quot;auto&quot;` will use AMP or APEX depending on the PyTorch version detected, while the            other choices will force the requested backend.        fp16_full_eval (:obj:`bool`, `optional`, defaults to :obj:`False`):            Whether to use full 16-bit precision evaluation instead of 32-bit. This will be faster and save memory but            can harm metric values.        local_rank (:obj:`int`, `optional`, defaults to -1):            Rank of the process during distributed training.        tpu_num_cores (:obj:`int`, `optional`):            When training on TPU, the number of TPU cores (automatically passed by launcher script).        debug (:obj:`bool`, `optional`, defaults to :obj:`False`):            When training on TPU, whether to print debug metrics or not.        dataloader_drop_last (:obj:`bool`, `optional`, defaults to :obj:`False`):            Whether to drop the last incomplete batch (if the length of the dataset is not divisible by the batch size)            or not.        eval_steps (:obj:`int`, `optional`):            Number of update steps between two evaluations if :obj:`evaluation_strategy=&quot;steps&quot;`. Will default to the            same value as :obj:`logging_steps` if not set.        dataloader_num_workers (:obj:`int`, `optional`, defaults to 0):            Number of subprocesses to use for data loading (PyTorch only). 0 means that the data will be loaded in the            main process.        past_index (:obj:`int`, `optional`, defaults to -1):            Some models like :doc:`TransformerXL &lt;../model_doc/transformerxl&gt;` or :doc`XLNet &lt;../model_doc/xlnet&gt;` can            make use of the past hidden states for their predictions. If this argument is set to a positive int, the            ``Trainer`` will use the corresponding output (usually index 2) as the past state and feed it to the model            at the next training step under the keyword argument ``mems``.        run_name (:obj:`str`, `optional`):            A descriptor for the run. Typically used for `wandb &lt;https://www.wandb.com/&gt;`_ logging.        disable_tqdm (:obj:`bool`, `optional`):            Whether or not to disable the tqdm progress bars and table of metrics produced by            :class:`~transformers.notebook.NotebookTrainingTracker` in Jupyter Notebooks. Will default to :obj:`True`            if the logging level is set to warn or lower (default), :obj:`False` otherwise.        remove_unused_columns (:obj:`bool`, `optional`, defaults to :obj:`True`):            If using :obj:`datasets.Dataset` datasets, whether or not to automatically remove the columns unused by the            model forward method.            (Note that this behavior is not implemented for :class:`~transformers.TFTrainer` yet.)        label_names (:obj:`List[str]`, `optional`):            The list of keys in your dictionary of inputs that correspond to the labels.            Will eventually default to :obj:`[&quot;labels&quot;]` except if the model used is one of the            :obj:`XxxForQuestionAnswering` in which case it will default to :obj:`[&quot;start_positions&quot;,            &quot;end_positions&quot;]`.        load_best_model_at_end (:obj:`bool`, `optional`, defaults to :obj:`False`):            Whether or not to load the best model found during training at the end of training.            .. note::                When set to :obj:`True`, the parameters :obj:`save_strategy` and :obj:`save_steps` will be ignored and                the model will be saved after each evaluation.        metric_for_best_model (:obj:`str`, `optional`):            Use in conjunction with :obj:`load_best_model_at_end` to specify the metric to use to compare two different            models. Must be the name of a metric returned by the evaluation with or without the prefix :obj:`&quot;eval_&quot;`.            Will default to :obj:`&quot;loss&quot;` if unspecified and :obj:`load_best_model_at_end=True` (to use the evaluation            loss).            If you set this value, :obj:`greater_is_better` will default to :obj:`True`. Don&#39;t forget to set it to            :obj:`False` if your metric is better when lower.        greater_is_better (:obj:`bool`, `optional`):            Use in conjunction with :obj:`load_best_model_at_end` and :obj:`metric_for_best_model` to specify if better            models should have a greater metric or not. Will default to:            - :obj:`True` if :obj:`metric_for_best_model` is set to a value that isn&#39;t :obj:`&quot;loss&quot;` or              :obj:`&quot;eval_loss&quot;`.            - :obj:`False` if :obj:`metric_for_best_model` is not set, or set to :obj:`&quot;loss&quot;` or :obj:`&quot;eval_loss&quot;`.        ignore_skip_data (:obj:`bool`, `optional`, defaults to :obj:`False`):            When resuming training, whether or not to skip the epochs and batches to get the data loading at the same            stage as in the previous training. If set to :obj:`True`, the training will begin faster (as that skipping            step can take a long time) but will not yield the same results as the interrupted training would have.        sharded_ddp (:obj:`bool`, :obj:`str` or list of :class:`~transformers.trainer_utils.ShardedDDPOption`, `optional`, defaults to :obj:`False`):            Use Sharded DDP training from `FairScale &lt;https://github.com/facebookresearch/fairscale&gt;`__ (in distributed            training only). This is an experimental feature.            A list of options along the following:            - :obj:`&quot;simple&quot;`: to use first instance of sharded DDP released by fairscale (:obj:`ShardedDDP`) similar              to ZeRO-2.            - :obj:`&quot;zero_dp_2&quot;`: to use the second instance of sharded DPP released by fairscale              (:obj:`FullyShardedDDP`) in Zero-2 mode (with :obj:`reshard_after_forward=False`).            - :obj:`&quot;zero_dp_3&quot;`: to use the second instance of sharded DPP released by fairscale              (:obj:`FullyShardedDDP`) in Zero-3 mode (with :obj:`reshard_after_forward=True`).            - :obj:`&quot;offload&quot;`: to add ZeRO-offload (only compatible with :obj:`&quot;zero_dp_2&quot;` and :obj:`&quot;zero_dp_3&quot;`).            If a string is passed, it will be split on space. If a bool is passed, it will be converted to an empty            list for :obj:`False` and :obj:`[&quot;simple&quot;]` for :obj:`True`.        deepspeed (:obj:`str`, `optional`):            Use `Deepspeed &lt;https://github.com/microsoft/deepspeed&gt;`__. This is an experimental feature and its API may            evolve in the future. The value is the location of its json config file (usually ``ds_config.json``).        label_smoothing_factor (:obj:`float`, `optional`, defaults to 0.0):            The label smoothing factor to use. Zero means no label smoothing, otherwise the underlying onehot-encoded            labels are changed from 0s and 1s to :obj:`label_smoothing_factor/num_labels` and :obj:`1 -            label_smoothing_factor + label_smoothing_factor/num_labels` respectively.        adafactor (:obj:`bool`, `optional`, defaults to :obj:`False`):            Whether or not to use the :class:`~transformers.Adafactor` optimizer instead of            :class:`~transformers.AdamW`.        group_by_length (:obj:`bool`, `optional`, defaults to :obj:`False`):            Whether or not to group together samples of roughly the same legnth in the training dataset (to minimize            padding applied and be more efficient). Only useful if applying dynamic padding.        report_to (:obj:`str` or :obj:`List[str]`, `optional`, defaults to :obj:`&quot;all&quot;`):            The list of integrations to report the results and logs to. Supported platforms are :obj:`&quot;azure_ml&quot;`,            :obj:`&quot;comet_ml&quot;`, :obj:`&quot;mlflow&quot;`, :obj:`&quot;tensorboard&quot;` and :obj:`&quot;wandb&quot;`. Use :obj:`&quot;all&quot;` to report to            all integrations installed, :obj:`&quot;none&quot;` for no integrations.        ddp_find_unused_parameters (:obj:`bool`, `optional`):            When using distributed training, the value of the flag :obj:`find_unused_parameters` passed to            :obj:`DistributedDataParallel`. Will default to :obj:`False` if gradient checkpointing is used, :obj:`True`            otherwise.        dataloader_pin_memory (:obj:`bool`, `optional`, defaults to :obj:`True`)):            Whether you want to pin memory in data loaders or not. Will default to :obj:`True`.        skip_memory_metrics (:obj:`bool`, `optional`, defaults to :obj:`False`)):            Whether to skip adding of memory profiler reports to metrics. Defaults to :obj:`False`.    &#39;&#39;&#39;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;NLP-with-GTX1060（文本分类）&quot;&gt;&lt;a href=&quot;#NLP-with-GTX1060（文本分类）&quot; class=&quot;headerlink&quot; title=&quot;NLP with GTX1060（文本分类）&quot;&gt;&lt;/a&gt;NLP with GTX1060（文本分
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="NLP" scheme="/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>我的炉石卡组</title>
    <link href="/2021/03/25/%E6%88%91%E7%9A%84%E7%82%89%E7%9F%B3%E5%8D%A1%E7%BB%84/"/>
    <id>/2021/03/25/我的炉石卡组/</id>
    <published>2021-03-25T04:54:15.000Z</published>
    <updated>2021-11-26T07:18:17.358Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="https://hsdeck.herokuapp.com/" target="_blank" rel="noopener">卡组api</a> 调用自文章 <a href="https://zhangshuqiao.org/2018-12/%E7%82%89%E7%9F%B3%E5%8D%A1%E7%BB%84%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/" target="_blank" rel="noopener">炉石卡组代码解析</a> </li></ul><h1 id="宇宙牧"><a href="#宇宙牧" class="headerlink" title="宇宙牧"></a>宇宙牧</h1><h2 id="卡组一览"><a href="#卡组一览" class="headerlink" title="卡组一览"></a>卡组一览</h2><center><iframe src="https://hsdeck.herokuapp.com/?name=%E5%AE%87%E5%AE%99%E7%89%A7&code=AAEBAd35Ax7TCtcKuQ2BDsMWhRfgrAKDuwLYuwLRwQKWxALfxALmzAKJzQLo0AKQ0wLy7ALmiAPrmwPanQP8owP2sAOIsQORsQPIvgPOvgOm1QP21gO/4AOm7wMAAA==" border="0" frameborder="no" style="width: 100%; height: 1600px; transform: scale(1.0); transform-origin: 0 top 0; border-radius: 4px; box-shadow: 0 1px 20px -6px rgba(0,0,0,.5) !important;"></iframe></center><h2 id="卡组代码"><a href="#卡组代码" class="headerlink" title="卡组代码"></a>卡组代码</h2><pre><code>AAEBAd35Ax7TCtcKuQ2BDsMWhRfgrAKDuwLYuwLRwQKWxALfxALmzAKJzQLo0AKQ0wLy7ALmiAPrmwPanQP8owP2sAOIsQORsQPIvgPOvgOm1QP21gO/4AOm7wMAAA==</code></pre><h2 id="选配包解析（5选2）"><a href="#选配包解析（5选2）" class="headerlink" title="选配包解析（5选2）"></a>选配包解析（5选2）</h2><p><strong>选项1</strong>：唤醒造物者+死亡领主/克苏恩，破碎之劫（<strong>亡语包</strong>）<br><strong>选项2</strong>：寻求指引+死亡领主（<strong>发现包</strong>）<br><strong>选项3</strong>：黑暗主教本尼迪塔斯+克苏恩，破碎之劫（<strong>暗影包</strong>）</p><h3 id="1-唤醒造物者"><a href="#1-唤醒造物者" class="headerlink" title="1 唤醒造物者"></a>1 唤醒造物者</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">1费</td><td style="text-align:center">任务</td><td style="text-align:center"><strong>任务</strong>：己方召唤7个亡语，<strong>奖励</strong>：希望守护者阿玛拉（5/8/8，<strong>嘲讽</strong>，<strong>战吼</strong>：将己方英雄生命值置为40点）</td><td style="text-align:center"><strong>亡语</strong> 体系，中后期的 <strong>回血</strong> 手段</td><td style="text-align:center">搭配 <strong>雷诺+灵媒术</strong>，可实现理论 <strong>30+40+40+40=150点的中后期血量</strong></td></tr></tbody></table><h3 id="1-寻求指引"><a href="#1-寻求指引" class="headerlink" title="1 寻求指引"></a>1 寻求指引</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">1费</td><td style="text-align:center">任务</td><td style="text-align:center"><strong>任务1</strong>：使用2、3、4费牌各一张，<strong>奖励</strong>：从牌库中发现一张牌，<strong>任务2</strong>：使用5、6费牌各一张，<strong>奖励</strong>：从牌库中发现一张牌，<strong>任务3</strong>：使用7、8费牌各一张，<strong>奖励</strong>：圣徒泽瑞拉（5/8/8，<strong>嘲讽</strong>，<strong>战吼</strong>：将净化的碎片（10费法术：消灭敌方英雄）洗入牌库）</td><td style="text-align:center">单卡 <strong>终结</strong> 对局</td><td style="text-align:center">搭配 <strong>博学者普克尔特</strong>，可实现 <strong>做完任务后两回合终结对局</strong></td></tr></tbody></table><h3 id="3-死亡领主（2-8）"><a href="#3-死亡领主（2-8）" class="headerlink" title="3 死亡领主（2/8）"></a>3 死亡领主（2/8）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">3费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>嘲讽</strong>，<strong>亡语</strong>：将对手牌库中随机的一张随从牌置入敌方战场</td><td style="text-align:center"><strong>亡语</strong> 体系，<strong>防快攻</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="5-黑暗主教本尼迪塔斯"><a href="#5-黑暗主教本尼迪塔斯" class="headerlink" title="5 黑暗主教本尼迪塔斯"></a>5 黑暗主教本尼迪塔斯</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">3费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>对局开始时</strong>：若己方牌库中所有法术都为暗影法术，则进入暗影形态（<strong>英雄技能</strong>（2费）：造成两点伤害）</td><td style="text-align:center"><strong>防快攻</strong>，中前期 <strong>控场</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="10-克苏恩，破碎之劫（6-6）"><a href="#10-克苏恩，破碎之劫（6-6）" class="headerlink" title="10 克苏恩，破碎之劫（6/6）"></a>10 克苏恩，破碎之劫（6/6）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">10费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>对局开始时</strong>：破碎为四张碎片，将超模的三张解牌及一张站场牌洗入牌库，<strong>使用四张碎片后</strong>：融合成 <strong>克苏恩，破碎之劫</strong> 并将其洗入牌库，<strong>战吼</strong>：造成30点伤害随机分配到所有敌人</td><td style="text-align:center">单卡 <strong>终结</strong> 对局</td><td style="text-align:center">非典型</td></tr></tbody></table><h2 id="卡组主体解析（28张）"><a href="#卡组主体解析（28张）" class="headerlink" title="卡组主体解析（28张）"></a>卡组主体解析（28张）</h2><h3 id="1-变色龙卡米洛斯（1-1）"><a href="#1-变色龙卡米洛斯（1-1）" class="headerlink" title="1 变色龙卡米洛斯（1/1）"></a>1 变色龙卡米洛斯（1/1）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">1费</td><td style="text-align:center">随从</td><td style="text-align:center">如果这张牌在手牌中，每回合随机变为对方手牌中的一张牌（抽到的第一回合是本体）</td><td style="text-align:center"><strong>窥屏</strong> 对手手牌</td><td style="text-align:center">搭配 <strong>脏鼠/吞噬者穆坦努斯</strong>，可实现 <strong>精准打击对手key牌</strong></td></tr></tbody></table><h3 id="1-灵魂之匣（1-3）"><a href="#1-灵魂之匣（1-3）" class="headerlink" title="1 灵魂之匣（1/3）"></a>1 灵魂之匣（1/3）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">1费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>吸血</strong>，<strong>亡语</strong>：将 <strong>终极魂匣（7/6/8嘲讽，吸血，不可被敌方法术及英雄技能选中）</strong> 洗入牌库</td><td style="text-align:center"><strong>亡语</strong> 体系，前期 <strong>回血站场</strong>，增加卡组中后期 <strong>厚度</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="2-暗言术：灭（暗影）"><a href="#2-暗言术：灭（暗影）" class="headerlink" title="2 暗言术：灭（暗影）"></a>2 暗言术：灭（暗影）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">2费</td><td style="text-align:center">法术</td><td style="text-align:center">消灭选中 ATK&gt;=5 的随从</td><td style="text-align:center">低费高攻 <strong>单体解</strong></td><td style="text-align:center">搭配 <strong>女王</strong>，可实现 <strong>8费精神控制</strong></td></tr></tbody></table><h3 id="2-暗言术：痛（暗影）"><a href="#2-暗言术：痛（暗影）" class="headerlink" title="2 暗言术：痛（暗影）"></a>2 暗言术：痛（暗影）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">2费</td><td style="text-align:center">法术</td><td style="text-align:center">消灭选中 ATK&lt;=3 的随从</td><td style="text-align:center">低费低攻 <strong>单体解</strong></td><td style="text-align:center">搭配 <strong>脏鼠</strong>，可实现 <strong>低费解决低攻随从类Key牌</strong>（如法师的火妖3/2/4 &amp; 巫师学徒2/3/2）</td></tr></tbody></table><h3 id="2-灵媒术（暗影）"><a href="#2-灵媒术（暗影）" class="headerlink" title="2 灵媒术（暗影）"></a>2 灵媒术（暗影）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">2费</td><td style="text-align:center">法术</td><td style="text-align:center">将选中随从的复制置入己方手牌</td><td style="text-align:center">随从类Key牌 <strong>复制</strong>，根据对局提供 <strong>选择</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="2-暗影视界（暗影）"><a href="#2-暗影视界（暗影）" class="headerlink" title="2 暗影视界（暗影）"></a>2 暗影视界（暗影）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">2费</td><td style="text-align:center">法术</td><td style="text-align:center">在己方牌库中 <strong>发现</strong> 一张法术的复制</td><td style="text-align:center"><strong>发现</strong> 解牌，根据对局提供 <strong>选择</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="2-卑劣的脏鼠（2-6）"><a href="#2-卑劣的脏鼠（2-6）" class="headerlink" title="2 卑劣的脏鼠（2/6）"></a>2 卑劣的脏鼠（2/6）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">2费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>嘲讽</strong>，<strong>战吼</strong>：使你的对手从手牌中随机召唤一个随从</td><td style="text-align:center"><strong>防快攻</strong>，<strong>销毁</strong> 对手随从类Key牌</td><td style="text-align:center">搭配 <strong>铜须</strong>，可实现 <strong>高容错销毁对手的随从类Key牌</strong></td></tr></tbody></table><h3 id="2-了不起的杰弗里斯（3-2）"><a href="#2-了不起的杰弗里斯（3-2）" class="headerlink" title="2 了不起的杰弗里斯（3/2）"></a>2 了不起的杰弗里斯（3/2）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">2费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：若己方牌库中没有相同的牌，<strong>发现</strong>一张完美的牌</td><td style="text-align:center"><strong>宇宙</strong> 体系，<strong>发现</strong> 解牌、斩杀、过牌、保命、大哥选项，根据对局提供 <strong>选择</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="3-布莱恩·铜须（2-4）"><a href="#3-布莱恩·铜须（2-4）" class="headerlink" title="3 布莱恩·铜须（2/4）"></a>3 布莱恩·铜须（2/4）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">3费</td><td style="text-align:center">随从</td><td style="text-align:center">己方随从的 <strong>战吼</strong> 触发两次</td><td style="text-align:center">实现更好的 <strong>战吼</strong> 效果</td><td style="text-align:center">搭配 <strong>某些战吼类随从</strong>，可实现 <strong>原有战吼效果的两倍</strong></td></tr></tbody></table><h3 id="3-拉祖尔女士（3-2）"><a href="#3-拉祖尔女士（3-2）" class="headerlink" title="3 拉祖尔女士（3/2）"></a>3 拉祖尔女士（3/2）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">2费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：<strong>发现</strong> 一张对方手牌的复制</td><td style="text-align:center"><strong>窥屏</strong> 对手手牌</td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="4-祖达克仪祭师（3-9）"><a href="#4-祖达克仪祭师（3-9）" class="headerlink" title="4 祖达克仪祭师（3/9）"></a>4 祖达克仪祭师（3/9）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">4费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>嘲讽</strong>，<strong>战吼</strong>：为对手召唤3个随机的1费随从</td><td style="text-align:center"><strong>防快攻</strong>，<strong>污染</strong> 对手坟场，单卡 <strong>针对</strong> 大哥牧</td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="4-暗言术：毁（暗影）"><a href="#4-暗言术：毁（暗影）" class="headerlink" title="4 暗言术：毁（暗影）"></a>4 暗言术：毁（暗影）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">4费</td><td style="text-align:center">法术</td><td style="text-align:center">消灭所有ATK&gt;=5的随从</td><td style="text-align:center">低费高攻 <strong>群体解</strong></td><td style="text-align:center">搭配 <strong>女王</strong>，可实现 <strong>后期逆风返场</strong></td></tr></tbody></table><h3 id="4-卡扎库斯（3-3）"><a href="#4-卡扎库斯（3-3）" class="headerlink" title="4 卡扎库斯（3/3）"></a>4 卡扎库斯（3/3）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">4费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：若己方牌库没有相同的牌，创建一张自定义法术</td><td style="text-align:center"><strong>宇宙</strong> 体系，<strong>发现</strong> 解牌、直伤、过牌、保命、返场选项，根据对局提供 <strong>选择</strong>，概率抽到变羊选项 <strong>针对</strong> 大哥牧</td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="5-淤泥喷射者（3-5）"><a href="#5-淤泥喷射者（3-5）" class="headerlink" title="5 淤泥喷射者（3/5）"></a>5 淤泥喷射者（3/5）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">5费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>嘲讽</strong>，<strong>亡语</strong>：召唤一个1/1/2具有 <strong>嘲讽</strong> 的软泥怪</td><td style="text-align:center"><strong>亡语</strong> 体系，<strong>防快攻</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="5-黏指狗头人（4-4）"><a href="#5-黏指狗头人（4-4）" class="headerlink" title="5 黏指狗头人（4/4）"></a>5 黏指狗头人（4/4）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">5费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：偷取对手的武器</td><td style="text-align:center"><strong>销毁</strong> 对手武器类Key牌，单卡 <strong>针对</strong> 弑君贼、剽窃贼</td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="5-缚链者拉兹（5-5）"><a href="#5-缚链者拉兹（5-5）" class="headerlink" title="5 缚链者拉兹（5/5）"></a>5 缚链者拉兹（5/5）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">5费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：若己方牌库没有相同的牌，将英雄技能置为0费</td><td style="text-align:center"><strong>宇宙</strong> 体系，中前期低成本 <strong>回血</strong>、中后期低成本 <strong>控场</strong></td><td style="text-align:center">搭配 <strong>暗影收割者安度因</strong>，可实现 <strong>中后期低成本的直伤</strong></td></tr></tbody></table><h3 id="5-博学者普克尔特（4-5）"><a href="#5-博学者普克尔特（4-5）" class="headerlink" title="5 博学者普克尔特（4/5）"></a>5 博学者普克尔特（4/5）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">5费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：将己方牌库按费用消耗从高到低排序</td><td style="text-align:center">中后期稳定的 <strong>定向</strong> 检索</td><td style="text-align:center">搭配 <strong>寻求指引（净化的碎片）/克苏恩，破碎之劫</strong>，可实现 <strong>中后期稳定的斩杀</strong></td></tr></tbody></table><h3 id="5-希尔瓦娜斯·风行者（5-5）"><a href="#5-希尔瓦娜斯·风行者（5-5）" class="headerlink" title="5 希尔瓦娜斯·风行者（5/5）"></a>5 希尔瓦娜斯·风行者（5/5）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">6费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>亡语</strong>：随机获得一个敌方随从的控制权</td><td style="text-align:center"><strong>亡语</strong> 体系，单卡 <strong>站场</strong></td><td style="text-align:center">搭配 <strong>高攻解牌</strong>，可实现 <strong>解场返场</strong></td></tr></tbody></table><h3 id="6-雷诺·杰克逊（4-6）"><a href="#6-雷诺·杰克逊（4-6）" class="headerlink" title="6 雷诺·杰克逊（4/6）"></a>6 雷诺·杰克逊（4/6）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">6费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：若己方牌库没有相同的牌，为己方英雄回复所有生命值</td><td style="text-align:center"><strong>宇宙</strong> 体系，<strong>回血</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="7-心灵尖啸（暗影）"><a href="#7-心灵尖啸（暗影）" class="headerlink" title="7 心灵尖啸（暗影）"></a>7 心灵尖啸（暗影）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">7费</td><td style="text-align:center">法术</td><td style="text-align:center">将所有随从洗入对手牌库</td><td style="text-align:center"><strong>污染</strong> 对手牌库，无副作用的 <strong>群体解</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="7-大主教本尼迪塔斯（4-6）"><a href="#7-大主教本尼迪塔斯（4-6）" class="headerlink" title="7 大主教本尼迪塔斯（4/6）"></a>7 大主教本尼迪塔斯（4/6）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">7费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：复制对手的牌库并洗入己方牌库</td><td style="text-align:center"><strong>防爆牌</strong>，单卡 <strong>针对</strong> 爆牌贼、宇宙术（提克特斯）</td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="7-灵魂之镜（暗影）"><a href="#7-灵魂之镜（暗影）" class="headerlink" title="7 灵魂之镜（暗影）"></a>7 灵魂之镜（暗影）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">7费</td><td style="text-align:center">法术</td><td style="text-align:center">召唤所有敌方随从的复制，并使敌方随从与其对应复制相互攻击</td><td style="text-align:center"><strong>群体解</strong>，<strong>逆风返场</strong>，为 <strong>亡语</strong> 体系积累素材（唤醒造物者、恩佐斯）</td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="7-吞噬者穆坦努斯（4-4）"><a href="#7-吞噬者穆坦努斯（4-4）" class="headerlink" title="7 吞噬者穆坦努斯（4/4）"></a>7 吞噬者穆坦努斯（4/4）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">7费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：吃掉对手手牌中的一张随机随从牌，并在7/4/4原有基础上叠加该随从的ATK、HP</td><td style="text-align:center"><strong>销毁</strong> 对手随从类Key牌</td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="8-暗影收割者安度因（护甲-5）"><a href="#8-暗影收割者安度因（护甲-5）" class="headerlink" title="8 暗影收割者安度因（护甲+5）"></a>8 暗影收割者安度因（护甲+5）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">8费</td><td style="text-align:center">死骑</td><td style="text-align:center"><strong>战吼</strong>：消灭所有ATK&gt;=5的随从，<strong>英雄技能</strong>（2费）：造成2点伤害，使用卡牌后重置英雄技能</td><td style="text-align:center">高攻 <strong>群体解</strong>，中后期 <strong>控场</strong></td><td style="text-align:center">搭配 <strong>缚链者拉兹</strong>，可实现 <strong>中后期低成本的直伤</strong></td></tr></tbody></table><h3 id="8-耶比托·乔巴斯（6-6）"><a href="#8-耶比托·乔巴斯（6-6）" class="headerlink" title="8 耶比托·乔巴斯（6/6）"></a>8 耶比托·乔巴斯（6/6）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">8费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：从牌库中抽取两张随从牌，将抽到的牌变为1/1/1</td><td style="text-align:center"><strong>过牌</strong>，中后期较稳定的 <strong>定向</strong> 检索</td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="9-黑曜石雕像（4-8）"><a href="#9-黑曜石雕像（4-8）" class="headerlink" title="9 黑曜石雕像（4/8）"></a>9 黑曜石雕像（4/8）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">9费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>嘲讽</strong>，<strong>吸血</strong>，<strong>亡语</strong>：随机消灭一个敌方随从</td><td style="text-align:center"><strong>亡语</strong> 体系，中后期单卡 <strong>回血站场</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="9-红龙女王阿莱克斯塔萨（8-8）"><a href="#9-红龙女王阿莱克斯塔萨（8-8）" class="headerlink" title="9 红龙女王阿莱克斯塔萨（8/8）"></a>9 红龙女王阿莱克斯塔萨（8/8）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">9费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：若己方牌库没有相同的牌，将两张其他龙牌置入己方手牌并置为0费</td><td style="text-align:center"><strong>宇宙</strong> 体系，后期单回合 <strong>返场</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h3 id="10-恩佐斯（5-7）"><a href="#10-恩佐斯（5-7）" class="headerlink" title="10 恩佐斯（5/7）"></a>10 恩佐斯（5/7）</h3><table><thead><tr><th style="text-align:center">费用</th><th style="text-align:center">属性</th><th style="text-align:center">效果</th><th style="text-align:center">价值</th><th style="text-align:center">Combo</th></tr></thead><tbody><tr><td style="text-align:center">10费</td><td style="text-align:center">随从</td><td style="text-align:center"><strong>战吼</strong>：召唤所有本局对战中己方死亡的具有 <strong>亡语</strong> 的随从</td><td style="text-align:center"><strong>亡语</strong> 体系，中后期单回合 <strong>返场</strong></td><td style="text-align:center">非典型</td></tr></tbody></table><h1 id="宇宙萨"><a href="#宇宙萨" class="headerlink" title="宇宙萨"></a>宇宙萨</h1><h2 id="卡组一览-1"><a href="#卡组一览-1" class="headerlink" title="卡组一览"></a>卡组一览</h2><center><iframe src="https://hsdeck.herokuapp.com/?name=%E5%AE%87%E5%AE%99%E8%90%A8&code=AAEBAaoIHvUEsgaTCfoOwxb6qgKIrwL5vwKXwQLHwQLfxAKbywKr5wLz5wLg6gLv8QLv9wKtkQO9mQP8owPPpQPhpQPhqAOIsQPDtgPgzAOczgP21gOm7wOvnwQAAA==" border="0" frameborder="no" style="width: 100%; height: 1600px; transform: scale(1.0); transform-origin: 0 top 0; border-radius: 4px; box-shadow: 0 1px 20px -6px rgba(0,0,0,.5) !important;"></iframe></center><h2 id="卡组代码-1"><a href="#卡组代码-1" class="headerlink" title="卡组代码"></a>卡组代码</h2><pre><code>AAEBAaoIHvUEsgaTCfoOwxb6qgKIrwL5vwKXwQLHwQLfxAKbywKr5wLz5wLg6gLv8QLv9wKtkQO9mQP8owPPpQPhpQPhqAOIsQPDtgPgzAOczgP21gOm7wOvnwQAAA==</code></pre><h1 id="宇宙术"><a href="#宇宙术" class="headerlink" title="宇宙术"></a>宇宙术</h1><h2 id="卡组一览-2"><a href="#卡组一览-2" class="headerlink" title="卡组一览"></a>卡组一览</h2><center><iframe src="https://hsdeck.herokuapp.com/?name=%E5%AE%87%E5%AE%99%E6%9C%AF&code=AAEBAcn1Ah7OBtsGkgfOB8wI1hHDFoUX2LsC38QC58sCxcwCks0Cl9MC6OcCnPgC2p0D/KMD66wD7qwDkbEDv7kDxLkDkt4DzuED9uMD+OMDpu8D/voDh/sDAAA=" border="0" frameborder="no" style="width: 100%; height: 1600px; transform: scale(1.0); transform-origin: 0 top 0; border-radius: 4px; box-shadow: 0 1px 20px -6px rgba(0,0,0,.5) !important;"></iframe></center><h2 id="卡组代码-2"><a href="#卡组代码-2" class="headerlink" title="卡组代码"></a>卡组代码</h2><pre><code>AAEBAcn1Ah7OBtsGkgfOB8wI1hHDFoUX2LsC38QC58sCxcwCks0Cl9MC6OcCnPgC2p0D/KMD66wD7qwDkbEDv7kDxLkDkt4DzuED9uMD+OMDpu8D/voDh/sDAAA=</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://hsdeck.herokuapp.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;卡组api&lt;/a&gt; 调用自文章 &lt;a href=&quot;https://zhangshuqiao.org/2018-12/%E
      
    
    </summary>
    
      <category term="生活" scheme="/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="游戏" scheme="/tags/%E6%B8%B8%E6%88%8F/"/>
    
  </entry>
  
  <entry>
    <title>大阪隔离记录（在留卡再入国）</title>
    <link href="/2021/02/17/%E5%A4%A7%E9%98%AA%E9%9A%94%E7%A6%BB%E8%AE%B0%E5%BD%95%EF%BC%88%E5%9C%A8%E7%95%99%E5%8D%A1%E5%86%8D%E5%85%A5%E5%9B%BD%EF%BC%89/"/>
    <id>/2021/02/17/大阪隔离记录（在留卡再入国）/</id>
    <published>2021-02-17T14:30:48.000Z</published>
    <updated>2021-11-25T09:15:46.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="大阪隔离记录（在留卡再入国）"><a href="#大阪隔离记录（在留卡再入国）" class="headerlink" title="大阪隔离记录（在留卡再入国）"></a>大阪隔离记录（在留卡再入国）</h1><h2 id="1-入境前准备"><a href="#1-入境前准备" class="headerlink" title="1 入境前准备"></a>1 入境前准备</h2><h3 id="1-1-资料准备"><a href="#1-1-资料准备" class="headerlink" title="1.1 资料准备"></a>1.1 资料准备</h3><ul><li style="list-style: none"><input type="checkbox" checked> 在留卡、护照等必要证件</li><li style="list-style: none"><input type="checkbox" checked> 72小时内核酸证明 [1]（<strong>中英版本</strong> <strong>必须鼻咽拭子</strong> 咽拭子不可以 标本类型也最好写着英文版的鼻咽拭子）</li><li style="list-style: none"><input type="checkbox" checked> 核酸证明的誓约书（日本国驻华大使馆官网）</li></ul><h3 id="1-2-预定准备"><a href="#1-2-预定准备" class="headerlink" title="1.2 预定准备"></a>1.2 预定准备</h3><ul><li style="list-style: none"><input type="checkbox" checked> 航班预定（最好定<strong>中国航司直航</strong> 转机有很高的被取消风险）</li><li style="list-style: none"><input type="checkbox" checked> 酒店预定 [2]（<strong>共15晚</strong> 官方说法是14天不包括入境单天）</li><li style="list-style: none"><input type="checkbox" checked> 接机预定 [3]（携程上关西机场到大阪市区接机要700人民币左右）</li></ul><h3 id="1-3-一些解释"><a href="#1-3-一些解释" class="headerlink" title="1.3 一些解释"></a>1.3 一些解释</h3><p>[1] 截止写文之日，日本多个县还处于紧急状态之中，入境日本的人仅包括日本人、在留卡再入国以及永驻，不包括新签证以及之前谈好的商务签相关通道。<br>[2] 入境日本需要在不使用公共交通的前提下，在入境时报告的逗留地址或自己的住址自主隔离14天，期间避免乘坐公共交通，避免三密。因此若没有方法乘坐私车前往住址，则只能选择在酒店隔离。因为最近一直处于紧急状态，旅游业淡季，实际上大阪市内现在有很多便宜酒店。<br>[3] 关西机场建立在一个人工岛之上，与内陆仅靠跨海大桥相连，行人无法步行通过。因此，想要离开机场前往酒店进行隔离不能依靠步行而只能依靠接机。否则只能选择步行关西机场内唯一的酒店进行隔离，价格比较昂贵。</p><h2 id="2-入境当天流程"><a href="#2-入境当天流程" class="headerlink" title="2 入境当天流程"></a>2 入境当天流程</h2><h3 id="2-1-环境介绍"><a href="#2-1-环境介绍" class="headerlink" title="2.1 环境介绍"></a>2.1 环境介绍</h3><p>起飞：上海浦东国际机场<br>到达：大阪关西国际机场<br>航班：吉祥航空HO1333</p><h3 id="2-2-入境流程"><a href="#2-2-入境流程" class="headerlink" title="2.2 入境流程"></a>2.2 入境流程</h3><ol><li>值机前，工作人员会要求乘客填写日本入境要求填写的问卷，并生成二维码。该二维码需要截屏保存。</li><li>值机前，工作人员还会要求乘客填写中国出境的健康申报书，并生成二维码。该二维码也需要截屏保存。</li><li>值机前，工作人员会检查乘客的72小时内PCR证明以及相关证件确保乘客拥有日本政府要求的入境基本条件。</li><li>值机办理托运后，海关离境前，工作人员会扫描2中要求的出境健康申报书，符合要求后才会进行出境相关手续的办理和盖章。</li><li>登机、起飞（飞行过程中照例会要求填写报税的项目）、到达。</li><li>到达机场后，会有很多会中文的中日工作人员帮助办理入境。</li><li>入境前，排队按顺序领试管进行唾液的新冠检查（试管和资料上会写着编号）。</li><li>入境前，扫描1中要求的二维码，提交核算证明原件及誓约书，填写新发的遵守隔离政策的誓约书，等待唾液检查的结果（大屏幕上会显示已经出结果的编号）。</li><li>核酸阴性结果显示后，拿着手上的誓约书和其他资料换一张红色的纸片以表示核酸检查没问题，之后找行李并办理出境手续。</li><li>联系接机并正常办理酒店入住（酒店并不会把你当成隔离人员特殊照顾）。</li></ol><h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3 总结"></a>3 总结</h2><p>因为前期查了很多资料，做了各种准备，这次紧急状态期间的入境总耗时实际上也只有一个多小时，最后也在天黑之前顺利到达酒店办理了入住。虽然结果是很轻松也很顺利，但实际上在没顺利通过日本海关之前，谁都没办法掉以轻心。希望这个流程记录能或多或少帮到你，也希望还没入境的大家都能顺利入境。</p><h2 id="附：隔离期间的三餐-便利店便当大赏"><a href="#附：隔离期间的三餐-便利店便当大赏" class="headerlink" title="附：隔离期间的三餐 便利店便当大赏"></a>附：隔离期间的三餐 <span class="heimu" title="好奇心过剩呐～"><del>便利店便当大赏</del></span></h2><h3 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h3><p>Family Mart含税价格：</p><ul><li>汉堡肉便当@598日元</li><li>热狗 * 2@128日元 * 2</li><li>四川麻婆豆腐盖饭@430日元</li><li>酱油拉面@598日元</li></ul><center><a href="https://z3.ax1x.com/2021/02/21/yodrFS.jpg" data-fancybox="images" data-caption="Day1" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/02/21/yodrFS.jpg"></a></center><h3 id="Day-2"><a href="#Day-2" class="headerlink" title="Day 2"></a>Day 2</h3><p>Family Mart含税价格：</p><ul><li>🍌@108日元</li><li>🍣卷@430日元</li><li>奶油巧克力豆夹心🍞 * 2@138日元 * 2</li><li>汉堡肉🍱@598日元</li><li>金枪鱼🥗@220日元</li><li>炸鸡块🍱@460日元</li></ul><center><a href="https://z3.ax1x.com/2021/02/21/yod2yn.jpg" data-fancybox="images" data-caption="Day2" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/02/21/yod2yn.jpg"></a></center><h3 id="Day-3"><a href="#Day-3" class="headerlink" title="Day 3"></a>Day 3</h3><p>7-11不含税价格：</p><ul><li>脆皮🌭 * 2@150日元 * 2</li><li>🍣卷@298日元</li><li>巧克力🍩 * 2@178日元 * 2</li><li>金枪鱼🥗@198日元</li><li>酱油方便🍜@128日元</li><li>炸鸡块🍱@540日元</li><li>培根芝士🍝@398日元</li></ul><center><a href="https://z3.ax1x.com/2021/02/21/yowctO.jpg" data-fancybox="images" data-caption="Day3" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/02/21/yowctO.jpg"></a></center><h3 id="Day-4"><a href="#Day-4" class="headerlink" title="Day 4"></a>Day 4</h3><p>Family Mart含税价格：</p><ul><li>鸡油方便🍜@149日元</li><li>培根🍞 * 2@138日元 * 2</li><li>🍣卷@430日元</li><li>牛肉盖饭@430日元</li><li>广岛风什锦烧@550日元</li></ul><center><a href="https://z3.ax1x.com/2021/02/21/yo0yKs.jpg" data-fancybox="images" data-caption="Day4" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/02/21/yo0yKs.jpg"></a></center><h3 id="Day-X"><a href="#Day-X" class="headerlink" title="Day X"></a>Day X</h3><p>基本就这几种，重复不发了。。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;大阪隔离记录（在留卡再入国）&quot;&gt;&lt;a href=&quot;#大阪隔离记录（在留卡再入国）&quot; class=&quot;headerlink&quot; title=&quot;大阪隔离记录（在留卡再入国）&quot;&gt;&lt;/a&gt;大阪隔离记录（在留卡再入国）&lt;/h1&gt;&lt;h2 id=&quot;1-入境前准备&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="生活" scheme="/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="COVID-19" scheme="/tags/COVID-19/"/>
    
  </entry>
  
  <entry>
    <title>如何理解 CNN</title>
    <link href="/2021/02/10/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%20CNN/"/>
    <id>/2021/02/10/如何理解 CNN/</id>
    <published>2021-02-10T10:32:32.000Z</published>
    <updated>2021-02-10T10:32:32.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>本文参考<br>[1] <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" target="_blank" rel="noopener">Gradiant-Based Learning Applied to Document Recognition</a><br>[2] <a href="https://cs231n.github.io/" target="_blank" rel="noopener">CS231n Convolutional Neural Networks for Visual Recognition /Stanford</a></li></ul><h1 id="1-如何理解CNN"><a href="#1-如何理解CNN" class="headerlink" title="1 如何理解CNN"></a>1 如何理解CNN</h1><h2 id="1-1-什么是CNN"><a href="#1-1-什么是CNN" class="headerlink" title="1.1 什么是CNN"></a>1.1 什么是CNN</h2><p><strong>CNN模型</strong> 通常被认为始于Yann LeCun在1998年发表的文章 <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" target="_blank" rel="noopener">Gradiant-Based Learning Applied to Document Recognition</a>，该模型通常被称为 <strong>LeNet</strong>。</p><center><a href="https://s3.ax1x.com/2021/02/10/y0PaWV.png" data-fancybox="images" data-caption="LeNet的模型结构" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/02/10/y0PaWV.png"></a></center><center><strong>图1.1 LeNet的模型结构[1]</strong></center><p><strong>图1.1</strong> 为原文[1]中的配图，描述了一个两层卷积的CNN模型。</p><p>CNN（Convoolutional Neural Network）：</p><ol><li>CNN，卷积神经网络，是一种使用卷积层提取图像特征，再经过池化层保留重要特征的深度学习模型。</li><li>模型通常用于图像处理，能够很好的提取图像特征。</li></ol><p>符号理解：</p><ol><li>INPUT：输入图像是一个32*32的图像。虽然图像显示的是个A，但原文写的是Digits Recognition。</li><li>Convolutions：将32*32的输入图像经过一个5*5的卷积核得到28*28的输出图像。这个卷积核即为传统神经网络中的参数矩阵，在该模型中第一层卷积共有6个经过初始化的卷积核。卷积核的概念可以参考数字图像处理算法中的滤波器，类似滤镜，例如 <a href="/2020/02/12/opencv边缘检测%20C++实现/#3-5-高斯滤波">高斯滤波</a>。</li><li>Feature Maps：经过卷积核得到的中间输出图像被称为特征图，模型希望通过多个特征图来获取不同的特征。个人感觉该机制与Multi-Head Mechanism中的Multi-Head很相似。</li><li>Subsampling：下采样，减少输出维度，在该领域主要体现为Pooling，即池化。个人理解池化的目的是用于保留并突出重要信息，下文将详细说明池化的实现。</li><li>Full connection：全连接层，多称为Fully Connected Layer。用于将高维张量映射为向量，最终经过高斯分布得到对应每个Digits的概率。</li></ol><h2 id="1-2-LeNet的模型架构"><a href="#1-2-LeNet的模型架构" class="headerlink" title="1.2 LeNet的模型架构"></a>1.2 LeNet的模型架构</h2><h3 id="1-2-1-图像输入"><a href="#1-2-1-图像输入" class="headerlink" title="1.2.1 图像输入"></a>1.2.1 图像输入</h3><center><div style="width: 200px;"><a href="https://s3.ax1x.com/2021/02/10/y0P2Jx.png" data-fancybox="images" data-caption="LeNet的输入图像" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/02/10/y0P2Jx.png"></a></div></center><center><strong>图1.2 LeNet的输入图像[1]</strong></center><p>将32*32的原始图像输入到模型中。</p><h3 id="1-2-2-第一层卷积"><a href="#1-2-2-第一层卷积" class="headerlink" title="1.2.2 第一层卷积"></a>1.2.2 第一层卷积</h3><center><div style="width: 400px;"><a href="https://s3.ax1x.com/2021/02/10/y0PfSK.png" data-fancybox="images" data-caption="LeNet的第一层卷积" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/02/10/y0PfSK.png"></a></div></center><center><strong>图1.3 LeNet的第一层卷积[1]</strong></center><p>第一个卷积层将输入的32*32的原始图像经过6个5*5的初始化的卷积核分别得到6个28*28的特征图C1。卷积的本质我认为就是element-wise的加权求和。</p><h3 id="1-2-3-第一层下采样"><a href="#1-2-3-第一层下采样" class="headerlink" title="1.2.3 第一层下采样"></a>1.2.3 第一层下采样</h3><center><div style="width: 400px;"><a href="https://s3.ax1x.com/2021/02/10/y0PfSK.png" data-fancybox="images" data-caption="LeNet的第一层下采样" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/02/10/y0PfSK.png"></a></div></center><center><strong>图1.4 LeNet的第一层下采样[1]</strong></center><p>下采样在该模型上的体现即为池化。池化也可以理解为是卷积的一种，只不过池化有时候可能不存在有意义的卷积核（广义的卷积），比如最常用的池化方法max-pooling，如图1.5所示：</p><center><a href="https://s3.ax1x.com/2021/02/10/y0PqYt.png" data-fancybox="images" data-caption="max-pooling示意图" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/02/10/y0PqYt.png"></a></center><center><strong>图1.5 max-pooling示意图[2]</strong></center><p>在max-pooling中，上一层28*28的特征图C1将被分为14*14个2*2的block，模型将选出每个block中的最大值，并将最大值作为这个block的结果输出到下一层中，最终生成下一层14*14的特征图S2。</p><p>池化方法有很多种：</p><ol><li>max-pooling（取block最大值）</li><li>mean-pooling（取block平均值，即经过一个平均卷积核）</li><li>高斯池化（经过一个高斯模糊卷积核）</li><li>可训练池化（经过一个可训练的初始化的卷积核）</li></ol><p>但在Le-Net中，原文提到：<br>The four inputs to a unit in S2 are added, then multiplied by a trainable coefficient, and added to a trainable bias …… Layer S2 has 12 trainable parameters …… </p><p>即LeNet在下采样部分并没有使用现在流行的所谓pooling方法，而是将block内的像素值相加后乘上参数w再加上偏置b。最终针对6个不同的特征图将会有6对(w, b)的组合，即12个可训练参数。</p><p>我想这也可以算是可训练池化的一种。</p><h3 id="1-2-4-第二层卷积与下采样"><a href="#1-2-4-第二层卷积与下采样" class="headerlink" title="1.2.4 第二层卷积与下采样"></a>1.2.4 第二层卷积与下采样</h3><center><div style="width: 400px;"><a href="https://s3.ax1x.com/2021/02/10/y0PXSf.png" data-fancybox="images" data-caption="第二层卷积与下采样" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/02/10/y0PXSf.png"></a></div></center><center><strong>图1.6 第二层卷积与下采样[2]</strong></center><p>在第二轮的卷积中，模型通过一定的规则将经过第一轮卷积池化的6个特征图S2映射为16个特征图。</p><center><a href="https://s3.ax1x.com/2021/02/10/y0iSmQ.png" data-fancybox="images" data-caption="第二层卷积的映射关系" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/02/10/y0iSmQ.png"></a></center><center><strong>表1.1 第二层卷积的映射关系[2]</strong></center><p>在LeNet中，原文提到这样映射的原因以及如何映射：</p><ol><li><strong>Why not</strong> connect every S2 feature map to every C3 feature map?<br><strong>The reason</strong> is twofold. <strong>First</strong>, a non-complete connection sheme keeps the number of connection <strong>within reasonable bounds</strong>. <strong>More importantly</strong>, it forces <strong>a break of symmetry</strong> in the network.<br><strong>Different feature maps are forced to extract different(hopefully complementary) features because they get different sets of inputs.</strong></li><li>The rationale behind the connection sheme in the table Ⅰ is the followings.<br><strong>The first six</strong> C3 feature maps take inputs from <strong>every contiguous subsets of three</strong> feature maps in S2. <strong>(Column 0-5)</strong><br><strong>The next six</strong> take input from <strong>every contiguous subset of four</strong>. <strong>(Column 6-11)</strong><br><strong>The next three</strong> take input from some <strong>discontiiguous subsets of four</strong>. <strong>(Column 12-14)</strong><br><strong>Finally the last one</strong> takes input from <strong>all S2</strong> feature maps. <strong>(Column 15)</strong></li><li>Layer C3 has 1516 trainable parameters ……</li></ol><p>即LeNet在第二层卷积中：</p><ol><li>没有使用6张S2特征图到16张C3特征图的全映射，而是使用了 <strong>表1.1</strong> 的映射规律。</li><li>映射规律中，<strong>列0-5</strong> 使用了循环连续的三连特征图（理解为tri-gram），<strong>列6-11</strong> 使用了循环连续的四连特征图（理解为qua-gram），<strong>列12-14</strong> 使用了循环不连续的四连特征图（理解为两个bi-gram），<strong>列15</strong> 使用了S2全部特征图。</li><li>对于每个特征图到特征图的映射，需要一个5*5的初始化的卷积核，故共需要 25 * (3*6 + 4*6 + 4*3 + 6) + 16 = 1516 个参数。<br>其中，25是每个卷积核的参数量，16是16个列每列对应偏置的参数量。</li></ol><p>在第二层下采样中，采取了和第一层C1-S2相同的池化方式。通过选取无重叠的2*2block的最大值对C3进行max-pooling，将10*10的C3特征图池化为5*5的S4特征图。</p><h3 id="1-2-5-第三层卷积以及全连接层"><a href="#1-2-5-第三层卷积以及全连接层" class="headerlink" title="1.2.5 第三层卷积以及全连接层"></a>1.2.5 第三层卷积以及全连接层</h3><center><a href="https://s3.ax1x.com/2021/02/10/y0iPkn.png" data-fancybox="images" data-caption="第三层卷积以及全连接层" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/02/10/y0iPkn.png"></a></center><center><strong>图1.7 第三层卷积以及全连接层[2]</strong></center><p>第三层池化将第二层卷积池化后5*5的S4特征图再通过一定的规则经过5*5的卷积核卷积后得到120个1*1的特征图。</p><center><strong>表1.2 第三层卷积的映射关系</strong></center><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">0</th><th style="text-align:center">1</th><th style="text-align:center">…</th><th style="text-align:center">120</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">X</td><td style="text-align:center">X</td><td style="text-align:center">…</td><td style="text-align:center">X</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">X</td><td style="text-align:center">X</td><td style="text-align:center">…</td><td style="text-align:center">X</td></tr><tr><td style="text-align:center">…</td><td style="text-align:center">…</td><td style="text-align:center">…</td><td style="text-align:center">…</td><td style="text-align:center">…</td></tr><tr><td style="text-align:center">16</td><td style="text-align:center">X</td><td style="text-align:center">X</td><td style="text-align:center">X</td><td style="text-align:center">X</td></tr></tbody></table><p>在 <strong>图1.7</strong> 中，S4-C5下方的注释将这个过程称为全连接。而在LeNet原文中是这样描述的：<br>C5 is labeled as a convolutional layer, instead of a fully-connected layer, because if LeNet-5 input were made bigger with everything else kept constant, the feature map dimension would be larger than 1*1.<br>即C5在 <strong>图1.7</strong> 中表现为全连接只是一个巧合，实际情况当 <a href="/2021/02/10/如何理解%20CNN/#1-2-1-图像输入">1.2.1</a> 的输入图像像素量变大时，可能会出现C5为X*X。</p><p>C5经过一个全连接层将120维的向量转换为84个（似乎是为了与ASCII匹配），在经过一个高斯连接层（还没来得及搞明白这层）映射为一个10维向量（与10个数字匹配）。</p><h2 id="1-3-待续"><a href="#1-3-待续" class="headerlink" title="1.3 待续"></a>1.3 待续</h2><h1 id="2-TextCNN"><a href="#2-TextCNN" class="headerlink" title="2 TextCNN"></a>2 TextCNN</h1><p>待续。。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;本文参考&lt;br&gt;[1] &lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Gradiant-Based Learning App
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="NLP" scheme="/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>2020 全年更新日志</title>
    <link href="/2021/02/10/2020%20%E5%85%A8%E5%B9%B4%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97/"/>
    <id>/2021/02/10/2020 全年更新日志/</id>
    <published>2021-02-10T10:28:14.000Z</published>
    <updated>2021-02-10T10:28:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2020-全年更新日志"><a href="#2020-全年更新日志" class="headerlink" title="2020 全年更新日志"></a>2020 全年更新日志</h1><h2 id="2020-11-30更新日志"><a href="#2020-11-30更新日志" class="headerlink" title="2020.11.30更新日志"></a>2020.11.30更新日志</h2><ol><li>歌词api：<a href="http://music.163.com/api/song/media?id=1408319824" target="_blank" rel="noopener">http://music.163.com/api/song/media?id=1408319824</a></li><li>bilibili播放器：<div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><br> <iframe src="//player.bilibili.com/player.html?aid=800312111&bvid=BV1by4y1z7Pb&cid=256908064&page=1&high_quality=1&danmuku=0&t=1397" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe><br></div></li></ol><h2 id="2020-11-12更新日志"><a href="#2020-11-12更新日志" class="headerlink" title="2020.11.12更新日志"></a>2020.11.12更新日志</h2><ol><li>为上次更新的新歌单页重新设置toc对齐offset。</li><li>新日志中涉及了自定义歌词的html结构设置。</li></ol><h2 id="2020-09-28更新日志"><a href="#2020-09-28更新日志" class="headerlink" title="2020.09.28更新日志"></a>2020.09.28更新日志</h2><ol><li>将Valine评论更新并引入。</li><li>通过在sakara_app.js中使用$(document).ready(function(){})解决Valine刷新之后不执行的问题。</li><li>优化了歌单、归档、关于三个界面的标题显示，并将这三个界面的页面结构进行统一。</li></ol><h2 id="2020-08-09更新日志"><a href="#2020-08-09更新日志" class="headerlink" title="2020.08.09更新日志"></a>2020.08.09更新日志</h2><ol><li>将mathjax更新为国内cdn（<a href="https://cdn.baomitu.com/mathjax）。" target="_blank" rel="noopener">https://cdn.baomitu.com/mathjax）。</a></li><li>将mathjax位置由common-article.ejs调整至footer.ejs（common-article.ejs部分似乎受异步加载限制，刷新后无法加载js，故将mathjax调整至不受限制的footer部分）</li></ol><h2 id="2020-07-17更新日志"><a href="#2020-07-17更新日志" class="headerlink" title="2020.07.17更新日志"></a>2020.07.17更新日志</h2><ol><li>调整toc与实际文章标题对应的offset，使对齐（sakara_app.js）。</li><li>调整搜索菜单的tag显示数量以及tag、分类、文章的显示顺序（InsightSearch.js）。</li></ol><h2 id="2020-07-16更新日志"><a href="#2020-07-16更新日志" class="headerlink" title="2020.07.16更新日志"></a>2020.07.16更新日志</h2><ol><li>增加表格边框</li></ol><h2 id="2020-07-05更新日志"><a href="#2020-07-05更新日志" class="headerlink" title="2020.07.05更新日志"></a>2020.07.05更新日志</h2><ol><li>将centerbg-background的参考系设为center center，实现对中心的缩放（style.css）。</li><li>优化手机端观感。将手机端沉浸背景去掉，因为适配时比例会出现问题。通过@media限制低宽度（&lt;400px）分辨率的页面将centerbg高度设为固定，并将page的背景设为白（style.css）。</li><li>优化手机端观感。为主页post的某些宽度情况添加阴影以及margin（style.css）。</li><li>优化归档、标签页观感。为归档和标签页增加半透明背景内衬（style.css）。</li></ol><h2 id="2020-07-03更新日志"><a href="#2020-07-03更新日志" class="headerlink" title="2020.07.03更新日志"></a>2020.07.03更新日志</h2><ol><li>去掉首页视频以及视频播放按钮（style.css）</li></ol><h2 id="2020-06-18更新日志"><a href="#2020-06-18更新日志" class="headerlink" title="2020.06.18更新日志"></a>2020.06.18更新日志</h2><ol><li>沉浸背景（sakara_app.js中赋予content与centerbg同样的style）</li><li>樱花特效（footer.ejs中添加特效插件）</li><li>为post页本地图片pattern-center以及toc-list添加border（style.css），设置pattern-center的max-width为1080px（max-width可以保证与主页面大小同时缩放，width的话溢出部分不会缩进）</li><li>主页设置content为透明，post-list为不透明；博文页设置entry-content（博文页文字部分）为半透明，toc为半透明。</li></ol><h2 id="2020上半年更新日志"><a href="#2020上半年更新日志" class="headerlink" title="2020上半年更新日志"></a>2020上半年更新日志</h2><p>4月：</p><ol><li>优化了音乐播放器的歌词宽度匹配。</li></ol><p>5月：</p><ol><li>调整歌单界面播放器，解决了之前列表与主题重叠的问题，将歌词居中，限制播放器最大宽度500px。</li><li>为歌单界面增加了与文章界面相同的标题分层链接toc。</li><li>调整二级标题的指示符号为蓝色的 | 。</li><li>调整了主页播放器歌词显示逻辑，禁止其在歌单页显示歌词与其他播放器冲突。（aplayer.ejs）</li><li>更新了关于本人页。（botui.js）</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;2020-全年更新日志&quot;&gt;&lt;a href=&quot;#2020-全年更新日志&quot; class=&quot;headerlink&quot; title=&quot;2020 全年更新日志&quot;&gt;&lt;/a&gt;2020 全年更新日志&lt;/h1&gt;&lt;h2 id=&quot;2020-11-30更新日志&quot;&gt;&lt;a href=&quot;#202
      
    
    </summary>
    
      <category term="生活" scheme="/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="更新日志" scheme="/tags/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97/"/>
    
  </entry>
  
  <entry>
    <title>2021 年前总结</title>
    <link href="/2021/02/10/2021%20%E5%B9%B4%E5%89%8D%E6%80%BB%E7%BB%93/"/>
    <id>/2021/02/10/2021 年前总结/</id>
    <published>2021-02-10T10:23:30.000Z</published>
    <updated>2021-02-10T10:23:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2021-年前总结"><a href="#2021-年前总结" class="headerlink" title="2021 年前总结"></a>2021 年前总结</h1><p>现在是2021.02.10下午，去年的这会儿我大概正在为回国机票突然被取消而感到慌张。过去的一年对我来说非常特别，毕竟是十多年求学生涯的第一次家里蹲学习。因为这样那样的事情，虽然总的来说谈不上全力以赴，至少也算是稍微学到了些东西吧。</p><h2 id="2020-03"><a href="#2020-03" class="headerlink" title="2020.03"></a>2020.03</h2><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> <a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">BERT论文阅读</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/03/13/语音和语言处理第三版%202.1%20正则表达式/">Speech and LanguageProcessing基础理解</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="https://www.bilibili.com/video/BV1r4411f7td" target="_blank" rel="noopener">Stanford CS224N</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/03/21/日语语法%204.1%20敬语和动词词根/">日语语法Chapter 4</a></li></ul><p>生活：</p><ul><li style="list-style: none"><input type="checkbox" checked> CSGO入门</li></ul><h2 id="2020-04"><a href="#2020-04" class="headerlink" title="2020.04"></a>2020.04</h2><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> <a href="https://arxiv.org/abs/1908.08345" target="_blank" rel="noopener">BERTSUM论文阅读</a></li><li style="list-style: none"><input type="checkbox" checked> 开始组会汇报</li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/04/04/日语语法%204.8%20条件语/">日语语法Chapter 4</a></li></ul><h2 id="2020-05"><a href="#2020-05" class="headerlink" title="2020.05"></a>2020.05</h2><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> Windows10 + Python3.7 + Tensorflow1.15.0 + GTX1060 + CUDA10.0环境配置</li><li style="list-style: none"><input type="checkbox" checked> <a href="https://github.com/google-research/bert" target="_blank" rel="noopener">BERT预训练模型试玩</a></li></ul><h2 id="2020-06"><a href="#2020-06" class="headerlink" title="2020.06"></a>2020.06</h2><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> <a href="https://arxiv.org/abs/2004.08795" target="_blank" rel="noopener">SiameseBERT论文阅读</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="https://arxiv.org/abs/1908.10084" target="_blank" rel="noopener">SentenceBERT论文阅读</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="https://arxiv.org/abs/1907.11692" target="_blank" rel="noopener">RoBERTa论文阅读</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/06/28/如何理解%20RNN和LSTM/">RNN&amp;LSTM理解</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/06/28/如何理解%20Attention/">Attention Mechanism理解</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/06/24/日语语法%205.1%20使役动词和被动词/">日语语法Chapter 5</a></li></ul><h2 id="2020-07"><a href="#2020-07" class="headerlink" title="2020.07"></a>2020.07</h2><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> <a href="https://arxiv.org/abs/1909.10351" target="_blank" rel="noopener">TinyBERT论文阅读</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/07/03/如何理解%20Transformer/">Transformer理解</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/07/10/如何理解%20BERT/">BERT理解</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/07/10/日语语法%205.7%20表达相似性和传闻的多种说法/">日语语法Chapter 5</a></li></ul><h2 id="2020-08"><a href="#2020-08" class="headerlink" title="2020.08"></a>2020.08</h2><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/08/07/opencv添加水印%20C++实现/">opencv添加水印</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/08/27/run_classifier.py逐行注释/">BERT源码：run_classifier.py逐行注释</a></li></ul><p>生活：</p><ul><li style="list-style: none"><input type="checkbox" checked> 阳菜便服Ver. &amp; 和服Ver. 多图层尝试</li></ul><h2 id="2020-09"><a href="#2020-09" class="headerlink" title="2020.09"></a>2020.09</h2><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/09/03/modeling.py逐行注释/">BERT源码：modeling.py逐行注释</a></li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/09/04/日语语法%206.1%20正式表达（である、ではない）/">日语语法Chapter 6</a></li></ul><h2 id="2020-10"><a href="#2020-10" class="headerlink" title="2020.10"></a>2020.10</h2><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> 长文本分类</li><li style="list-style: none"><input type="checkbox" checked> <a href="/2020/10/16/python的文件IO/">python的文件IO</a></li></ul><h2 id="2020-11"><a href="#2020-11" class="headerlink" title="2020.11"></a>2020.11</h2><p>生活：</p><ul><li style="list-style: none"><input type="checkbox" checked> 日语歌词翻译尝试</li></ul><h2 id="2021-01"><a href="#2021-01" class="headerlink" title="2021.01"></a>2021.01</h2><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> 日语单词N2 P01-P40</li></ul><h2 id="2021-02"><a href="#2021-02" class="headerlink" title="2021.02"></a>2021.02</h2><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> <a href="/2021/02/10/如何理解%20CNN/">CNN理解</a></li></ul><h1 id="附-2021-年后展望"><a href="#附-2021-年后展望" class="headerlink" title="附 2021 年后展望"></a>附 2021 年后展望</h1><p>学习：</p><ul><li style="list-style: none"><input type="checkbox" checked> 毕业设计</li><li style="list-style: none"><input type="checkbox" checked> 机器学习基础</li><li style="list-style: none"><input type="checkbox" checked> 数据结构与算法</li><li style="list-style: none"><input type="checkbox" checked> Leetcode</li><li style="list-style: none"><input type="checkbox" checked> GTX1060 深度学习系列</li></ul><p>生活：</p><ul><li style="list-style: none"><input type="checkbox" checked> 摊煎饼进阶练习</li><li style="list-style: none"><input type="checkbox" checked> 如果可以的话让我去一次镰仓吧</li><li style="list-style: none"><input type="checkbox" checked> 如果可以的话让我去一次京都吧</li><li style="list-style: none"><input type="checkbox" checked> 如果可以的话让我去一次千叶吧</li><li style="list-style: none"><input type="checkbox" checked> 如果可以的话让我去一次秋叶原吧</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;2021-年前总结&quot;&gt;&lt;a href=&quot;#2021-年前总结&quot; class=&quot;headerlink&quot; title=&quot;2021 年前总结&quot;&gt;&lt;/a&gt;2021 年前总结&lt;/h1&gt;&lt;p&gt;现在是2021.02.10下午，去年的这会儿我大概正在为回国机票突然被取消而感到慌张
      
    
    </summary>
    
      <category term="生活" scheme="/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="总结" scheme="/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>分类任务的F1-score</title>
    <link href="/2021/01/21/%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84F1-score/"/>
    <id>/2021/01/21/分类任务的F1-score/</id>
    <published>2021-01-21T14:41:34.000Z</published>
    <updated>2021-01-21T14:41:34.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分类任务的F1-score"><a href="#分类任务的F1-score" class="headerlink" title="分类任务的F1-score"></a>分类任务的F1-score</h1><p><strong>背景</strong>：BERT的分类器源码run_classifier.py的评估指标部分只有accuracy和loss，没有F1-score。详情见 <a href="/2020/08/27/run_classifier.py逐行注释/#model-fn-builder">metric_fn</a> 。</p><h2 id="二分类模型的准确率、精确率、召回率以及F-score"><a href="#二分类模型的准确率、精确率、召回率以及F-score" class="headerlink" title="二分类模型的准确率、精确率、召回率以及F-score"></a>二分类模型的准确率、精确率、召回率以及F-score</h2><p>对于二分类模型：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">预测</th><th style="text-align:center">1’</th><th style="text-align:center">0’</th><th style="text-align:center">Total</th></tr></thead><tbody><tr><td style="text-align:center">实值</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">1</td><td style="text-align:center"></td><td style="text-align:center">TP（真正例）</td><td style="text-align:center">FN（假反例）</td><td style="text-align:center">P</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center"></td><td style="text-align:center">FP（假正例）</td><td style="text-align:center">TN（真反例）</td><td style="text-align:center">N</td></tr><tr><td style="text-align:center">Total</td><td style="text-align:center"></td><td style="text-align:center">P’</td><td style="text-align:center">N’</td><td style="text-align:center">S</td></tr></tbody></table><ol><li>准确率（Accuracy）：<br>\begin{equation}<br>Accuracy = \frac{TP + TN}{TP + FN + FP + TN} = \frac{TP + TN}{S}<br>\end{equation}</li><li>精确率/查准率（Precision）：<br>\begin{equation}<br>Precision = \frac{TP}{TP + FP} = \frac{TP}{P’}<br>\end{equation}</li><li>召回率/查全率（Recall）：<br>\begin{equation}<br>Recall = \frac{TP}{TP + FN} = \frac{TP}{P}<br>\end{equation}</li><li>F-score：<br>\begin{equation}<br>F-score = \frac{(1 + \beta^2) \cdot precision \cdot recall}{\beta^2 \cdot precision + recall}<br>\end{equation}<br>F-score的本质是Precision和Recall的加权调和平均。（加权的积在和上飞）</li><li>F1-score：<br>当 $ \beta^2 = 1 $ 时：<br>\begin{equation}<br>F-score = \frac{2 \cdot precision \cdot recall}{precision + recall}<br>\end{equation}</li></ol><h2 id="多分类任务的F1-score"><a href="#多分类任务的F1-score" class="headerlink" title="多分类任务的F1-score"></a>多分类任务的F1-score</h2><p>在多分类任务中，由于没有固定的正反例，没有统一的精确率、召回率等定义。<br>通常有两种算法F1_micro以及F1_macro。</p><p>对于N分类模型中的第i类有：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">预测</th><th style="text-align:center">i’</th><th style="text-align:center">其他’</th><th style="text-align:center">Total</th></tr></thead><tbody><tr><td style="text-align:center">实值</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">i</td><td style="text-align:center"></td><td style="text-align:center">TP1（真正例）</td><td style="text-align:center">FN1（假反例）</td><td style="text-align:center">P</td></tr><tr><td style="text-align:center">其他</td><td style="text-align:center"></td><td style="text-align:center">FP1（假正例）</td><td style="text-align:center">TN1（真反例）</td><td style="text-align:center">N</td></tr><tr><td style="text-align:center">Total</td><td style="text-align:center"></td><td style="text-align:center">P’</td><td style="text-align:center">N’</td><td style="text-align:center">S</td></tr></tbody></table><p>这样的 <strong>针对第i类的实值-预测值 困惑矩阵</strong> 可通过总的 <strong>N类实值-N类预测值 困惑矩阵</strong> 查表得到，共可得到N个。</p><p>根据这N个困惑矩阵的数据给出如下定义：</p><ol><li>F1_micro：<br>\begin{equation}<br>Recall_{micro} = \frac{\sum_{i=1}^{N}TP_i}{\sum_{i=1}^{N}TP_i + \sum_{i=1}^{N}FN_i}\\<br>Precision_{micro} = \frac{\sum_{i=1}^{N}TP_i}{\sum_{i=1}^{N}TP_i + \sum_{i=1}^{N}FP_i}\\<br>F1_{micro} = \frac{2 \cdot precision \cdot recall}{precision + recall}<br>\end{equation}<br>\begin{equation}<br>\because\sum_{i=1}^{N}TP_i + \sum_{i=1}^{N}FN_i = \sum_{i=1}^{N}TP_i + \sum_{i=1}^{N}FP_i = S\\<br>\therefore Accuracy = \frac{\sum_{i=1}^{N}TP_i}{S} = Recall_{micro} = Precision_{micro} = F1_{micro}<br>\end{equation}<br><strong>意义</strong>：F1_micro将<strong>所有样本</strong>都视为具有<strong>同样权重</strong>的样本，并针对全部样本作为整体，计算整体的Recall和Precision，并以此进一步计算F1-score。<br><strong>缺点</strong>：对于类别样本不均衡的数据集，如A：B = 10：1。由于F1_micro将所有样本都视为同样权重的样本，A类样本的统计学特征将分配到10倍于B类样本的权重，<strong>造成</strong>不同类别样本的<strong>权重分配不均匀</strong>。</li><li>F1_macro：<br>\begin{equation}<br>Recall_i = \frac{TP_i}{TP_i + FN_i}\\<br>Precision_i = \frac{TP_i}{TP_i + FP_i}\\<br>F1_i = \frac{2 \cdot precision_i \cdot recall_i}{precision_i + recall_i}\\<br>F1_{macro} = \frac{1}{N}\sum_{i=1}^{N}F1_i<br>\end{equation}<br><strong>意义</strong>：F1_macro将<strong>所有类别</strong>都视为具有<strong>同样权重</strong>的类别，并针对每个类别作为整体，分别计算每个类别的Recall和Precision，并以此进一步计算F1-score。<br><strong>优点</strong>：对于类别样本不均衡的数据集，如A：B = 10：1。由于F1_macro将所有类别都视为同样权重的类别，A类样本的统计学特征将分配到与B类样本相同的权重，<strong>不会造成</strong>不同类别样本的<strong>权重分配不均匀</strong>。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分类任务的F1-score&quot;&gt;&lt;a href=&quot;#分类任务的F1-score&quot; class=&quot;headerlink&quot; title=&quot;分类任务的F1-score&quot;&gt;&lt;/a&gt;分类任务的F1-score&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;：BERT的分
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="python" scheme="/tags/python/"/>
    
      <category term="数据处理" scheme="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>日语单词 N2 P31-P40</title>
    <link href="/2021/01/20/%E6%97%A5%E8%AF%AD%E5%8D%95%E8%AF%8D%20N2%20P31-P40/"/>
    <id>/2021/01/20/日语单词 N2 P31-P40/</id>
    <published>2021-01-20T13:59:28.000Z</published>
    <updated>2021-01-20T13:59:28.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>课程来自youtube@日本語の森</li></ul><h1 id="N2-ことば"><a href="#N2-ことば" class="headerlink" title="N2 ことば"></a>N2 ことば</h1><h2 id="P31"><a href="#P31" class="headerlink" title="P31"></a>P31</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=31&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>女性（じょせい）の心理（しんり）に応（おう）じて贈（おく）り物をする。</li><li>年齢（ねんれい）を聞いて全員（ぜんいん）が返事（へんじ）をする。</li><li>５対２で負（ま）けてしまい、ファン（fan）に申（もう）し訳（わけ）ない。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">合（あ）わせる</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 合并、配合、对照、引荐</span></td></tr><tr><td style="text-align:center">答（こた）える</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 回答、解答 <br> <em>同</em> - 応え、報え</span></td></tr><tr><td style="text-align:center">問（と）う</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 询问、调查</span></td></tr><tr><td style="text-align:center">勝（か）つ</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 胜利</span></td></tr></tbody></table><h2 id="P32"><a href="#P32" class="headerlink" title="P32"></a>P32</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=32&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>曖昧（あいまい）な知識（ちしき）を述（の）べる。</li><li>出張（しゅっちょう）を減（へ）らすことを希望（きぼう）する。</li><li>正面（しょうめん）玄関（げんかん）に咲（さ）いていた花が枯（か）れた。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">出入り口（でいりぐち）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 出入口</span></td></tr><tr><td style="text-align:center">咲く</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - （花）开</span></td></tr><tr><td style="text-align:center">開（ひら）く</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 开</span></td></tr><tr><td style="text-align:center">開（あ）く</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 开始（商店）、打开 <br> <em>他动词</em> - 张开（眼睛、嘴） <br> <em>同</em> - 明く、空く</span></td></tr><tr><td style="text-align:center">閉（し）まる</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 关闭、关门</span></td></tr><tr><td style="text-align:center">閉（と）じる</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词、他动词</em> - 关闭、合（书）、盖（容器）</span></td></tr></tbody></table><h2 id="P33"><a href="#P33" class="headerlink" title="P33"></a>P33</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=33&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>どの店で扇風機（せんぷうき）を買っても価格（かかく）に違いはない。</li><li>兄は真面目（まじめ）な割に成績（せいせき）が悪い。</li><li>踊（おど）りを終えた人のみ帰っていい。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">値段（ねだん）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 价格</span></td></tr><tr><td style="text-align:center">真面目（まじめ）</td><td style="text-align:center"><span class="heimu" title="释义"><em>形容动词</em> - 认真</span></td></tr><tr><td style="text-align:center">割（わり）に</td><td style="text-align:center"><span class="heimu" title="释义"><em>副词</em> - 比较（相对）、意外</span></td></tr><tr><td style="text-align:center">踊（おど）る</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 跳舞 <br> <em>自动词</em> - 颠簸（汽车）、不平整（印刷）</span></td></tr><tr><td style="text-align:center">終（お）える</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 完成、结束</span></td></tr><tr><td style="text-align:center">のみ</td><td style="text-align:center"><span class="heimu" title="释义"><em>副词</em> - 仅仅、只有</span></td></tr></tbody></table><h2 id="P34"><a href="#P34" class="headerlink" title="P34"></a>P34</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=34&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>道路（どうろ）が込んでいて通勤（つうきん）に余計（よけい）な時間がかかった。</li><li>ただの観光（かんこう）ではなくて科学（かがく）を勉強するために来た。</li><li>去年（きょねん）国際的（こくさいてき）に流行（りゅうこう）した柄（がら）の服を買う。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">生物学（せいぶつがく）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 生物学</span></td></tr><tr><td style="text-align:center">物理学（ぶつりがく）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 物理学</span></td></tr><tr><td style="text-align:center">化学（かがく）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 化学</span></td></tr><tr><td style="text-align:center">数学（すうがく）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 数学</span></td></tr><tr><td style="text-align:center">文学（ぶんがく）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 文学</span></td></tr><tr><td style="text-align:center">天文学（てんもんがく）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 天文学</span></td></tr><tr><td style="text-align:center">学問（がくもん）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 学科</span></td></tr><tr><td style="text-align:center">柄（がら）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 体格、品格、资格、（衣服的）花纹</span></td></tr></tbody></table><h2 id="P35"><a href="#P35" class="headerlink" title="P35"></a>P35</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=35&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>祭りに行くこと毎回（まいかい）写真（しゃしん）を沢山撮る。</li><li>日程（にってい）はそのままで、喫茶店（きっさてん）を変える。</li><li>のんびり絵本（えほん）を読んで休暇（きゅうか）を過ごした。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">注文（ちゅうもん）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、他动词</em> - 订货、订单、要求</span></td></tr><tr><td style="text-align:center">映す</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 映照、放映（影像）</span></td></tr><tr><td style="text-align:center">映る</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 反射、相称</span></td></tr><tr><td style="text-align:center">のんびり</td><td style="text-align:center"><span class="heimu" title="释义"><em>副词</em> - 无忧无虑、悠闲</span></td></tr><tr><td style="text-align:center">寛（くつろ）ぐ</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 轻松惬意休息、不拘礼节</span></td></tr></tbody></table><h2 id="P36"><a href="#P36" class="headerlink" title="P36"></a>P36</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=36&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>研究所（けんきゅうしょ）で一番偉い人を <ruby><span class="heimu" title="答案">尊敬</span><rt style="font-size:10px;color: white;background: #252525;">そん けい</rt></ruby> する。<br>そん：損　存　尊<br>けい：敬　警　経</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">損失（そんしつ）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 损失</span></td></tr><tr><td style="text-align:center">存在（そんざい）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、自动词</em> - 存在</span></td></tr><tr><td style="text-align:center">尊敬（そんけい）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 尊敬</span></td></tr><tr><td style="text-align:center">警察（けいさつ）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 警察</span></td></tr><tr><td style="text-align:center">経済（けいざい）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 经济</span></td></tr></tbody></table><ol start="2"><li>身体（しんたい）の状態（じょうたい）を <ruby><span class="heimu" title="答案">丁寧</span><rt style="font-size:10px;color: white;background: #252525;">てい ねい</rt></ruby> に調べる。<br>てい：程　提　定　丁　停<br>ねい：寧</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">程度（ていど）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 程度、水平</span></td></tr><tr><td style="text-align:center">提供（ていきょう）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、他动词</em> - 提供、赞助</span></td></tr><tr><td style="text-align:center">提出（ていしゅつ）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 提出</span></td></tr><tr><td style="text-align:center">定期（ていき）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 定期</span></td></tr><tr><td style="text-align:center">丁寧（ていねい）</td><td style="text-align:center"><span class="heimu" title="释义"><em>形容动词</em> - 有礼貌、小心谨慎、细心</span></td></tr><tr><td style="text-align:center">停止（ていし）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、自动词</em> - 中止、暂时停止</span></td></tr></tbody></table><h2 id="P37"><a href="#P37" class="headerlink" title="P37"></a>P37</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=37&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>ホテル（hotel）の会員（かいいん）に <ruby><span class="heimu" title="答案">率直</span><rt style="font-size:10px;color: white;background: #252525;">そっ ちょく</rt></ruby> な意見を求（もと）める</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">区別（くべつ）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、他动词</em> - 区分、辨别</span></td></tr><tr><td style="text-align:center">正直（しょうじき）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、形容动词、副词</em> - 诚实、坦率、正直</span></td></tr><tr><td style="text-align:center">お茶碗（ちゃわん）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 茶碗</span></td></tr><tr><td style="text-align:center">お茶碗蒸（む）し</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 蒸鸡蛋羹</span></td></tr></tbody></table><h2 id="P28"><a href="#P28" class="headerlink" title="P28"></a>P28</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=28&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>お菓子が不足（ふそく）したので適切（てきせつ）な分だけ足した。</li><li>二人の身長（しんちょう）を比（くら）べると僅（わず）かに差（さ）がある。</li><li>長生きする人は思い出（で）が多い。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">足（た）す</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 增加、填补</span></td></tr><tr><td style="text-align:center">足（た）りる</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 足够、可以、值得</span></td></tr><tr><td style="text-align:center">加（くわ）える</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 增加、附加</span></td></tr><tr><td style="text-align:center">増（ま）す</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词、他动词</em> - 增加、提升</span></td></tr><tr><td style="text-align:center">増（ふ）やす</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 增加、增值</span></td></tr><tr><td style="text-align:center">僅（わず）か</td><td style="text-align:center"><span class="heimu" title="释义"><em>副词、形容动词</em> - 微小、少</span></td></tr><tr><td style="text-align:center">微（かす）か</td><td style="text-align:center"><span class="heimu" title="释义"><em>形容动词</em> - 微弱、模糊、可怜</span></td></tr><tr><td style="text-align:center">思い出（で）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 回忆、纪念</span></td></tr><tr><td style="text-align:center">思い出（だ）す</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 回忆、记起</span></td></tr></tbody></table><h2 id="P29"><a href="#P29" class="headerlink" title="P29"></a>P29</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=29&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>話を進（すす）める前にあなたに対（たい）してどうしても言いたい。</li><li>おかずの種類（しゅるい）を倍（ばい）に増（ふ）やした。</li><li>怪我（けが）が順調（じゅんちょう）に回復（かいふく）している。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">話題（わだい）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 话题</span></td></tr><tr><td style="text-align:center">どうしても</td><td style="text-align:center"><span class="heimu" title="释义"><em>副词</em> - 无论如何也要</span></td></tr><tr><td style="text-align:center">おかず</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 菜肴</span></td></tr><tr><td style="text-align:center">順序（じゅんじょ）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 顺序、步骤</span></td></tr><tr><td style="text-align:center">純情（じゅんじょう）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、形容动词</em> - 纯真、天真</span></td></tr><tr><td style="text-align:center">傷（きず）つける</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 弄伤（身体）、损坏（感情）、败坏（名誉）</span></td></tr></tbody></table><h2 id="P30"><a href="#P30" class="headerlink" title="P30"></a>P30</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=30&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>息（いき）を吸（す）って吐くことを振（ふ）り返（かえ）す。</li><li>正確（せいかく）な日付（ひづけ）を聞く。</li><li>こんなに美しい光景（こうけい）を見たのは初めてだ。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;课程来自youtube@日本語の森&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;N2-ことば&quot;&gt;&lt;a href=&quot;#N2-ことば&quot; class=&quot;headerlink&quot; title=&quot;N2 ことば&quot;&gt;&lt;/a&gt;N2 ことば&lt;/h1&gt;&lt;h2 id=&quot;P31&quot;&gt;&lt;a hre
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="日语" scheme="/tags/%E6%97%A5%E8%AF%AD/"/>
    
  </entry>
  
  <entry>
    <title>日语单词 N2 P21-P30</title>
    <link href="/2021/01/20/%E6%97%A5%E8%AF%AD%E5%8D%95%E8%AF%8D%20N2%20P21-P30/"/>
    <id>/2021/01/20/日语单词 N2 P21-P30/</id>
    <published>2021-01-20T12:59:04.000Z</published>
    <updated>2021-01-20T12:59:04.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>课程来自youtube@日本語の森</li></ul><h1 id="N2-ことば"><a href="#N2-ことば" class="headerlink" title="N2 ことば"></a>N2 ことば</h1><h2 id="P21"><a href="#P21" class="headerlink" title="P21"></a>P21</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=21&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>温泉（おんせん）のお湯（ゆ）はかなり熱いから苦手（にがて）だ。</li><li>新しいスーツを買うかは値段（ねだん）次第（しだい）で決める。</li><li>この学年（がくねん）は芸術（げいじゅつ）に興味（きょうみ）を持っている学生が非常（ひじょう）に多い。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">貯（た）まる</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 积存、积攒</span></td></tr><tr><td style="text-align:center">脱（ぬ）ぐ</td><td style="text-align:center"><span class="heimu" title="释义"><em>名他动词</em> - 脱掉、摘掉</span></td></tr><tr><td style="text-align:center">脱（ぬ）げる</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - （穿在身上的东西）脱落、掉下</span></td></tr><tr><td style="text-align:center">拭（ぬぐ）う</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 擦拭、擦除</span></td></tr><tr><td style="text-align:center">関心（かんしん）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 关心、感兴趣</span></td></tr><tr><td style="text-align:center">趣味（しゅみ）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 趣味、爱好</span></td></tr></tbody></table><h2 id="P22"><a href="#P22" class="headerlink" title="P22"></a>P22</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=22&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>本社（ほんしゃ）に私の本が二冊（にさつ）あるのは確かだ。</li><li>時間はたっぷりあるのでコンビニに寄（よ）る。</li><li>交通（こうつう）の手段（しゅだん）が多いので行動（こうどう）範囲（はんい）が広かった。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">たっぷり</td><td style="text-align:center"><span class="heimu" title="释义"><em>副词</em> - 充分地、足够多</span></td></tr><tr><td style="text-align:center">寄（よ）る</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 靠近、聚集、顺便去、凭靠 <br> 同 - </span></td></tr></tbody></table><p>凭る|<br>|広がる|<span class="heimu" title="释义"><em>自动</em> - 拓宽、蔓延</span>|</p><h2 id="P23"><a href="#P23" class="headerlink" title="P23"></a>P23</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=23&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>劇（げき）の役割（やくわり）を巡って喧嘩（けんか）する。</li><li>解答（かいとう）欄（らん）を完全（かんぜん）に埋（う）めることを諦（あきら）めた。</li><li>製品（せいひん）を早く届（とど）けるよう指示（しじ）する。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">俳優（はいゆう）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 演员</span></td></tr><tr><td style="text-align:center">演（えん）じる</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 表演、扮演</span></td></tr><tr><td style="text-align:center">登場（とうじょう）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、自动词</em> - 登场、出现</span></td></tr><tr><td style="text-align:center">出身（しゅっしん）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 出身、籍贯、来自</span></td></tr><tr><td style="text-align:center">与（あた）える</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 给予、分配</span></td></tr><tr><td style="text-align:center">役割（やくわり）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 职责、角色、作用</span></td></tr><tr><td style="text-align:center">果たす</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 完成、实现、（用在动词词根后）尽</span></td></tr><tr><td style="text-align:center">諦（あきら）めた</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 放弃、死心</span></td></tr></tbody></table><h2 id="P24"><a href="#P24" class="headerlink" title="P24"></a>P24</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=24&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>栄養（えいよう）というテーマ（theme）から議論（ぎろん）を展開（てんかい）する。</li><li>恋愛（れんあい）に消極的（しょうきょくてき）か積極的（せっきょくてき）か問（と）う。</li><li>受験（じゅけん）の時には自然（しぜん）と部屋が散（ち）らかる。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">散（ち）らかる</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 零乱、（东西）散落</span></td></tr></tbody></table><h2 id="P25"><a href="#P25" class="headerlink" title="P25"></a>P25</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=25&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>組み合わせの良い料理（りょうり）を注文（ちゅうもん）する。</li><li>上にする面（めん）によって印象（いんしょう）が変わる。</li><li>火事（かじ）になった時の状況（じょうきょう）を想像（そうぞう）して動（うご）く。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">組み合わせ</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 配合、组合</span></td></tr><tr><td style="text-align:center">表（おもて）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 正面、表面、外边</span></td></tr><tr><td style="text-align:center">裏（うら）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 背面、后边</span></td></tr><tr><td style="text-align:center">平（たい）ら</td><td style="text-align:center"><span class="heimu" title="释义"><em>形容动词</em> - 平坦</span></td></tr><tr><td style="text-align:center">兎（うさぎ）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 兔子</span></td></tr></tbody></table><h2 id="P26"><a href="#P26" class="headerlink" title="P26"></a>P26</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=26&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>日が沈（しず）むと眠い。</li><li>この程度（ていど）の肉では満腹感（まんぷくかん）が得られないと批判（ひはん）する。</li><li>読書（どくしょ）する人の割合は減少（げんしょう）する傾向（けいこう）にある。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">方向（ほうこう）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 方向、方针</span></td></tr></tbody></table><h2 id="P27"><a href="#P27" class="headerlink" title="P27"></a>P27</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=27&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>人を外見（がいけん）だけで判断（はんだん）し、差別（さべつ）してはいけない。</li><li>先日（せんじつ）、通学（つうがく）途中（とちゅう）で不思議（ふしぎ）な体験をした。</li><li>正直（しょうじき）に話して謝（あやま）る。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">区別（くべつ）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、他动词</em> - 区分、辨别</span></td></tr><tr><td style="text-align:center">正直（しょうじき）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、形容动词、副词</em> - 诚实、坦率、正直</span></td></tr><tr><td style="text-align:center">お茶碗（ちゃわん）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 茶碗</span></td></tr><tr><td style="text-align:center">お茶碗蒸（む）し</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 蒸鸡蛋羹</span></td></tr></tbody></table><h2 id="P28"><a href="#P28" class="headerlink" title="P28"></a>P28</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=28&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>お菓子が不足（ふそく）したので適切（てきせつ）な分だけ足した。</li><li>二人の身長（しんちょう）を比（くら）べると僅（わず）かに差（さ）がある。</li><li>長生きする人は思い出（で）が多い。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">足（た）す</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 增加、填补</span></td></tr><tr><td style="text-align:center">足（た）りる</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词</em> - 足够、可以、值得</span></td></tr><tr><td style="text-align:center">加（くわ）える</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 增加、附加</span></td></tr><tr><td style="text-align:center">増（ま）す</td><td style="text-align:center"><span class="heimu" title="释义"><em>自动词、他动词</em> - 增加、提升</span></td></tr><tr><td style="text-align:center">増（ふ）やす</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 增加、增值</span></td></tr><tr><td style="text-align:center">僅（わず）か</td><td style="text-align:center"><span class="heimu" title="释义"><em>副词、形容动词</em> - 微小、少</span></td></tr><tr><td style="text-align:center">微（かす）か</td><td style="text-align:center"><span class="heimu" title="释义"><em>形容动词</em> - 微弱、模糊、可怜</span></td></tr><tr><td style="text-align:center">思い出（で）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 回忆、纪念</span></td></tr><tr><td style="text-align:center">思い出（だ）す</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 回忆、记起</span></td></tr></tbody></table><h2 id="P29"><a href="#P29" class="headerlink" title="P29"></a>P29</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=29&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>話を進（すす）める前にあなたに対（たい）してどうしても言いたい。</li><li>おかずの種類（しゅるい）を倍（ばい）に増（ふ）やした。</li><li>怪我（けが）が順調（じゅんちょう）に回復（かいふく）している。</li></ol><table><thead><tr><th style="text-align:center">单词/搭配</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">話題（わだい）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 话题</span></td></tr><tr><td style="text-align:center">どうしても</td><td style="text-align:center"><span class="heimu" title="释义"><em>副词</em> - 无论如何也要</span></td></tr><tr><td style="text-align:center">おかず</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 菜肴</span></td></tr><tr><td style="text-align:center">順序（じゅんじょ）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词</em> - 顺序、步骤</span></td></tr><tr><td style="text-align:center">純情（じゅんじょう）</td><td style="text-align:center"><span class="heimu" title="释义"><em>名词、形容动词</em> - 纯真、天真</span></td></tr><tr><td style="text-align:center">傷（きず）つける</td><td style="text-align:center"><span class="heimu" title="释义"><em>他动词</em> - 弄伤（身体）、损坏（感情）、败坏（名誉）</span></td></tr></tbody></table><h2 id="P30"><a href="#P30" class="headerlink" title="P30"></a>P30</h2><div style="position: relative; width: 100%; height: 0; padding-bottom: 65%;"><iframe src="//player.bilibili.com/player.html?aid=82744618&bvid=BV1PJ411V7Fk&cid=141563162&page=30&high_quality=1&danmuku=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 95%; left: 0; top: 0;"><br></iframe><br></div><ol><li>息（いき）を吸（す）って吐くことを振（ふ）り返（かえ）す。</li><li>正確（せいかく）な日付（ひづけ）を聞く。</li><li>こんなに美しい光景（こうけい）を見たのは初めてだ。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;课程来自youtube@日本語の森&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;N2-ことば&quot;&gt;&lt;a href=&quot;#N2-ことば&quot; class=&quot;headerlink&quot; title=&quot;N2 ことば&quot;&gt;&lt;/a&gt;N2 ことば&lt;/h1&gt;&lt;h2 id=&quot;P21&quot;&gt;&lt;a hre
      
    
    </summary>
    
      <category term="学习" scheme="/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="日语" scheme="/tags/%E6%97%A5%E8%AF%AD/"/>
    
  </entry>
  
</feed>
